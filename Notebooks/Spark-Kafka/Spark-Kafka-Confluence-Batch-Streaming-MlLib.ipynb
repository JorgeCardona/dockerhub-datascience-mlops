{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dc8402-9c6d-40cb-8650-72bc1cc599ec",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d6250-476c-4b3f-982f-e94a60ab5309",
   "metadata": {},
   "source": [
    "# START ZOOKEPER SERVICE\n",
    "### RUN THIS COMMAND IN A TERMINAL\n",
    "```\n",
    "/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties\n",
    "\n",
    "```\n",
    "# START KAFKA BROKERS\n",
    "### RUN THIS COMMAND ON A DIFFERENT TERMINAL FOR EACH LINE\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server1.properties\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2.properties\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server3.properties\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server4.properties\n",
    "```\n",
    "# LIST AVALABLE BROKERS\n",
    "```\n",
    "/usr/local/kafka/bin/zookeeper-shell.sh localhost:2181 ls /brokers/ids\n",
    "```\n",
    "\n",
    "# CREATE GROUPS AND TOPICS AVALABLE GROUPS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --group jorge-cardona-kafka-batch --topic animals-topic-batch\n",
    "/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --group jorge-cardona-kafka-streaming --topic animals-topic-streaming\n",
    "```\n",
    "\n",
    "# LIST AVALABLE GROUPS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list\n",
    "```\n",
    "\n",
    "# LISTS TOPICS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092\n",
    "```\n",
    "\n",
    "# LISTS CONSUMERS ASOCIATE TO GROUPS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group jorge-cardona-kafka-batch\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group jorge-cardona-kafka-streaming\n",
    "```\n",
    "\n",
    "# DELETE CONSUMER GROUP\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-batch\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-streaming\n",
    "```\n",
    "\n",
    "# DELETE TOPICS\n",
    "```\n",
    "# all topics at same time\n",
    "/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch,animals-topic-streaming\n",
    "\n",
    "# or one by one topic\n",
    "/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch\n",
    "/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-streaming\n",
    "```\n",
    "\n",
    "# DELETE TOPICS\n",
    "```\n",
    "# all groups at same time\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-batch,jorge-cardona-kafka-streaming\n",
    "\n",
    "\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-batch\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1d103-cffb-4485-b0f8-63941bd64e97",
   "metadata": {},
   "source": [
    "# <center> PYTHON LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea906c-f40a-4513-97e2-e674ca6381c0",
   "metadata": {},
   "source": [
    "# EXECUTE COMMANDS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbae095-c157-49ca-b60c-0a452319a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def execute_commands(commands):\n",
    "    for command in commands:\n",
    "        print(f\"Executing: {command}\")\n",
    "        try:\n",
    "            subprocess.Popen(command, shell=True)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a1ee5-b8c6-4e52-b4e6-120d6f191164",
   "metadata": {},
   "source": [
    "# START ZOOKEEPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b170d7-92cf-425b-9508-d9055cb96328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties\n",
      "\n",
      "[2025-03-10 22:42:50,050] INFO Reading configuration from: /usr/local/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,053] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,053] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,053] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,053] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,055] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
      "[2025-03-10 22:42:50,055] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
      "[2025-03-10 22:42:50,055] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)\n",
      "[2025-03-10 22:42:50,056] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)\n",
      "[2025-03-10 22:42:50,057] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)\n",
      "[2025-03-10 22:42:50,057] INFO Reading configuration from: /usr/local/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,058] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,058] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,058] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,058] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2025-03-10 22:42:50,058] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)\n",
      "[2025-03-10 22:42:50,070] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@79ad8b2f (org.apache.zookeeper.server.ServerMetrics)\n",
      "[2025-03-10 22:42:50,074] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)\n",
      "[2025-03-10 22:42:50,074] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)\n",
      "[2025-03-10 22:42:50,076] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)\n",
      "[2025-03-10 22:42:50,084] INFO  (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO    / /    / _ \\   / _ \\  | |/ /  / _ \\  / _ \\ | '_ \\   / _ \\ | '__| (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO  /_____|  \\___/   \\___/  |_|\\_\\  \\___|  \\___| | .__/   \\___| |_| (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,084] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,085] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,085] INFO  (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,086] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,086] INFO Server environment:host.name=5a54e50b65a1 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,086] INFO Server environment:java.version=21.0.5 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,087] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,087] INFO Server environment:java.home=/usr/lib/jvm/jdk-21.0.5-oracle-x64 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,087] INFO Server environment:java.class.path=/usr/local/kafka/bin/../libs/activation-1.1.1.jar:/usr/local/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/usr/local/kafka/bin/../libs/argparse4j-0.7.0.jar:/usr/local/kafka/bin/../libs/audience-annotations-0.12.0.jar:/usr/local/kafka/bin/../libs/caffeine-2.9.3.jar:/usr/local/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/usr/local/kafka/bin/../libs/commons-cli-1.4.jar:/usr/local/kafka/bin/../libs/commons-collections-3.2.2.jar:/usr/local/kafka/bin/../libs/commons-digester-2.1.jar:/usr/local/kafka/bin/../libs/commons-io-2.14.0.jar:/usr/local/kafka/bin/../libs/commons-lang3-3.12.0.jar:/usr/local/kafka/bin/../libs/commons-logging-1.2.jar:/usr/local/kafka/bin/../libs/commons-validator-1.7.jar:/usr/local/kafka/bin/../libs/connect-api-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-json-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-runtime-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-transforms-3.9.0.jar:/usr/local/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/usr/local/kafka/bin/../libs/hk2-api-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-locator-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-utils-2.6.1.jar:/usr/local/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-core-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-databind-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-scala_2.12-2.16.2.jar:/usr/local/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/usr/local/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/usr/local/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/usr/local/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/usr/local/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/usr/local/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/usr/local/kafka/bin/../libs/javassist-3.29.2-GA.jar:/usr/local/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/usr/local/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/usr/local/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/usr/local/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/usr/local/kafka/bin/../libs/jaxb-api-2.3.1.jar:/usr/local/kafka/bin/../libs/jersey-client-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-common-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-server-2.39.1.jar:/usr/local/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jline-3.25.1.jar:/usr/local/kafka/bin/../libs/jopt-simple-5.0.4.jar:/usr/local/kafka/bin/../libs/jose4j-0.9.4.jar:/usr/local/kafka/bin/../libs/jsr305-3.0.2.jar:/usr/local/kafka/bin/../libs/kafka-clients-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-raft-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-shell-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-scala_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/lz4-java-1.8.0.jar:/usr/local/kafka/bin/../libs/maven-artifact-3.9.6.jar:/usr/local/kafka/bin/../libs/metrics-core-2.2.0.jar:/usr/local/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/usr/local/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/usr/local/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/usr/local/kafka/bin/../libs/paranamer-2.8.jar:/usr/local/kafka/bin/../libs/pcollections-4.0.1.jar:/usr/local/kafka/bin/../libs/plexus-utils-3.5.1.jar:/usr/local/kafka/bin/../libs/protobuf-java-3.25.5.jar:/usr/local/kafka/bin/../libs/reflections-0.10.2.jar:/usr/local/kafka/bin/../libs/reload4j-1.2.25.jar:/usr/local/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/usr/local/kafka/bin/../libs/scala-collection-compat_2.12-2.10.0.jar:/usr/local/kafka/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/usr/local/kafka/bin/../libs/scala-library-2.12.19.jar:/usr/local/kafka/bin/../libs/scala-logging_2.12-3.9.5.jar:/usr/local/kafka/bin/../libs/scala-reflect-2.12.19.jar:/usr/local/kafka/bin/../libs/slf4j-api-1.7.36.jar:/usr/local/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/usr/local/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/usr/local/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/usr/local/kafka/bin/../libs/trogdor-3.9.0.jar:/usr/local/kafka/bin/../libs/zookeeper-3.8.4.jar:/usr/local/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/usr/local/kafka/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,087] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,088] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,089] INFO Server environment:user.dir=/notebooks (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,089] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,089] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,089] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,089] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,089] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,090] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,090] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,090] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,090] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,090] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,091] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)\n",
      "[2025-03-10 22:42:50,093] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,093] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,094] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)\n",
      "[2025-03-10 22:42:50,095] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)\n",
      "[2025-03-10 22:42:50,095] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2025-03-10 22:42:50,095] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2025-03-10 22:42:50,095] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2025-03-10 22:42:50,095] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2025-03-10 22:42:50,096] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2025-03-10 22:42:50,096] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2025-03-10 22:42:50,098] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,098] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,099] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)\n",
      "[2025-03-10 22:42:50,099] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)\n",
      "[2025-03-10 22:42:50,099] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir /usr/local/kafka/data/zookeeper/version-2 snapdir /usr/local/kafka/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,116] INFO Logging initialized @512ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)\n",
      "[2025-03-10 22:42:50,181] WARN o.e.j.s.ServletContextHandler@5fbe4146{/,null,STOPPED} contextPath ends with /* (org.eclipse.jetty.server.handler.ContextHandler)\n",
      "[2025-03-10 22:42:50,181] WARN Empty contextPath (org.eclipse.jetty.server.handler.ContextHandler)\n",
      "[2025-03-10 22:42:50,198] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.5+9-LTS-239 (org.eclipse.jetty.server.Server)\n",
      "[2025-03-10 22:42:50,221] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)\n",
      "[2025-03-10 22:42:50,221] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)\n",
      "[2025-03-10 22:42:50,223] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)\n",
      "[2025-03-10 22:42:50,225] WARN ServletContext@o.e.j.s.ServletContextHandler@5fbe4146{/,null,STARTING} has uncovered http methods for path: /* (org.eclipse.jetty.security.SecurityHandler)\n",
      "[2025-03-10 22:42:50,235] INFO Started o.e.j.s.ServletContextHandler@5fbe4146{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)\n",
      "[2025-03-10 22:42:50,245] INFO Started ServerConnector@74235045{HTTP/1.1, (http/1.1)}{0.0.0.0:9090} (org.eclipse.jetty.server.AbstractConnector)\n",
      "[2025-03-10 22:42:50,245] INFO Started @641ms (org.eclipse.jetty.server.Server)\n",
      "[2025-03-10 22:42:50,245] INFO Started AdminServer on address 0.0.0.0, port 9090 and command URL /commands (org.apache.zookeeper.server.admin.JettyAdminServer)\n",
      "[2025-03-10 22:42:50,248] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)\n",
      "[2025-03-10 22:42:50,249] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)\n",
      "[2025-03-10 22:42:50,250] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)\n",
      "[2025-03-10 22:42:50,251] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)\n",
      "[2025-03-10 22:42:50,261] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)\n",
      "[2025-03-10 22:42:50,261] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)\n",
      "[2025-03-10 22:42:50,261] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)\n",
      "[2025-03-10 22:42:50,262] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)\n",
      "[2025-03-10 22:42:50,266] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)\n",
      "[2025-03-10 22:42:50,266] INFO Snapshotting: 0x0 to /usr/local/kafka/data/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)\n",
      "[2025-03-10 22:42:50,270] INFO Snapshot loaded in 8 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)\n",
      "[2025-03-10 22:42:50,271] INFO Snapshotting: 0x0 to /usr/local/kafka/data/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)\n",
      "[2025-03-10 22:42:50,272] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2025-03-10 22:42:50,279] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)\n",
      "[2025-03-10 22:42:50,280] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)\n",
      "[2025-03-10 22:42:50,295] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)\n",
      "[2025-03-10 22:42:50,296] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)\n"
     ]
    }
   ],
   "source": [
    "commands = [\n",
    "    \"/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties\"\n",
    "]\n",
    "\n",
    "execute_commands(commands=commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46934a18-8902-4764-a789-36761bbb3871",
   "metadata": {},
   "source": [
    "# START SECOND BROKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cefd55-ad64-45b1-a84e-6591c1950f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2.properties\n",
      "\n",
      "[2025-03-10 22:42:52,647] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\n",
      "[2025-03-10 22:42:52,853] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)\n",
      "[2025-03-10 22:42:52,931] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)\n",
      "[2025-03-10 22:42:52,933] INFO starting (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:52,933] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:52,953] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2025-03-10 22:42:52,956] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,956] INFO Client environment:host.name=5a54e50b65a1 (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,956] INFO Client environment:java.version=21.0.5 (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,956] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,957] INFO Client environment:java.home=/usr/lib/jvm/jdk-21.0.5-oracle-x64 (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,957] INFO Client environment:java.class.path=/usr/local/kafka/bin/../libs/activation-1.1.1.jar:/usr/local/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/usr/local/kafka/bin/../libs/argparse4j-0.7.0.jar:/usr/local/kafka/bin/../libs/audience-annotations-0.12.0.jar:/usr/local/kafka/bin/../libs/caffeine-2.9.3.jar:/usr/local/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/usr/local/kafka/bin/../libs/commons-cli-1.4.jar:/usr/local/kafka/bin/../libs/commons-collections-3.2.2.jar:/usr/local/kafka/bin/../libs/commons-digester-2.1.jar:/usr/local/kafka/bin/../libs/commons-io-2.14.0.jar:/usr/local/kafka/bin/../libs/commons-lang3-3.12.0.jar:/usr/local/kafka/bin/../libs/commons-logging-1.2.jar:/usr/local/kafka/bin/../libs/commons-validator-1.7.jar:/usr/local/kafka/bin/../libs/connect-api-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-json-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-runtime-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-transforms-3.9.0.jar:/usr/local/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/usr/local/kafka/bin/../libs/hk2-api-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-locator-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-utils-2.6.1.jar:/usr/local/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-core-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-databind-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-scala_2.12-2.16.2.jar:/usr/local/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/usr/local/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/usr/local/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/usr/local/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/usr/local/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/usr/local/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/usr/local/kafka/bin/../libs/javassist-3.29.2-GA.jar:/usr/local/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/usr/local/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/usr/local/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/usr/local/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/usr/local/kafka/bin/../libs/jaxb-api-2.3.1.jar:/usr/local/kafka/bin/../libs/jersey-client-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-common-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-server-2.39.1.jar:/usr/local/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jline-3.25.1.jar:/usr/local/kafka/bin/../libs/jopt-simple-5.0.4.jar:/usr/local/kafka/bin/../libs/jose4j-0.9.4.jar:/usr/local/kafka/bin/../libs/jsr305-3.0.2.jar:/usr/local/kafka/bin/../libs/kafka-clients-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-raft-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-shell-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-scala_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/lz4-java-1.8.0.jar:/usr/local/kafka/bin/../libs/maven-artifact-3.9.6.jar:/usr/local/kafka/bin/../libs/metrics-core-2.2.0.jar:/usr/local/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/usr/local/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/usr/local/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/usr/local/kafka/bin/../libs/paranamer-2.8.jar:/usr/local/kafka/bin/../libs/pcollections-4.0.1.jar:/usr/local/kafka/bin/../libs/plexus-utils-3.5.1.jar:/usr/local/kafka/bin/../libs/protobuf-java-3.25.5.jar:/usr/local/kafka/bin/../libs/reflections-0.10.2.jar:/usr/local/kafka/bin/../libs/reload4j-1.2.25.jar:/usr/local/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/usr/local/kafka/bin/../libs/scala-collection-compat_2.12-2.10.0.jar:/usr/local/kafka/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/usr/local/kafka/bin/../libs/scala-library-2.12.19.jar:/usr/local/kafka/bin/../libs/scala-logging_2.12-3.9.5.jar:/usr/local/kafka/bin/../libs/scala-reflect-2.12.19.jar:/usr/local/kafka/bin/../libs/slf4j-api-1.7.36.jar:/usr/local/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/usr/local/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/usr/local/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/usr/local/kafka/bin/../libs/trogdor-3.9.0.jar:/usr/local/kafka/bin/../libs/zookeeper-3.8.4.jar:/usr/local/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/usr/local/kafka/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:os.version=5.15.167.4-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,958] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,959] INFO Client environment:user.dir=/notebooks (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,959] INFO Client environment:os.memory.free=983MB (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,959] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,959] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,960] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3224a577 (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:42:52,965] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)\n",
      "[2025-03-10 22:42:52,969] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)\n",
      "[2025-03-10 22:42:52,972] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2025-03-10 22:42:52,973] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)\n",
      "[2025-03-10 22:42:52,975] INFO Socket connection established, initiating session, client: /127.0.0.1:56668, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)\n",
      "[2025-03-10 22:42:52,983] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)\n",
      "[2025-03-10 22:42:52,998] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100005479200000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)\n",
      "[2025-03-10 22:42:53,000] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2025-03-10 22:42:53,268] INFO Cluster ID = snKkvVlIT7mJQxwYkjD1Kg (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:53,343] INFO KafkaConfig values: \n",
      "\tadvertised.listeners = null\n",
      "\talter.config.policy.class.name = null\n",
      "\talter.log.dirs.replication.quota.window.num = 11\n",
      "\talter.log.dirs.replication.quota.window.size.seconds = 1\n",
      "\tauthorizer.class.name = \n",
      "\tauto.create.topics.enable = true\n",
      "\tauto.include.jmx.reporter = true\n",
      "\tauto.leader.rebalance.enable = true\n",
      "\tbackground.threads = 10\n",
      "\tbroker.heartbeat.interval.ms = 2000\n",
      "\tbroker.id = 2\n",
      "\tbroker.id.generation.enable = true\n",
      "\tbroker.rack = null\n",
      "\tbroker.session.timeout.ms = 9000\n",
      "\tclient.quota.callback.class = null\n",
      "\tcompression.gzip.level = -1\n",
      "\tcompression.lz4.level = 9\n",
      "\tcompression.type = producer\n",
      "\tcompression.zstd.level = 3\n",
      "\tconnection.failed.authentication.delay.ms = 100\n",
      "\tconnections.max.idle.ms = 600000\n",
      "\tconnections.max.reauth.ms = 0\n",
      "\tcontrol.plane.listener.name = null\n",
      "\tcontrolled.shutdown.enable = true\n",
      "\tcontrolled.shutdown.max.retries = 3\n",
      "\tcontrolled.shutdown.retry.backoff.ms = 5000\n",
      "\tcontroller.listener.names = null\n",
      "\tcontroller.quorum.append.linger.ms = 25\n",
      "\tcontroller.quorum.bootstrap.servers = []\n",
      "\tcontroller.quorum.election.backoff.max.ms = 1000\n",
      "\tcontroller.quorum.election.timeout.ms = 1000\n",
      "\tcontroller.quorum.fetch.timeout.ms = 2000\n",
      "\tcontroller.quorum.request.timeout.ms = 2000\n",
      "\tcontroller.quorum.retry.backoff.ms = 20\n",
      "\tcontroller.quorum.voters = []\n",
      "\tcontroller.quota.window.num = 11\n",
      "\tcontroller.quota.window.size.seconds = 1\n",
      "\tcontroller.socket.timeout.ms = 30000\n",
      "\tcreate.topic.policy.class.name = null\n",
      "\tdefault.replication.factor = 1\n",
      "\tdelegation.token.expiry.check.interval.ms = 3600000\n",
      "\tdelegation.token.expiry.time.ms = 86400000\n",
      "\tdelegation.token.master.key = null\n",
      "\tdelegation.token.max.lifetime.ms = 604800000\n",
      "\tdelegation.token.secret.key = null\n",
      "\tdelete.records.purgatory.purge.interval.requests = 1\n",
      "\tdelete.topic.enable = true\n",
      "\tearly.start.listeners = null\n",
      "\teligible.leader.replicas.enable = false\n",
      "\tfetch.max.bytes = 57671680\n",
      "\tfetch.purgatory.purge.interval.requests = 1000\n",
      "\tgroup.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]\n",
      "\tgroup.consumer.heartbeat.interval.ms = 5000\n",
      "\tgroup.consumer.max.heartbeat.interval.ms = 15000\n",
      "\tgroup.consumer.max.session.timeout.ms = 60000\n",
      "\tgroup.consumer.max.size = 2147483647\n",
      "\tgroup.consumer.migration.policy = disabled\n",
      "\tgroup.consumer.min.heartbeat.interval.ms = 5000\n",
      "\tgroup.consumer.min.session.timeout.ms = 45000\n",
      "\tgroup.consumer.session.timeout.ms = 45000\n",
      "\tgroup.coordinator.append.linger.ms = 10\n",
      "\tgroup.coordinator.new.enable = false\n",
      "\tgroup.coordinator.rebalance.protocols = [classic]\n",
      "\tgroup.coordinator.threads = 1\n",
      "\tgroup.initial.rebalance.delay.ms = 0\n",
      "\tgroup.max.session.timeout.ms = 1800000\n",
      "\tgroup.max.size = 2147483647\n",
      "\tgroup.min.session.timeout.ms = 6000\n",
      "\tgroup.share.delivery.count.limit = 5\n",
      "\tgroup.share.enable = false\n",
      "\tgroup.share.heartbeat.interval.ms = 5000\n",
      "\tgroup.share.max.groups = 10\n",
      "\tgroup.share.max.heartbeat.interval.ms = 15000\n",
      "\tgroup.share.max.record.lock.duration.ms = 60000\n",
      "\tgroup.share.max.session.timeout.ms = 60000\n",
      "\tgroup.share.max.size = 200\n",
      "\tgroup.share.min.heartbeat.interval.ms = 5000\n",
      "\tgroup.share.min.record.lock.duration.ms = 15000\n",
      "\tgroup.share.min.session.timeout.ms = 45000\n",
      "\tgroup.share.partition.max.record.locks = 200\n",
      "\tgroup.share.record.lock.duration.ms = 30000\n",
      "\tgroup.share.session.timeout.ms = 45000\n",
      "\tinitial.broker.registration.timeout.ms = 60000\n",
      "\tinter.broker.listener.name = null\n",
      "\tinter.broker.protocol.version = 3.9-IV0\n",
      "\tkafka.metrics.polling.interval.secs = 10\n",
      "\tkafka.metrics.reporters = []\n",
      "\tleader.imbalance.check.interval.seconds = 300\n",
      "\tleader.imbalance.per.broker.percentage = 10\n",
      "\tlistener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT\n",
      "\tlisteners = PLAINTEXT://:9092\n",
      "\tlog.cleaner.backoff.ms = 15000\n",
      "\tlog.cleaner.dedupe.buffer.size = 134217728\n",
      "\tlog.cleaner.delete.retention.ms = 86400000\n",
      "\tlog.cleaner.enable = true\n",
      "\tlog.cleaner.io.buffer.load.factor = 0.9\n",
      "\tlog.cleaner.io.buffer.size = 524288\n",
      "\tlog.cleaner.io.max.bytes.per.second = 1.7976931348623157E308\n",
      "\tlog.cleaner.max.compaction.lag.ms = 9223372036854775807\n",
      "\tlog.cleaner.min.cleanable.ratio = 0.5\n",
      "\tlog.cleaner.min.compaction.lag.ms = 0\n",
      "\tlog.cleaner.threads = 1\n",
      "\tlog.cleanup.policy = [delete]\n",
      "\tlog.dir = /tmp/kafka-logs\n",
      "\tlog.dir.failure.timeout.ms = 30000\n",
      "\tlog.dirs = /usr/local/kafka/data/logs/broker_2\n",
      "\tlog.flush.interval.messages = 9223372036854775807\n",
      "\tlog.flush.interval.ms = null\n",
      "\tlog.flush.offset.checkpoint.interval.ms = 60000\n",
      "\tlog.flush.scheduler.interval.ms = 9223372036854775807\n",
      "\tlog.flush.start.offset.checkpoint.interval.ms = 60000\n",
      "\tlog.index.interval.bytes = 4096\n",
      "\tlog.index.size.max.bytes = 10485760\n",
      "\tlog.initial.task.delay.ms = 30000\n",
      "\tlog.local.retention.bytes = -2\n",
      "\tlog.local.retention.ms = -2\n",
      "\tlog.message.downconversion.enable = true\n",
      "\tlog.message.format.version = 3.0-IV1\n",
      "\tlog.message.timestamp.after.max.ms = 9223372036854775807\n",
      "\tlog.message.timestamp.before.max.ms = 9223372036854775807\n",
      "\tlog.message.timestamp.difference.max.ms = 9223372036854775807\n",
      "\tlog.message.timestamp.type = CreateTime\n",
      "\tlog.preallocate = false\n",
      "\tlog.retention.bytes = -1\n",
      "\tlog.retention.check.interval.ms = 300000\n",
      "\tlog.retention.hours = 168\n",
      "\tlog.retention.minutes = null\n",
      "\tlog.retention.ms = null\n",
      "\tlog.roll.hours = 168\n",
      "\tlog.roll.jitter.hours = 0\n",
      "\tlog.roll.jitter.ms = null\n",
      "\tlog.roll.ms = null\n",
      "\tlog.segment.bytes = 1073741824\n",
      "\tlog.segment.delete.delay.ms = 60000\n",
      "\tmax.connection.creation.rate = 2147483647\n",
      "\tmax.connections = 2147483647\n",
      "\tmax.connections.per.ip = 2147483647\n",
      "\tmax.connections.per.ip.overrides = \n",
      "\tmax.incremental.fetch.session.cache.slots = 1000\n",
      "\tmax.request.partition.size.limit = 2000\n",
      "\tmessage.max.bytes = 1048588\n",
      "\tmetadata.log.dir = null\n",
      "\tmetadata.log.max.record.bytes.between.snapshots = 20971520\n",
      "\tmetadata.log.max.snapshot.interval.ms = 3600000\n",
      "\tmetadata.log.segment.bytes = 1073741824\n",
      "\tmetadata.log.segment.min.bytes = 8388608\n",
      "\tmetadata.log.segment.ms = 604800000\n",
      "\tmetadata.max.idle.interval.ms = 500\n",
      "\tmetadata.max.retention.bytes = 104857600\n",
      "\tmetadata.max.retention.ms = 604800000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tmin.insync.replicas = 1\n",
      "\tnode.id = 2\n",
      "\tnum.io.threads = 8\n",
      "\tnum.network.threads = 3\n",
      "\tnum.partitions = 1\n",
      "\tnum.recovery.threads.per.data.dir = 1\n",
      "\tnum.replica.alter.log.dirs.threads = null\n",
      "\tnum.replica.fetchers = 1\n",
      "\toffset.metadata.max.bytes = 4096\n",
      "\toffsets.commit.required.acks = -1\n",
      "\toffsets.commit.timeout.ms = 5000\n",
      "\toffsets.load.buffer.size = 5242880\n",
      "\toffsets.retention.check.interval.ms = 600000\n",
      "\toffsets.retention.minutes = 10080\n",
      "\toffsets.topic.compression.codec = 0\n",
      "\toffsets.topic.num.partitions = 50\n",
      "\toffsets.topic.replication.factor = 1\n",
      "\toffsets.topic.segment.bytes = 104857600\n",
      "\tpassword.encoder.cipher.algorithm = AES/CBC/PKCS5Padding\n",
      "\tpassword.encoder.iterations = 4096\n",
      "\tpassword.encoder.key.length = 128\n",
      "\tpassword.encoder.keyfactory.algorithm = null\n",
      "\tpassword.encoder.old.secret = null\n",
      "\tpassword.encoder.secret = null\n",
      "\tprincipal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder\n",
      "\tprocess.roles = []\n",
      "\tproducer.id.expiration.check.interval.ms = 600000\n",
      "\tproducer.id.expiration.ms = 86400000\n",
      "\tproducer.purgatory.purge.interval.requests = 1000\n",
      "\tqueued.max.request.bytes = -1\n",
      "\tqueued.max.requests = 500\n",
      "\tquota.window.num = 11\n",
      "\tquota.window.size.seconds = 1\n",
      "\tremote.fetch.max.wait.ms = 500\n",
      "\tremote.log.index.file.cache.total.size.bytes = 1073741824\n",
      "\tremote.log.manager.copier.thread.pool.size = -1\n",
      "\tremote.log.manager.copy.max.bytes.per.second = 9223372036854775807\n",
      "\tremote.log.manager.copy.quota.window.num = 11\n",
      "\tremote.log.manager.copy.quota.window.size.seconds = 1\n",
      "\tremote.log.manager.expiration.thread.pool.size = -1\n",
      "\tremote.log.manager.fetch.max.bytes.per.second = 9223372036854775807\n",
      "\tremote.log.manager.fetch.quota.window.num = 11\n",
      "\tremote.log.manager.fetch.quota.window.size.seconds = 1\n",
      "\tremote.log.manager.task.interval.ms = 30000\n",
      "\tremote.log.manager.task.retry.backoff.max.ms = 30000\n",
      "\tremote.log.manager.task.retry.backoff.ms = 500\n",
      "\tremote.log.manager.task.retry.jitter = 0.2\n",
      "\tremote.log.manager.thread.pool.size = 10\n",
      "\tremote.log.metadata.custom.metadata.max.bytes = 128\n",
      "\tremote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager\n",
      "\tremote.log.metadata.manager.class.path = null\n",
      "\tremote.log.metadata.manager.impl.prefix = rlmm.config.\n",
      "\tremote.log.metadata.manager.listener.name = null\n",
      "\tremote.log.reader.max.pending.tasks = 100\n",
      "\tremote.log.reader.threads = 10\n",
      "\tremote.log.storage.manager.class.name = null\n",
      "\tremote.log.storage.manager.class.path = null\n",
      "\tremote.log.storage.manager.impl.prefix = rsm.config.\n",
      "\tremote.log.storage.system.enable = false\n",
      "\treplica.fetch.backoff.ms = 1000\n",
      "\treplica.fetch.max.bytes = 1048576\n",
      "\treplica.fetch.min.bytes = 1\n",
      "\treplica.fetch.response.max.bytes = 10485760\n",
      "\treplica.fetch.wait.max.ms = 500\n",
      "\treplica.high.watermark.checkpoint.interval.ms = 5000\n",
      "\treplica.lag.time.max.ms = 30000\n",
      "\treplica.selector.class = null\n",
      "\treplica.socket.receive.buffer.bytes = 65536\n",
      "\treplica.socket.timeout.ms = 30000\n",
      "\treplication.quota.window.num = 11\n",
      "\treplication.quota.window.size.seconds = 1\n",
      "\trequest.timeout.ms = 30000\n",
      "\treserved.broker.max.id = 1000\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.enabled.mechanisms = [GSSAPI]\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.principal.to.local.rules = [DEFAULT]\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.connect.timeout.ms = null\n",
      "\tsasl.login.read.timeout.ms = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.login.retry.backoff.max.ms = 10000\n",
      "\tsasl.login.retry.backoff.ms = 100\n",
      "\tsasl.mechanism.controller.protocol = GSSAPI\n",
      "\tsasl.mechanism.inter.broker.protocol = GSSAPI\n",
      "\tsasl.oauthbearer.clock.skew.seconds = 30\n",
      "\tsasl.oauthbearer.expected.audience = null\n",
      "\tsasl.oauthbearer.expected.issuer = null\n",
      "\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n",
      "\tsasl.oauthbearer.jwks.endpoint.url = null\n",
      "\tsasl.oauthbearer.scope.claim.name = scope\n",
      "\tsasl.oauthbearer.sub.claim.name = sub\n",
      "\tsasl.oauthbearer.token.endpoint.url = null\n",
      "\tsasl.server.callback.handler.class = null\n",
      "\tsasl.server.max.receive.size = 524288\n",
      "\tsecurity.inter.broker.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tserver.max.startup.time.ms = 9223372036854775807\n",
      "\tsocket.connection.setup.timeout.max.ms = 30000\n",
      "\tsocket.connection.setup.timeout.ms = 10000\n",
      "\tsocket.listen.backlog.size = 50\n",
      "\tsocket.receive.buffer.bytes = 102400\n",
      "\tsocket.request.max.bytes = 104857600\n",
      "\tsocket.send.buffer.bytes = 102400\n",
      "\tssl.allow.dn.changes = false\n",
      "\tssl.allow.san.changes = false\n",
      "\tssl.cipher.suites = []\n",
      "\tssl.client.auth = none\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.certificate.chain = null\n",
      "\tssl.keystore.key = null\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.principal.mapping.rules = DEFAULT\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.certificates = null\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\ttelemetry.max.bytes = 1048576\n",
      "\ttransaction.abort.timed.out.transaction.cleanup.interval.ms = 10000\n",
      "\ttransaction.max.timeout.ms = 900000\n",
      "\ttransaction.partition.verification.enable = true\n",
      "\ttransaction.remove.expired.transaction.cleanup.interval.ms = 3600000\n",
      "\ttransaction.state.log.load.buffer.size = 5242880\n",
      "\ttransaction.state.log.min.isr = 1\n",
      "\ttransaction.state.log.num.partitions = 50\n",
      "\ttransaction.state.log.replication.factor = 1\n",
      "\ttransaction.state.log.segment.bytes = 104857600\n",
      "\ttransactional.id.expiration.ms = 604800000\n",
      "\tunclean.leader.election.enable = false\n",
      "\tunclean.leader.election.interval.ms = 300000\n",
      "\tunstable.api.versions.enable = false\n",
      "\tunstable.feature.versions.enable = false\n",
      "\tzookeeper.clientCnxnSocket = null\n",
      "\tzookeeper.connect = localhost:2181\n",
      "\tzookeeper.connection.timeout.ms = 18000\n",
      "\tzookeeper.max.in.flight.requests = 10\n",
      "\tzookeeper.metadata.migration.enable = false\n",
      "\tzookeeper.metadata.migration.min.batch.size = 200\n",
      "\tzookeeper.session.timeout.ms = 18000\n",
      "\tzookeeper.set.acl = false\n",
      "\tzookeeper.ssl.cipher.suites = null\n",
      "\tzookeeper.ssl.client.enable = false\n",
      "\tzookeeper.ssl.crl.enable = false\n",
      "\tzookeeper.ssl.enabled.protocols = null\n",
      "\tzookeeper.ssl.endpoint.identification.algorithm = HTTPS\n",
      "\tzookeeper.ssl.keystore.location = null\n",
      "\tzookeeper.ssl.keystore.password = null\n",
      "\tzookeeper.ssl.keystore.type = null\n",
      "\tzookeeper.ssl.ocsp.enable = false\n",
      "\tzookeeper.ssl.protocol = TLSv1.2\n",
      "\tzookeeper.ssl.truststore.location = null\n",
      "\tzookeeper.ssl.truststore.password = null\n",
      "\tzookeeper.ssl.truststore.type = null\n",
      " (kafka.server.KafkaConfig)\n",
      "[2025-03-10 22:42:53,376] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:42:53,377] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:42:53,378] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:42:53,380] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:42:53,387] INFO [KafkaServer id=2] Rewriting /usr/local/kafka/data/logs/broker_2/meta.properties (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:53,450] INFO Loading logs from log dirs ArrayBuffer(/usr/local/kafka/data/logs/broker_2) (kafka.log.LogManager)\n",
      "[2025-03-10 22:42:53,455] INFO No logs found to be loaded in /usr/local/kafka/data/logs/broker_2 (kafka.log.LogManager)\n",
      "[2025-03-10 22:42:53,466] INFO Loaded 0 logs in 16ms (kafka.log.LogManager)\n",
      "[2025-03-10 22:42:53,469] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)\n",
      "[2025-03-10 22:42:53,471] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)\n",
      "[2025-03-10 22:42:53,556] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)\n",
      "[2025-03-10 22:42:53,566] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2025-03-10 22:42:53,573] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)\n",
      "[2025-03-10 22:42:53,590] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:42:53,863] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)\n",
      "[2025-03-10 22:42:53,886] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)\n",
      "[2025-03-10 22:42:53,891] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:42:53,911] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:53,912] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:53,913] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:53,913] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:53,914] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:53,925] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2025-03-10 22:42:53,926] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)\n",
      "[2025-03-10 22:42:53,964] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)\n",
      "[2025-03-10 22:42:53,988] INFO Stat of the created znode at /brokers/ids/2 is: 25,25,1741646573976,1741646573976,1,0,0,72057956847321088,208,0,25\n",
      " (kafka.zk.KafkaZkClient)\n",
      "[2025-03-10 22:42:53,989] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://5a54e50b65a1:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)\n",
      "[2025-03-10 22:42:54,024] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:54,030] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:54,031] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:54,035] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)\n",
      "[2025-03-10 22:42:54,044] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:42:54,054] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:42:54,058] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)\n",
      "[2025-03-10 22:42:54,066] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2025-03-10 22:42:54,071] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2025-03-10 22:42:54,071] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2025-03-10 22:42:54,079] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)\n",
      "[2025-03-10 22:42:54,102] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:42:54,137] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2025-03-10 22:42:54,155] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)\n",
      "[2025-03-10 22:42:54,156] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:42:54,162] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)\n",
      "[2025-03-10 22:42:54,162] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:42:54,166] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:42:54,176] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:54,177] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:54,177] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:54,177] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:54,182] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2025-03-10 22:42:54,182] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2025-03-10 22:42:54,182] INFO Kafka startTimeMs: 1741646574177 (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2025-03-10 22:42:54,184] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:42:54,394] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 5a54e50b65a1:9092 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:42:54,397] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 5a54e50b65a1:9092 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:43:10,033] INFO Creating topic animals-topic-batch-classic-way with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)\n",
      "[2025-03-10 22:43:10,106] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(animals-topic-batch-classic-way-0) (kafka.server.ReplicaFetcherManager)\n",
      "[2025-03-10 22:43:10,147] INFO [LogLoader partition=animals-topic-batch-classic-way-0, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:10,155] INFO Created log for partition animals-topic-batch-classic-way-0 in /usr/local/kafka/data/logs/broker_2/animals-topic-batch-classic-way-0 with properties {} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:10,156] INFO [Partition animals-topic-batch-classic-way-0 broker=2] No checkpointed highwatermark is found for partition animals-topic-batch-classic-way-0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:10,157] INFO [Partition animals-topic-batch-classic-way-0 broker=2] Log loaded for partition animals-topic-batch-classic-way-0 with initial high watermark 0 (kafka.cluster.Partition)\n"
     ]
    }
   ],
   "source": [
    "commands = [\n",
    "    \"/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2.properties\"\n",
    "]\n",
    "\n",
    "execute_commands(commands=commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cc9a0-0b48-4423-a8d5-5a4289337692",
   "metadata": {},
   "source": [
    "# PRODUCE MESSAGES CLASIC WAY\n",
    "### COPY, PASTE, AND RUN THE FOLLOWING CODE IN ANOTHER NOTEBOOK TO OBSERVE STREAMING READING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce26a2-ffbf-48e8-ac7e-237e8ddae262",
   "metadata": {},
   "source": [
    "```python\n",
    "from confluent_kafka import Producer\n",
    "import json\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "\n",
    "def get_dataset():\n",
    "    # Create a sample list with animal data\n",
    "    dataset = [(\"lion\", \"mammal\"), (\"elephant\", \"mammal\"), (\"tiger\", \"feline\"), (\"whale\", \"mammal\"), (\"penguin\", \"bird\"), (\"gorilla\", \"primate\"), (\"leopard\", \"feline\"), (\"crocodile\", \"reptile\"), (\"rhinoceros\", \"mammal\"), \n",
    "            (\"zebra\", \"mammal\"), (\"hippopotamus\", \"mammal\"), (\"eagle\", \"bird\"), (\"orangutan\", \"primate\"), (\"grizzly bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), (\"python\", \"reptile\"), (\"hawk\", \"bird\"), \n",
    "            (\"wolf\", \"mammal\"), (\"tortoise\", \"reptile\"), (\"swan\", \"bird\"), (\"cheetah\", \"feline\"), (\"seagull\", \"bird\"), (\"giraffe\", \"mammal\"), (\"deer\", \"mammal\"), (\"giraffe\", \"mammal\"), (\"lizard\", \"reptile\"), (\"flamingo\", \"bird\"),\n",
    "            (\"chimp\", \"primate\"), (\"buffalo\", \"mammal\"), (\"vulture\", \"bird\"), (\"bear\", \"mammal\"), (\"anaconda\", \"reptile\"), (\"pigeon\", \"bird\"), (\"coyote\", \"mammal\"), (\"chameleon\", \"reptile\"), (\"ostrich\", \"bird\"), (\"jaguar\", \"feline\"), \n",
    "            (\"owl\", \"bird\"), (\"beetle\", \"insect\"), (\"snail\", \"invertebrate\"), (\"octopus\", \"cephalopod\"), (\"lobster\", \"crustacean\"), (\"koala\", \"marsupial\"), (\"crane\", \"bird\"), (\"iguana\", \"reptile\"), (\"lemur\", \"primate\"), (\"sloth\", \"mammal\"), \n",
    "            (\"gazelle\", \"mammal\"), (\"wombat\", \"marsupial\"), (\"hummingbird\", \"bird\"), (\"porcupine\", \"mammal\"), (\"macaw\", \"bird\"), (\"hyena\", \"mammal\"), (\"dolphin\", \"mammal\"), (\"seahorse\", \"fish\"), (\"orca\", \"mammal\"), (\"kangaroo\", \"marsupial\"), \n",
    "            (\"shark\", \"fish\"), (\"beaver\", \"mammal\"), (\"platypus\", \"mammal\"), (\"armadillo\", \"mammal\"), (\"rabbit\", \"mammal\"), (\"camel\", \"mammal\"), (\"squirrel\", \"mammal\"), (\"peacock\", \"bird\"), (\"crow\", \"bird\"), (\"frog\", \"amphibian\"), \n",
    "            (\"toad\", \"amphibian\"), (\"newt\", \"amphibian\"), (\"axolotl\", \"amphibian\"), (\"butterfly\", \"insect\"), (\"dragonfly\", \"insect\"), (\"grasshopper\", \"insect\"), (\"mantis\", \"insect\"), (\"beetle\", \"insect\"), (\"ant\", \"insect\"), (\"termite\", \"insect\"),\n",
    "            (\"spider\", \"arachnid\"), (\"scorpion\", \"arachnid\"), (\"tick\", \"arachnid\"), (\"bee\", \"insect\"), (\"wasp\", \"insect\"), (\"hornet\", \"insect\"), (\"fly\", \"insect\"), (\"mosquito\", \"insect\"), (\"cockroach\", \"insect\"), (\"ladybug\", \"insect\"), \n",
    "            (\"firefly\", \"insect\"), (\"millipede\", \"arthropod\"), (\"centipede\", \"arthropod\"), (\"crab\", \"crustacean\"), (\"shrimp\", \"crustacean\"), (\"barnacle\", \"crustacean\"), (\"clam\", \"mollusk\"), (\"oyster\", \"mollusk\"), (\"mussel\", \"mollusk\"), \n",
    "            (\"snail\", \"mollusk\"), (\"slug\", \"mollusk\"), (\"squid\", \"cephalopod\"), (\"cuttlefish\", \"cephalopod\"), (\"nautilus\", \"cephalopod\"), (\"jellyfish\", \"cnidarian\"), (\"coral\", \"cnidarian\"), (\"hydra\", \"cnidarian\"), (\"anemone\", \"cnidarian\"), \n",
    "            (\"sponge\", \"porifera\"), (\"sea cucumber\", \"echinoderm\"), (\"starfish\", \"echinoderm\"), (\"sand dollar\", \"echinoderm\"), (\"sea urchin\", \"echinoderm\"), (\"brittle star\", \"echinoderm\"), (\"sea star\", \"echinoderm\"), (\"sea lily\", \"echinoderm\"), \n",
    "            (\"feather star\", \"echinoderm\"), (\"black widow\", \"arachnid\"), (\"brown recluse\", \"arachnid\"), (\"tarantula\", \"arachnid\"), (\"daddy longlegs\", \"arachnid\"), (\"wolf spider\", \"arachnid\"), (\"jumping spider\", \"arachnid\"), \n",
    "            (\"huntsman spider\", \"arachnid\"), (\"tarantula hawk\", \"insect\"), (\"assassin bug\", \"insect\"), (\"lacewing\", \"insect\"), (\"stink bug\", \"insect\"), (\"cicada\", \"insect\"), (\"walking stick\", \"insect\"), (\"scorpionfly\", \"insect\"), \n",
    "            (\"flower mantis\", \"insect\"), (\"praying mantis\", \"insect\"), (\"earwig\", \"insect\"), (\"flea\", \"insect\"), (\"leaf insect\", \"insect\"), (\"planthopper\", \"insect\"), (\"scale insect\", \"insect\"), (\"aphid\", \"insect\"), (\"mealybug\", \"insect\"), \n",
    "            (\"thrips\", \"insect\"), (\"whitefly\", \"insect\"), (\"beetle\", \"insect\"), (\"antlion\", \"insect\"), (\"snakefly\", \"insect\"), (\"dobsonfly\", \"insect\"), (\"webspinner\", \"insect\"), (\"mayfly\", \"insect\"), (\"stonefly\", \"insect\"), \n",
    "            (\"silverfish\", \"insect\"), (\"firebrat\", \"insect\"), (\"bristletail\", \"insect\"), (\"thysanuran\", \"insect\"), (\"dragonfly\", \"insect\"), (\"damselfly\", \"insect\"), (\"bluet\", \"insect\"), (\"darner\", \"insect\"), (\"adder\", \"insect\"), \n",
    "            (\"basker\", \"insect\"), (\"biter\", \"insect\"), (\"blister beetle\", \"insect\"), (\"bomber\", \"insect\"), (\"bristle beetle\", \"insect\"), (\"burrower\", \"insect\"), (\"carrier\", \"insect\"), (\"caterpillar\", \"insect\"), (\"chafers\", \"insect\"), \n",
    "            (\"chewer\", \"insect\"), (\"click beetle\", \"insect\"), (\"cobblers\", \"insect\"), (\"cobweb spider\", \"arachnid\"), (\"cockroaches\", \"insect\"), (\"coil worm\", \"insect\"), (\"creeper\", \"insect\"), (\"cuckoo wasp\", \"insect\"), (\"cutworm\", \"insect\"), \n",
    "            (\"digger\", \"insect\"), (\"dor beetle\", \"insect\"), (\"earthworms\", \"insect\"), (\"eggfly\", \"insect\"), (\"elaters\", \"insect\"), (\"emperor\", \"insect\"), (\"gadfly\", \"insect\"), (\"gnat\", \"insect\"), (\"grasshopper\", \"insect\"), (\"grazer\", \"insect\"), \n",
    "            (\"ground beetle\", \"insect\"), (\"harvester\", \"insect\"), (\"hornet\", \"insect\"), (\"hornworm\", \"insect\"), (\"humblebee\", \"insect\"), (\"humpbacked fly\", \"insect\"), (\"hoverfly\", \"insect\"), (\"hunter\", \"insect\"), (\"jumper\", \"insect\"), \n",
    "            (\"katydid\", \"insect\"), (\"lacewing\", \"insect\"), (\"leafcutter\", \"insect\"), (\"leafhopper\", \"insect\"), (\"leafroller\", \"insect\"), (\"louse\", \"insect\"), (\"maggot\", \"insect\"), (\"mantisfly\", \"insect\"), (\"marsh fly\", \"insect\"), \n",
    "            (\"marsh beetle\", \"insect\"), (\"mason wasp\", \"insect\"), (\"mealybug\", \"insect\"), (\"miner\", \"insect\"), (\"mite\", \"insect\"), (\"mole cricket\", \"insect\"), (\"moth\", \"insect\"), (\"nemesis\", \"insect\"), (\"net-winged insect\", \"insect\"), \n",
    "            (\"nightcrawler\", \"insect\"), (\"nit\", \"insect\"), (\"nymph\", \"insect\"), (\"odorous ant\", \"insect\"), (\"oracle\", \"insect\"), (\"orb weaver\", \"arachnid\"), (\"orcus\", \"insect\"), (\"ostracod\", \"insect\"), (\"outlaw\", \"insect\"), \n",
    "            (\"peacock butterfly\", \"insect\"), (\"pharaoh ant\", \"insect\"), (\"pillbug\", \"insect\"), (\"plankton\", \"insect\"), (\"pollinator\", \"insect\"), (\"potter wasp\", \"insect\"), (\"praying mantis\", \"insect\"), (\"predator\", \"insect\"),\n",
    "            (\"proboscis\", \"insect\"), (\"prophet\", \"insect\"), (\"pruner\", \"insect\"), (\"pseudoscorpion\", \"arachnid\"), (\"psycho\", \"insect\"), (\"psycho fly\", \"insect\"), (\"psychodid\", \"insect\"), (\"pupa\", \"insect\"), (\"purple martin\", \"insect\"), \n",
    "            (\"putter\", \"insect\"), (\"ranger\", \"insect\"), (\"recluse\", \"insect\"), (\"reducer\", \"insect\"), (\"repeater\", \"insect\"), (\"riffle bug\", \"insect\"), (\"robber fly\", \"insect\"), (\"rootworm\", \"insect\"), (\"rover\", \"insect\"), (\"saber wasp\", \"insect\"),\n",
    "            (\"sawfly\", \"insect\"), (\"scarab\", \"insect\"), (\"scorpionfly\", \"insect\"), (\"scourge\", \"insect\"), (\"scout\", \"insect\"), (\"scuttle fly\", \"insect\"), (\"silk spinner\", \"insect\"), (\"silverfish\", \"insect\"), (\"skipper butterfly\", \"insect\"), \n",
    "            (\"snout butterfly\", \"insect\"), (\"snout beetle\", \"insect\"), (\"snout moth\", \"insect\"), (\"sow bug\", \"insect\"),(\"spider mite\", \"insect\"), (\"spider wasp\", \"insect\"), (\"sphinx moth\", \"insect\"), (\"spider\", \"arachnid\"), (\"spinner\", \"insect\"),\n",
    "            (\"spittlebug\", \"insect\"), (\"spook\", \"insect\"), (\"springtail\", \"insect\"), (\"stag beetle\", \"insect\"), (\"stealer\", \"insect\"), (\"stinger\", \"insect\"), (\"stink bug\", \"insect\"), (\"stinging ant\", \"insect\"), (\"stonefly\", \"insect\"), \n",
    "            (\"strangler\", \"insect\"), (\"sucking louse\", \"insect\"), (\"sweat bee\", \"insect\"), (\"tailor\", \"insect\"), (\"tanglefoot\", \"insect\"), (\"tarantula\", \"arachnid\"), (\"tarantula hawk\", \"insect\"), (\"tick\", \"arachnid\"), (\"tiger beetle\", \"insect\"), \n",
    "            (\"tiger moth\", \"insect\"), (\"tiphiid wasp\", \"insect\"), (\"titan beetle\", \"insect\"), (\"toad bug\", \"insect\"), (\"torchbearer\", \"insect\"), (\"torpedo bug\", \"insect\"), (\"tortoise beetle\", \"insect\"), (\"trapper\", \"insect\"), \n",
    "            (\"tree cricket\", \"insect\"), (\"trilobite beetle\", \"insect\"), (\"trogonoptera\", \"insect\"), (\"twig borer\", \"insect\"), (\"vampire\", \"insect\"), (\"victorious\", \"insect\"), (\"vinegar fly\", \"insect\"), (\"vine (weevil\", \"insect\"), \n",
    "            (\"wanderer\", \"insect\"), (\"wasps\", \"insect\"), (\"weaver\", \"insect\"), (\"webworm moth\", \"insect\"), (\"weta\", \"insect\"), (\"whirligig beetle\", \"insect\"), (\"whisperer\", \"insect\"), (\"whitefly\", \"insect\"), (\"widow spider\", \"arachnid\"),\n",
    "            (\"willow fly\", \"insect\"), (\"winged ant\", \"insect\"), (\"wood wasp\", \"insect\"), (\"woodworm\", \"insect\"), (\"woolly bear\", \"insect\"), (\"worm\", \"insect\"),(\"wrestler\", \"insect\"), (\"yucca moth\", \"insect\"), (\"zebra butterfly\", \"insect\"),(\"zebra\", \"mammal\"), \n",
    "            (\"koala\", \"marsupial\"), (\"cheetah\", \"feline\"),(\"dolphin\", \"mammal\"),(\"parrot\", \"bird\"), (\"rhino\", \"mammal\"), (\"panda\", \"mammal\"), (\"kangaroo\", \"marsupial\"),(\"panther\", \"feline\"), (\"chimpanzee\", \"primate\"), (\"hippo\", \"mammal\"), (\"eagle\", \"bird\"),\n",
    "            (\"orangutan\", \"primate\"), (\"bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"),(\"snake\", \"reptile\"), (\"hawk\", \"bird\"), (\"fox\", \"mammal\"), (\"turtle\", \"reptile\"), (\"swan\", \"bird\"), (\"jaguar\", \"feline\"), (\"seagull\", \"bird\"), (\"gazelle\", \"mammal\")]\n",
    "    return dataset\n",
    "    \n",
    "def produce_messages(kafka_bootstrap_servers, topic, dataset, iterations=1, empty=0, random_sample=20):\n",
    "    \"\"\"\n",
    "    Generate sample animal data and write it to a Kafka topic.\n",
    "\n",
    "    Args:\n",
    "        kafka_bootstrap_servers (str): Kafka bootstrap servers in the format \"host:port\".\n",
    "        topic (str): Kafka topic to which the data will be written.\n",
    "        iterations (int, optional): Number of iterations to write data. Defaults to 1.\n",
    "        empty (int, optional): Flag to indicate whether to write empty data. Defaults to 0.\n",
    "    \"\"\"\n",
    " \n",
    "    # Kafka Producer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': kafka_bootstrap_servers,\n",
    "    }\n",
    "\n",
    "    # Create Kafka Producer\n",
    "    producer = Producer(conf)\n",
    "\n",
    "    try:\n",
    "        for iteration in range(iterations):\n",
    "            # Select random elements from the data list\n",
    "            selected_data = random.sample(dataset, random_sample)\n",
    "            \n",
    "            # Write data to Kafka\n",
    "            local_timezone = pytz.timezone('America/New_York')  # Set the local timezone\n",
    "            date_created = datetime.now(local_timezone).strftime('%Y-%m-%d %H:%M:%S %Z')  # Get current timestamp in the desired format\n",
    "            for name, animal_type in selected_data:\n",
    "                animal_data = {'name': name, 'type': animal_type, 'iteration': iteration + 1, 'date_created': date_created}\n",
    "                producer.produce(topic, key='Animal', value=json.dumps(animal_data))  # Eliminé .encode('utf-8')\n",
    "            # Print a message indicating that the data has been written to the Kafka topic\n",
    "            print(f\"Iteration {iteration + 1} , Data written to Kafka topic ({topic}).\")    \n",
    "            # delaying seconds for next batch\n",
    "            sleep(iteration %2 + 1)  # Fixed iteration + 1 seconds wait between iterations\n",
    "            \n",
    "        # Flush any remaining messages\n",
    "        producer.flush()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Close the producer\n",
    "        producer.flush()  # Flush any remaining messages before closing\n",
    "        producer.poll(0)  # Poll to handle any message delivery callbacks\n",
    "        del producer\n",
    "\n",
    "# Example usage:\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch-classic-way\"\n",
    "dataset = get_dataset()\n",
    "produce_messages(kafka_bootstrap_servers=kafka_bootstrap_servers, dataset=dataset, topic=topic, iterations=12, random_sample = 27)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da53e17-dd68-442c-80aa-6a723baafea7",
   "metadata": {},
   "source": [
    "# CONSUME MESSAGES CLASIC WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9e5dd5-a233-42e7-afec-ec2a3ab466fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-10 22:43:12,823] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(2), 32 -> ArrayBuffer(2), 41 -> ArrayBuffer(2), 17 -> ArrayBuffer(2), 8 -> ArrayBuffer(2), 35 -> ArrayBuffer(2), 44 -> ArrayBuffer(2), 26 -> ArrayBuffer(2), 11 -> ArrayBuffer(2), 29 -> ArrayBuffer(2), 38 -> ArrayBuffer(2), 47 -> ArrayBuffer(2), 20 -> ArrayBuffer(2), 2 -> ArrayBuffer(2), 5 -> ArrayBuffer(2), 14 -> ArrayBuffer(2), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(2), 27 -> ArrayBuffer(2), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(2), 21 -> ArrayBuffer(2), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(2), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(2), 15 -> ArrayBuffer(2), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(2), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)\n",
      "[2025-03-10 22:43:12,954] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)\n",
      "[2025-03-10 22:43:12,960] INFO [LogLoader partition=__consumer_offsets-0, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:12,961] INFO Created log for partition __consumer_offsets-0 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:12,961] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:12,962] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:12,976] INFO [LogLoader partition=__consumer_offsets-29, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:12,977] INFO Created log for partition __consumer_offsets-29 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:12,977] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:12,977] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:12,992] INFO [LogLoader partition=__consumer_offsets-48, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:12,993] INFO Created log for partition __consumer_offsets-48 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:12,993] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:12,993] INFO [Partition __consumer_offsets-48 broker=2] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,009] INFO [LogLoader partition=__consumer_offsets-10, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,009] INFO Created log for partition __consumer_offsets-10 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,009] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,010] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,025] INFO [LogLoader partition=__consumer_offsets-45, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,026] INFO Created log for partition __consumer_offsets-45 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,026] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,026] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,041] INFO [LogLoader partition=__consumer_offsets-26, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,042] INFO Created log for partition __consumer_offsets-26 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,042] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,042] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,058] INFO [LogLoader partition=__consumer_offsets-7, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,058] INFO Created log for partition __consumer_offsets-7 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,058] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,058] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,074] INFO [LogLoader partition=__consumer_offsets-42, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,074] INFO Created log for partition __consumer_offsets-42 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,075] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,075] INFO [Partition __consumer_offsets-42 broker=2] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,090] INFO [LogLoader partition=__consumer_offsets-4, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,091] INFO Created log for partition __consumer_offsets-4 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,091] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,091] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,105] INFO [LogLoader partition=__consumer_offsets-23, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,106] INFO Created log for partition __consumer_offsets-23 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,106] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,107] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,121] INFO [LogLoader partition=__consumer_offsets-1, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,122] INFO Created log for partition __consumer_offsets-1 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,122] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,122] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,137] INFO [LogLoader partition=__consumer_offsets-20, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,138] INFO Created log for partition __consumer_offsets-20 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,138] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,138] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,157] INFO [LogLoader partition=__consumer_offsets-39, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,157] INFO Created log for partition __consumer_offsets-39 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,158] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,158] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,173] INFO [LogLoader partition=__consumer_offsets-17, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,174] INFO Created log for partition __consumer_offsets-17 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,174] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,174] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,189] INFO [LogLoader partition=__consumer_offsets-36, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,190] INFO Created log for partition __consumer_offsets-36 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,190] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,190] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,204] INFO [LogLoader partition=__consumer_offsets-14, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,205] INFO Created log for partition __consumer_offsets-14 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,205] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,205] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,230] INFO [LogLoader partition=__consumer_offsets-33, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,231] INFO Created log for partition __consumer_offsets-33 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,231] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,231] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,260] INFO [LogLoader partition=__consumer_offsets-49, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,260] INFO Created log for partition __consumer_offsets-49 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,261] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,261] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,276] INFO [LogLoader partition=__consumer_offsets-11, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,276] INFO Created log for partition __consumer_offsets-11 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,277] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,277] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,292] INFO [LogLoader partition=__consumer_offsets-30, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,293] INFO Created log for partition __consumer_offsets-30 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,293] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,293] INFO [Partition __consumer_offsets-30 broker=2] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,308] INFO [LogLoader partition=__consumer_offsets-46, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,309] INFO Created log for partition __consumer_offsets-46 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,309] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,309] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,324] INFO [LogLoader partition=__consumer_offsets-27, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,325] INFO Created log for partition __consumer_offsets-27 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,325] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,325] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,340] INFO [LogLoader partition=__consumer_offsets-8, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,341] INFO Created log for partition __consumer_offsets-8 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,341] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,341] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,356] INFO [LogLoader partition=__consumer_offsets-24, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,357] INFO Created log for partition __consumer_offsets-24 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,357] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,357] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,371] INFO [LogLoader partition=__consumer_offsets-43, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,372] INFO Created log for partition __consumer_offsets-43 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,372] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,372] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,387] INFO [LogLoader partition=__consumer_offsets-5, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,387] INFO Created log for partition __consumer_offsets-5 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,387] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,387] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,402] INFO [LogLoader partition=__consumer_offsets-21, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,403] INFO Created log for partition __consumer_offsets-21 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,403] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,403] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,419] INFO [LogLoader partition=__consumer_offsets-40, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,419] INFO Created log for partition __consumer_offsets-40 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,419] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,420] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,436] INFO [LogLoader partition=__consumer_offsets-2, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,437] INFO Created log for partition __consumer_offsets-2 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,437] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,437] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,452] INFO [LogLoader partition=__consumer_offsets-37, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,453] INFO Created log for partition __consumer_offsets-37 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,453] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,453] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,468] INFO [LogLoader partition=__consumer_offsets-18, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,468] INFO Created log for partition __consumer_offsets-18 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,469] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,469] INFO [Partition __consumer_offsets-18 broker=2] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,484] INFO [LogLoader partition=__consumer_offsets-34, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,484] INFO Created log for partition __consumer_offsets-34 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,485] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,485] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,500] INFO [LogLoader partition=__consumer_offsets-15, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,500] INFO Created log for partition __consumer_offsets-15 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,500] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,500] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,515] INFO [LogLoader partition=__consumer_offsets-12, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,516] INFO Created log for partition __consumer_offsets-12 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,516] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,516] INFO [Partition __consumer_offsets-12 broker=2] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,531] INFO [LogLoader partition=__consumer_offsets-31, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,532] INFO Created log for partition __consumer_offsets-31 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,532] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,532] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,547] INFO [LogLoader partition=__consumer_offsets-9, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,547] INFO Created log for partition __consumer_offsets-9 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,547] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,547] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,563] INFO [LogLoader partition=__consumer_offsets-47, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,563] INFO Created log for partition __consumer_offsets-47 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,564] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,564] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,578] INFO [LogLoader partition=__consumer_offsets-19, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,579] INFO Created log for partition __consumer_offsets-19 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,579] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,579] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,594] INFO [LogLoader partition=__consumer_offsets-28, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,594] INFO Created log for partition __consumer_offsets-28 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,594] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,594] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,609] INFO [LogLoader partition=__consumer_offsets-38, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,609] INFO Created log for partition __consumer_offsets-38 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,609] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,609] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,624] INFO [LogLoader partition=__consumer_offsets-35, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,625] INFO Created log for partition __consumer_offsets-35 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,625] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,626] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,640] INFO [LogLoader partition=__consumer_offsets-6, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,640] INFO Created log for partition __consumer_offsets-6 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,640] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,641] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,655] INFO [LogLoader partition=__consumer_offsets-44, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,655] INFO Created log for partition __consumer_offsets-44 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,655] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,655] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,670] INFO [LogLoader partition=__consumer_offsets-25, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,671] INFO Created log for partition __consumer_offsets-25 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,671] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,671] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,686] INFO [LogLoader partition=__consumer_offsets-16, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,686] INFO Created log for partition __consumer_offsets-16 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,687] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,687] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,702] INFO [LogLoader partition=__consumer_offsets-22, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,702] INFO Created log for partition __consumer_offsets-22 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,702] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,702] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,717] INFO [LogLoader partition=__consumer_offsets-41, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,717] INFO Created log for partition __consumer_offsets-41 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,717] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,717] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,732] INFO [LogLoader partition=__consumer_offsets-32, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,732] INFO Created log for partition __consumer_offsets-32 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,733] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,733] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,747] INFO [LogLoader partition=__consumer_offsets-3, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,747] INFO Created log for partition __consumer_offsets-3 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,747] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,747] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,762] INFO [LogLoader partition=__consumer_offsets-13, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:13,763] INFO Created log for partition __consumer_offsets-13 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:13,763] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,763] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:13,775] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,776] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,777] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,778] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,779] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,781] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,782] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,783] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,783] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,784] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 7 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,784] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,785] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,785] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,785] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,785] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,787] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,787] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,787] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 12 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 13 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 14 milliseconds for epoch 0, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 15 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 15 milliseconds for epoch 0, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2025-03-10 22:43:13,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 14 milliseconds for epoch 0, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "[2025-03-10 22:43:13,884] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group my_consumer_group in Empty state. Created a new member id rdkafka-5814c1bb-b9e2-4a74-9335-e80deb3f38db and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,891] INFO [GroupCoordinator 2]: Preparing to rebalance group my_consumer_group in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member rdkafka-5814c1bb-b9e2-4a74-9335-e80deb3f38db with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,897] INFO [GroupCoordinator 2]: Stabilized group my_consumer_group generation 1 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:13,905] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-5814c1bb-b9e2-4a74-9335-e80deb3f38db for group my_consumer_group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)\n",
      "Batch index: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spittlebug\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"biter\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"slug\", \"type\": \"mollusk\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scuttle fly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wood wasp\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gadfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"yucca moth\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sand dollar\", \"type\": \"echinoderm\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ant\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rhinoceros\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                       Value  \\\n",
       "0        {\"name\": \"spittlebug\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "1             {\"name\": \"biter\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "2             {\"name\": \"slug\", \"type\": \"mollusk\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "3       {\"name\": \"scuttle fly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "4               {\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "5         {\"name\": \"wood wasp\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "6   {\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "7             {\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "8            {\"name\": \"gadfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "9        {\"name\": \"yucca moth\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "10  {\"name\": \"sand dollar\", \"type\": \"echinoderm\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "11       {\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "12       {\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "13              {\"name\": \"ant\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "14       {\"name\": \"rhinoceros\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0       0  2025-03-10 22:43:09  \n",
       "1   animals-topic-batch-classic-way          0       1  2025-03-10 22:43:09  \n",
       "2   animals-topic-batch-classic-way          0       2  2025-03-10 22:43:09  \n",
       "3   animals-topic-batch-classic-way          0       3  2025-03-10 22:43:09  \n",
       "4   animals-topic-batch-classic-way          0       4  2025-03-10 22:43:09  \n",
       "5   animals-topic-batch-classic-way          0       5  2025-03-10 22:43:09  \n",
       "6   animals-topic-batch-classic-way          0       6  2025-03-10 22:43:09  \n",
       "7   animals-topic-batch-classic-way          0       7  2025-03-10 22:43:09  \n",
       "8   animals-topic-batch-classic-way          0       8  2025-03-10 22:43:09  \n",
       "9   animals-topic-batch-classic-way          0       9  2025-03-10 22:43:09  \n",
       "10  animals-topic-batch-classic-way          0      10  2025-03-10 22:43:09  \n",
       "11  animals-topic-batch-classic-way          0      11  2025-03-10 22:43:09  \n",
       "12  animals-topic-batch-classic-way          0      12  2025-03-10 22:43:09  \n",
       "13  animals-topic-batch-classic-way          0      13  2025-03-10 22:43:09  \n",
       "14  animals-topic-batch-classic-way          0      14  2025-03-10 22:43:09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 0\n",
      "\n",
      "Batch index: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rhino\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hornet\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cuttlefish\", \"type\": \"cephalopod\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leaf insect\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra butterfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"penguin\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"earwig\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scale insect\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ground beetle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2025-03-10 22:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rover\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"marsh beetle\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                       Value  \\\n",
       "0             {\"name\": \"rhino\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "1             {\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "2            {\"name\": \"hornet\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "3    {\"name\": \"cuttlefish\", \"type\": \"cephalopod\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "4               {\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "5       {\"name\": \"leaf insect\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "6   {\"name\": \"zebra butterfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "7             {\"name\": \"penguin\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "8            {\"name\": \"earwig\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "9      {\"name\": \"scale insect\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "10         {\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "11    {\"name\": \"ground beetle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2025-03-10 18:43:09 EDT\"}   \n",
       "12        {\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "13            {\"name\": \"rover\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "14     {\"name\": \"marsh beetle\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      15  2025-03-10 22:43:09  \n",
       "1   animals-topic-batch-classic-way          0      16  2025-03-10 22:43:09  \n",
       "2   animals-topic-batch-classic-way          0      17  2025-03-10 22:43:09  \n",
       "3   animals-topic-batch-classic-way          0      18  2025-03-10 22:43:09  \n",
       "4   animals-topic-batch-classic-way          0      19  2025-03-10 22:43:09  \n",
       "5   animals-topic-batch-classic-way          0      20  2025-03-10 22:43:09  \n",
       "6   animals-topic-batch-classic-way          0      21  2025-03-10 22:43:09  \n",
       "7   animals-topic-batch-classic-way          0      22  2025-03-10 22:43:09  \n",
       "8   animals-topic-batch-classic-way          0      23  2025-03-10 22:43:09  \n",
       "9   animals-topic-batch-classic-way          0      24  2025-03-10 22:43:09  \n",
       "10  animals-topic-batch-classic-way          0      25  2025-03-10 22:43:09  \n",
       "11  animals-topic-batch-classic-way          0      26  2025-03-10 22:43:09  \n",
       "12  animals-topic-batch-classic-way          0      27  2025-03-10 22:43:10  \n",
       "13  animals-topic-batch-classic-way          0      28  2025-03-10 22:43:10  \n",
       "14  animals-topic-batch-classic-way          0      29  2025-03-10 22:43:10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 1\n",
      "\n",
      "Batch index: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"woolly bear\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"psycho\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vulture\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ranger\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"toad bug\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sand dollar\", \"type\": \"echinoderm\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ostracod\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snail\", \"type\": \"invertebrate\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scourge\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"brittle star\", \"type\": \"echinoderm\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mason wasp\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"katydid\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider wasp\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0        {\"name\": \"woolly bear\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "1             {\"name\": \"psycho\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "2              {\"name\": \"vulture\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "3             {\"name\": \"ranger\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "4           {\"name\": \"toad bug\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "5    {\"name\": \"sand dollar\", \"type\": \"echinoderm\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "6           {\"name\": \"ostracod\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "7        {\"name\": \"snail\", \"type\": \"invertebrate\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "8          {\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "9            {\"name\": \"scourge\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "10  {\"name\": \"brittle star\", \"type\": \"echinoderm\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "11        {\"name\": \"mason wasp\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "12               {\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "13           {\"name\": \"katydid\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "14       {\"name\": \"spider wasp\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      30  2025-03-10 22:43:10  \n",
       "1   animals-topic-batch-classic-way          0      31  2025-03-10 22:43:10  \n",
       "2   animals-topic-batch-classic-way          0      32  2025-03-10 22:43:10  \n",
       "3   animals-topic-batch-classic-way          0      33  2025-03-10 22:43:10  \n",
       "4   animals-topic-batch-classic-way          0      34  2025-03-10 22:43:10  \n",
       "5   animals-topic-batch-classic-way          0      35  2025-03-10 22:43:10  \n",
       "6   animals-topic-batch-classic-way          0      36  2025-03-10 22:43:10  \n",
       "7   animals-topic-batch-classic-way          0      37  2025-03-10 22:43:10  \n",
       "8   animals-topic-batch-classic-way          0      38  2025-03-10 22:43:10  \n",
       "9   animals-topic-batch-classic-way          0      39  2025-03-10 22:43:10  \n",
       "10  animals-topic-batch-classic-way          0      40  2025-03-10 22:43:10  \n",
       "11  animals-topic-batch-classic-way          0      41  2025-03-10 22:43:10  \n",
       "12  animals-topic-batch-classic-way          0      42  2025-03-10 22:43:10  \n",
       "13  animals-topic-batch-classic-way          0      43  2025-03-10 22:43:10  \n",
       "14  animals-topic-batch-classic-way          0      44  2025-03-10 22:43:10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 2\n",
      "\n",
      "Batch index: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"prophet\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"millipede\", \"type\": \"arthropod\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orcus\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"twig borer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grazer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>2025-03-10 22:43:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wasps\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nautilus\", \"type\": \"cephalopod\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mosquito\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0     {\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "1         {\"name\": \"prophet\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "2    {\"name\": \"millipede\", \"type\": \"arthropod\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "3      {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "4          {\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "5           {\"name\": \"orcus\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "6      {\"name\": \"twig borer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "7             {\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "8          {\"name\": \"grazer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2025-03-10 18:43:10 EDT\"}   \n",
       "9           {\"name\": \"wasps\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "10  {\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "11   {\"name\": \"nautilus\", \"type\": \"cephalopod\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "12        {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "13       {\"name\": \"mosquito\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "14     {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      45  2025-03-10 22:43:10  \n",
       "1   animals-topic-batch-classic-way          0      46  2025-03-10 22:43:10  \n",
       "2   animals-topic-batch-classic-way          0      47  2025-03-10 22:43:10  \n",
       "3   animals-topic-batch-classic-way          0      48  2025-03-10 22:43:10  \n",
       "4   animals-topic-batch-classic-way          0      49  2025-03-10 22:43:10  \n",
       "5   animals-topic-batch-classic-way          0      50  2025-03-10 22:43:10  \n",
       "6   animals-topic-batch-classic-way          0      51  2025-03-10 22:43:10  \n",
       "7   animals-topic-batch-classic-way          0      52  2025-03-10 22:43:10  \n",
       "8   animals-topic-batch-classic-way          0      53  2025-03-10 22:43:10  \n",
       "9   animals-topic-batch-classic-way          0      54  2025-03-10 22:43:12  \n",
       "10  animals-topic-batch-classic-way          0      55  2025-03-10 22:43:12  \n",
       "11  animals-topic-batch-classic-way          0      56  2025-03-10 22:43:12  \n",
       "12  animals-topic-batch-classic-way          0      57  2025-03-10 22:43:12  \n",
       "13  animals-topic-batch-classic-way          0      58  2025-03-10 22:43:12  \n",
       "14  animals-topic-batch-classic-way          0      59  2025-03-10 22:43:12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 3\n",
      "\n",
      "Batch index: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout moth\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea lily\", \"type\": \"echinoderm\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"victorious\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sawfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"squirrel\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cockroaches\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"purple martin\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"winged ant\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dor beetle\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ranger\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0      {\"name\": \"snout moth\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "1      {\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "2    {\"name\": \"sea lily\", \"type\": \"echinoderm\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "3      {\"name\": \"victorious\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "4          {\"name\": \"sawfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "5        {\"name\": \"squirrel\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "6           {\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "7        {\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "8     {\"name\": \"cockroaches\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "9   {\"name\": \"purple martin\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "10     {\"name\": \"winged ant\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "11     {\"name\": \"dor beetle\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "12    {\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "13            {\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "14         {\"name\": \"ranger\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      60  2025-03-10 22:43:12  \n",
       "1   animals-topic-batch-classic-way          0      61  2025-03-10 22:43:12  \n",
       "2   animals-topic-batch-classic-way          0      62  2025-03-10 22:43:12  \n",
       "3   animals-topic-batch-classic-way          0      63  2025-03-10 22:43:12  \n",
       "4   animals-topic-batch-classic-way          0      64  2025-03-10 22:43:12  \n",
       "5   animals-topic-batch-classic-way          0      65  2025-03-10 22:43:12  \n",
       "6   animals-topic-batch-classic-way          0      66  2025-03-10 22:43:12  \n",
       "7   animals-topic-batch-classic-way          0      67  2025-03-10 22:43:12  \n",
       "8   animals-topic-batch-classic-way          0      68  2025-03-10 22:43:12  \n",
       "9   animals-topic-batch-classic-way          0      69  2025-03-10 22:43:12  \n",
       "10  animals-topic-batch-classic-way          0      70  2025-03-10 22:43:12  \n",
       "11  animals-topic-batch-classic-way          0      71  2025-03-10 22:43:12  \n",
       "12  animals-topic-batch-classic-way          0      72  2025-03-10 22:43:12  \n",
       "13  animals-topic-batch-classic-way          0      73  2025-03-10 22:43:12  \n",
       "14  animals-topic-batch-classic-way          0      74  2025-03-10 22:43:12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 4\n",
      "\n",
      "Batch index: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ostracod\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"twig borer\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dragonfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hornworm\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2025-03-10 22:43:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"prophet\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"willow fly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hippo\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"eagle\", \"type\": \"bird\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                       Value  \\\n",
       "0         {\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "1          {\"name\": \"ostracod\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "2        {\"name\": \"twig borer\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "3        {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "4         {\"name\": \"dragonfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "5          {\"name\": \"hornworm\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2025-03-10 18:43:12 EDT\"}   \n",
       "6           {\"name\": \"prophet\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "7        {\"name\": \"willow fly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "8             {\"name\": \"hippo\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "9               {\"name\": \"eagle\", \"type\": \"bird\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "10   {\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "11           {\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "12         {\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "13  {\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "14           {\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      75  2025-03-10 22:43:12  \n",
       "1   animals-topic-batch-classic-way          0      76  2025-03-10 22:43:12  \n",
       "2   animals-topic-batch-classic-way          0      77  2025-03-10 22:43:12  \n",
       "3   animals-topic-batch-classic-way          0      78  2025-03-10 22:43:12  \n",
       "4   animals-topic-batch-classic-way          0      79  2025-03-10 22:43:12  \n",
       "5   animals-topic-batch-classic-way          0      80  2025-03-10 22:43:12  \n",
       "6   animals-topic-batch-classic-way          0      81  2025-03-10 22:43:13  \n",
       "7   animals-topic-batch-classic-way          0      82  2025-03-10 22:43:13  \n",
       "8   animals-topic-batch-classic-way          0      83  2025-03-10 22:43:13  \n",
       "9   animals-topic-batch-classic-way          0      84  2025-03-10 22:43:13  \n",
       "10  animals-topic-batch-classic-way          0      85  2025-03-10 22:43:13  \n",
       "11  animals-topic-batch-classic-way          0      86  2025-03-10 22:43:13  \n",
       "12  animals-topic-batch-classic-way          0      87  2025-03-10 22:43:13  \n",
       "13  animals-topic-batch-classic-way          0      88  2025-03-10 22:43:13  \n",
       "14  animals-topic-batch-classic-way          0      89  2025-03-10 22:43:13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 5\n",
      "\n",
      "Batch index: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ant\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"coral\", \"type\": \"cnidarian\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"worm\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cicada\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scout\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"adder\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea cucumber\", \"type\": \"echinoderm\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"giraffe\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whitefly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rootworm\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stonefly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"torchbearer\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0                {\"name\": \"ant\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "1           {\"name\": \"coral\", \"type\": \"cnidarian\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "2               {\"name\": \"worm\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "3             {\"name\": \"cicada\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "4              {\"name\": \"scout\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "5              {\"name\": \"adder\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "6   {\"name\": \"sea cucumber\", \"type\": \"echinoderm\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "7            {\"name\": \"giraffe\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "8           {\"name\": \"whitefly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "9     {\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "10          {\"name\": \"rootworm\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "11          {\"name\": \"stonefly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "12              {\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "13       {\"name\": \"torchbearer\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "14        {\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      90  2025-03-10 22:43:13  \n",
       "1   animals-topic-batch-classic-way          0      91  2025-03-10 22:43:13  \n",
       "2   animals-topic-batch-classic-way          0      92  2025-03-10 22:43:13  \n",
       "3   animals-topic-batch-classic-way          0      93  2025-03-10 22:43:13  \n",
       "4   animals-topic-batch-classic-way          0      94  2025-03-10 22:43:13  \n",
       "5   animals-topic-batch-classic-way          0      95  2025-03-10 22:43:13  \n",
       "6   animals-topic-batch-classic-way          0      96  2025-03-10 22:43:13  \n",
       "7   animals-topic-batch-classic-way          0      97  2025-03-10 22:43:13  \n",
       "8   animals-topic-batch-classic-way          0      98  2025-03-10 22:43:13  \n",
       "9   animals-topic-batch-classic-way          0      99  2025-03-10 22:43:13  \n",
       "10  animals-topic-batch-classic-way          0     100  2025-03-10 22:43:13  \n",
       "11  animals-topic-batch-classic-way          0     101  2025-03-10 22:43:13  \n",
       "12  animals-topic-batch-classic-way          0     102  2025-03-10 22:43:13  \n",
       "13  animals-topic-batch-classic-way          0     103  2025-03-10 22:43:13  \n",
       "14  animals-topic-batch-classic-way          0     104  2025-03-10 22:43:13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 6\n",
      "\n",
      "Batch index: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leopard\", \"type\": \"feline\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"toad bug\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whisperer\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>2025-03-10 22:43:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scale insect\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snail\", \"type\": \"invertebrate\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dobsonfly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crab\", \"type\": \"crustacean\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gazelle\", \"type\": \"mammal\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stag beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                         Value  \\\n",
       "0             {\"name\": \"leopard\", \"type\": \"feline\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "1            {\"name\": \"toad bug\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "2           {\"name\": \"whisperer\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2025-03-10 18:43:13 EDT\"}   \n",
       "3        {\"name\": \"scale insect\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "4         {\"name\": \"snail\", \"type\": \"invertebrate\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "5           {\"name\": \"dobsonfly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "6            {\"name\": \"crab\", \"type\": \"crustacean\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "7              {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "8             {\"name\": \"gazelle\", \"type\": \"mammal\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "9             {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "10              {\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "11      {\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "12        {\"name\": \"stag beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "13         {\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "14  {\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     105  2025-03-10 22:43:13  \n",
       "1   animals-topic-batch-classic-way          0     106  2025-03-10 22:43:13  \n",
       "2   animals-topic-batch-classic-way          0     107  2025-03-10 22:43:13  \n",
       "3   animals-topic-batch-classic-way          0     108  2025-03-10 22:43:15  \n",
       "4   animals-topic-batch-classic-way          0     109  2025-03-10 22:43:15  \n",
       "5   animals-topic-batch-classic-way          0     110  2025-03-10 22:43:15  \n",
       "6   animals-topic-batch-classic-way          0     111  2025-03-10 22:43:15  \n",
       "7   animals-topic-batch-classic-way          0     112  2025-03-10 22:43:15  \n",
       "8   animals-topic-batch-classic-way          0     113  2025-03-10 22:43:15  \n",
       "9   animals-topic-batch-classic-way          0     114  2025-03-10 22:43:15  \n",
       "10  animals-topic-batch-classic-way          0     115  2025-03-10 22:43:15  \n",
       "11  animals-topic-batch-classic-way          0     116  2025-03-10 22:43:15  \n",
       "12  animals-topic-batch-classic-way          0     117  2025-03-10 22:43:15  \n",
       "13  animals-topic-batch-classic-way          0     118  2025-03-10 22:43:15  \n",
       "14  animals-topic-batch-classic-way          0     119  2025-03-10 22:43:15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 7\n",
      "\n",
      "Batch index: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"webworm moth\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orca\", \"type\": \"mammal\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wasp\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"purple martin\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whale\", \"type\": \"mammal\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"daddy longlegs\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"outlaw\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"webspinner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dragonfly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>2025-03-10 22:43:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0         {\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "1             {\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "2       {\"name\": \"webworm moth\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "3               {\"name\": \"orca\", \"type\": \"mammal\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "4               {\"name\": \"wasp\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "5      {\"name\": \"purple martin\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "6           {\"name\": \"spider\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "7             {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "8          {\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "9             {\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "10             {\"name\": \"whale\", \"type\": \"mammal\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "11  {\"name\": \"daddy longlegs\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "12            {\"name\": \"outlaw\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "13        {\"name\": \"webspinner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "14         {\"name\": \"dragonfly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2025-03-10 18:43:15 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     120  2025-03-10 22:43:15  \n",
       "1   animals-topic-batch-classic-way          0     121  2025-03-10 22:43:15  \n",
       "2   animals-topic-batch-classic-way          0     122  2025-03-10 22:43:15  \n",
       "3   animals-topic-batch-classic-way          0     123  2025-03-10 22:43:15  \n",
       "4   animals-topic-batch-classic-way          0     124  2025-03-10 22:43:15  \n",
       "5   animals-topic-batch-classic-way          0     125  2025-03-10 22:43:15  \n",
       "6   animals-topic-batch-classic-way          0     126  2025-03-10 22:43:15  \n",
       "7   animals-topic-batch-classic-way          0     127  2025-03-10 22:43:15  \n",
       "8   animals-topic-batch-classic-way          0     128  2025-03-10 22:43:15  \n",
       "9   animals-topic-batch-classic-way          0     129  2025-03-10 22:43:15  \n",
       "10  animals-topic-batch-classic-way          0     130  2025-03-10 22:43:15  \n",
       "11  animals-topic-batch-classic-way          0     131  2025-03-10 22:43:15  \n",
       "12  animals-topic-batch-classic-way          0     132  2025-03-10 22:43:15  \n",
       "13  animals-topic-batch-classic-way          0     133  2025-03-10 22:43:15  \n",
       "14  animals-topic-batch-classic-way          0     134  2025-03-10 22:43:15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 8\n",
      "\n",
      "Batch index: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"macaw\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea star\", \"type\": \"echinoderm\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"butterfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"squid\", \"type\": \"cephalopod\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nemesis\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sow bug\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"flamingo\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"torchbearer\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seahorse\", \"type\": \"fish\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tortoise\", \"type\": \"reptile\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silk spinner\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                    Value  \\\n",
       "0            {\"name\": \"macaw\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "1   {\"name\": \"sea star\", \"type\": \"echinoderm\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "2     {\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "3      {\"name\": \"butterfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "4      {\"name\": \"squid\", \"type\": \"cephalopod\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "5        {\"name\": \"nemesis\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "6     {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "7        {\"name\": \"sow bug\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "8         {\"name\": \"flamingo\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "9    {\"name\": \"torchbearer\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "10        {\"name\": \"seahorse\", \"type\": \"fish\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "11          {\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "12     {\"name\": \"tortoise\", \"type\": \"reptile\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "13        {\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "14  {\"name\": \"silk spinner\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     135  2025-03-10 22:43:16  \n",
       "1   animals-topic-batch-classic-way          0     136  2025-03-10 22:43:16  \n",
       "2   animals-topic-batch-classic-way          0     137  2025-03-10 22:43:16  \n",
       "3   animals-topic-batch-classic-way          0     138  2025-03-10 22:43:16  \n",
       "4   animals-topic-batch-classic-way          0     139  2025-03-10 22:43:16  \n",
       "5   animals-topic-batch-classic-way          0     140  2025-03-10 22:43:16  \n",
       "6   animals-topic-batch-classic-way          0     141  2025-03-10 22:43:16  \n",
       "7   animals-topic-batch-classic-way          0     142  2025-03-10 22:43:16  \n",
       "8   animals-topic-batch-classic-way          0     143  2025-03-10 22:43:16  \n",
       "9   animals-topic-batch-classic-way          0     144  2025-03-10 22:43:16  \n",
       "10  animals-topic-batch-classic-way          0     145  2025-03-10 22:43:16  \n",
       "11  animals-topic-batch-classic-way          0     146  2025-03-10 22:43:16  \n",
       "12  animals-topic-batch-classic-way          0     147  2025-03-10 22:43:16  \n",
       "13  animals-topic-batch-classic-way          0     148  2025-03-10 22:43:16  \n",
       "14  animals-topic-batch-classic-way          0     149  2025-03-10 22:43:16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 9\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"elaters\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fox\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"peacock\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"yucca moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bomber\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"thysanuran\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>2025-03-10 22:43:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"flower mantis\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bee\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0         {\"name\": \"elaters\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "1             {\"name\": \"fox\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "2     {\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "3           {\"name\": \"peacock\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "4           {\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "5      {\"name\": \"yucca moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "6          {\"name\": \"bomber\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "7             {\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "8           {\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "9          {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "10       {\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "11     {\"name\": \"thysanuran\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2025-03-10 18:43:16 EDT\"}   \n",
       "12  {\"name\": \"flower mantis\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "13    {\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "14            {\"name\": \"bee\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     150  2025-03-10 22:43:16  \n",
       "1   animals-topic-batch-classic-way          0     151  2025-03-10 22:43:16  \n",
       "2   animals-topic-batch-classic-way          0     152  2025-03-10 22:43:16  \n",
       "3   animals-topic-batch-classic-way          0     153  2025-03-10 22:43:16  \n",
       "4   animals-topic-batch-classic-way          0     154  2025-03-10 22:43:16  \n",
       "5   animals-topic-batch-classic-way          0     155  2025-03-10 22:43:16  \n",
       "6   animals-topic-batch-classic-way          0     156  2025-03-10 22:43:16  \n",
       "7   animals-topic-batch-classic-way          0     157  2025-03-10 22:43:16  \n",
       "8   animals-topic-batch-classic-way          0     158  2025-03-10 22:43:16  \n",
       "9   animals-topic-batch-classic-way          0     159  2025-03-10 22:43:16  \n",
       "10  animals-topic-batch-classic-way          0     160  2025-03-10 22:43:16  \n",
       "11  animals-topic-batch-classic-way          0     161  2025-03-10 22:43:16  \n",
       "12  animals-topic-batch-classic-way          0     162  2025-03-10 22:43:18  \n",
       "13  animals-topic-batch-classic-way          0     163  2025-03-10 22:43:18  \n",
       "14  animals-topic-batch-classic-way          0     164  2025-03-10 22:43:18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 10\n",
      "\n",
      "Batch index: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nautilus\", \"type\": \"cephalopod\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"centipede\", \"type\": \"arthropod\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"torpedo bug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jumper\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hornworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"outlaw\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"darner\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tiger moth\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"polar bear\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout beetle\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"torchbearer\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                    Value  \\\n",
       "0       {\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "1   {\"name\": \"nautilus\", \"type\": \"cephalopod\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "2   {\"name\": \"centipede\", \"type\": \"arthropod\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "3    {\"name\": \"torpedo bug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "4         {\"name\": \"jumper\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "5       {\"name\": \"hornworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "6         {\"name\": \"outlaw\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "7         {\"name\": \"darner\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "8     {\"name\": \"tiger moth\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "9    {\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "10       {\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "11    {\"name\": \"polar bear\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "12    {\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "13  {\"name\": \"snout beetle\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "14   {\"name\": \"torchbearer\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     165  2025-03-10 22:43:18  \n",
       "1   animals-topic-batch-classic-way          0     166  2025-03-10 22:43:18  \n",
       "2   animals-topic-batch-classic-way          0     167  2025-03-10 22:43:18  \n",
       "3   animals-topic-batch-classic-way          0     168  2025-03-10 22:43:18  \n",
       "4   animals-topic-batch-classic-way          0     169  2025-03-10 22:43:18  \n",
       "5   animals-topic-batch-classic-way          0     170  2025-03-10 22:43:18  \n",
       "6   animals-topic-batch-classic-way          0     171  2025-03-10 22:43:18  \n",
       "7   animals-topic-batch-classic-way          0     172  2025-03-10 22:43:18  \n",
       "8   animals-topic-batch-classic-way          0     173  2025-03-10 22:43:18  \n",
       "9   animals-topic-batch-classic-way          0     174  2025-03-10 22:43:18  \n",
       "10  animals-topic-batch-classic-way          0     175  2025-03-10 22:43:18  \n",
       "11  animals-topic-batch-classic-way          0     176  2025-03-10 22:43:18  \n",
       "12  animals-topic-batch-classic-way          0     177  2025-03-10 22:43:18  \n",
       "13  animals-topic-batch-classic-way          0     178  2025-03-10 22:43:18  \n",
       "14  animals-topic-batch-classic-way          0     179  2025-03-10 22:43:18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 11\n",
      "\n",
      "Batch index: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wanderer\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hippopotamus\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beaver\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hummingbird\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"iguana\", \"type\": \"reptile\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea star\", \"type\": \"echinoderm\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>2025-03-10 22:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spittlebug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tortoise beetle\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stinging ant\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"recluse\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"coral\", \"type\": \"cnidarian\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                       Value  \\\n",
       "0          {\"name\": \"wanderer\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "1      {\"name\": \"hippopotamus\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "2      {\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "3            {\"name\": \"beaver\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "4         {\"name\": \"hummingbird\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "5           {\"name\": \"iguana\", \"type\": \"reptile\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "6      {\"name\": \"sea star\", \"type\": \"echinoderm\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "7             {\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "8          {\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2025-03-10 18:43:18 EDT\"}   \n",
       "9        {\"name\": \"spittlebug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "10  {\"name\": \"tortoise beetle\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "11     {\"name\": \"stinging ant\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "12          {\"name\": \"recluse\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "13      {\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "14         {\"name\": \"coral\", \"type\": \"cnidarian\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     180  2025-03-10 22:43:18  \n",
       "1   animals-topic-batch-classic-way          0     181  2025-03-10 22:43:18  \n",
       "2   animals-topic-batch-classic-way          0     182  2025-03-10 22:43:18  \n",
       "3   animals-topic-batch-classic-way          0     183  2025-03-10 22:43:18  \n",
       "4   animals-topic-batch-classic-way          0     184  2025-03-10 22:43:18  \n",
       "5   animals-topic-batch-classic-way          0     185  2025-03-10 22:43:18  \n",
       "6   animals-topic-batch-classic-way          0     186  2025-03-10 22:43:18  \n",
       "7   animals-topic-batch-classic-way          0     187  2025-03-10 22:43:18  \n",
       "8   animals-topic-batch-classic-way          0     188  2025-03-10 22:43:18  \n",
       "9   animals-topic-batch-classic-way          0     189  2025-03-10 22:43:19  \n",
       "10  animals-topic-batch-classic-way          0     190  2025-03-10 22:43:19  \n",
       "11  animals-topic-batch-classic-way          0     191  2025-03-10 22:43:19  \n",
       "12  animals-topic-batch-classic-way          0     192  2025-03-10 22:43:19  \n",
       "13  animals-topic-batch-classic-way          0     193  2025-03-10 22:43:19  \n",
       "14  animals-topic-batch-classic-way          0     194  2025-03-10 22:43:19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 12\n",
      "\n",
      "Batch index: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"squid\", \"type\": \"cephalopod\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wombat\", \"type\": \"marsupial\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"twig borer\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"brittle star\", \"type\": \"echinoderm\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"louse\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scuttle fly\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gorilla\", \"type\": \"primate\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider wasp\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pigeon\", \"type\": \"bird\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea urchin\", \"type\": \"echinoderm\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0          {\"name\": \"squid\", \"type\": \"cephalopod\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "1          {\"name\": \"wombat\", \"type\": \"marsupial\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "2         {\"name\": \"twig borer\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "3   {\"name\": \"brittle star\", \"type\": \"echinoderm\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "4         {\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "5         {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "6              {\"name\": \"louse\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "7        {\"name\": \"scuttle fly\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "8           {\"name\": \"gorilla\", \"type\": \"primate\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "9                  {\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "10       {\"name\": \"spider wasp\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "11              {\"name\": \"pigeon\", \"type\": \"bird\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "12    {\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "13        {\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "14    {\"name\": \"sea urchin\", \"type\": \"echinoderm\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     195  2025-03-10 22:43:19  \n",
       "1   animals-topic-batch-classic-way          0     196  2025-03-10 22:43:19  \n",
       "2   animals-topic-batch-classic-way          0     197  2025-03-10 22:43:19  \n",
       "3   animals-topic-batch-classic-way          0     198  2025-03-10 22:43:19  \n",
       "4   animals-topic-batch-classic-way          0     199  2025-03-10 22:43:19  \n",
       "5   animals-topic-batch-classic-way          0     200  2025-03-10 22:43:19  \n",
       "6   animals-topic-batch-classic-way          0     201  2025-03-10 22:43:19  \n",
       "7   animals-topic-batch-classic-way          0     202  2025-03-10 22:43:19  \n",
       "8   animals-topic-batch-classic-way          0     203  2025-03-10 22:43:19  \n",
       "9   animals-topic-batch-classic-way          0     204  2025-03-10 22:43:19  \n",
       "10  animals-topic-batch-classic-way          0     205  2025-03-10 22:43:19  \n",
       "11  animals-topic-batch-classic-way          0     206  2025-03-10 22:43:19  \n",
       "12  animals-topic-batch-classic-way          0     207  2025-03-10 22:43:19  \n",
       "13  animals-topic-batch-classic-way          0     208  2025-03-10 22:43:19  \n",
       "14  animals-topic-batch-classic-way          0     209  2025-03-10 22:43:19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 13\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"putter\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gazelle\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"earwig\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>2025-03-10 22:43:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ground beetle\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pruner\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nightcrawler\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"coyote\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snakefly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nemesis\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pillbug\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0          {\"name\": \"putter\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "1         {\"name\": \"gazelle\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "2           {\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "3         {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "4       {\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "5          {\"name\": \"earwig\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2025-03-10 18:43:19 EDT\"}   \n",
       "6   {\"name\": \"ground beetle\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "7          {\"name\": \"pruner\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "8          {\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "9    {\"name\": \"nightcrawler\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "10         {\"name\": \"coyote\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "11    {\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "12       {\"name\": \"snakefly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "13        {\"name\": \"nemesis\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "14        {\"name\": \"pillbug\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     210  2025-03-10 22:43:19  \n",
       "1   animals-topic-batch-classic-way          0     211  2025-03-10 22:43:19  \n",
       "2   animals-topic-batch-classic-way          0     212  2025-03-10 22:43:19  \n",
       "3   animals-topic-batch-classic-way          0     213  2025-03-10 22:43:19  \n",
       "4   animals-topic-batch-classic-way          0     214  2025-03-10 22:43:19  \n",
       "5   animals-topic-batch-classic-way          0     215  2025-03-10 22:43:19  \n",
       "6   animals-topic-batch-classic-way          0     216  2025-03-10 22:43:21  \n",
       "7   animals-topic-batch-classic-way          0     217  2025-03-10 22:43:21  \n",
       "8   animals-topic-batch-classic-way          0     218  2025-03-10 22:43:21  \n",
       "9   animals-topic-batch-classic-way          0     219  2025-03-10 22:43:21  \n",
       "10  animals-topic-batch-classic-way          0     220  2025-03-10 22:43:21  \n",
       "11  animals-topic-batch-classic-way          0     221  2025-03-10 22:43:21  \n",
       "12  animals-topic-batch-classic-way          0     222  2025-03-10 22:43:21  \n",
       "13  animals-topic-batch-classic-way          0     223  2025-03-10 22:43:21  \n",
       "14  animals-topic-batch-classic-way          0     224  2025-03-10 22:43:21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 14\n",
      "\n",
      "Batch index: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"louse\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ostrich\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"firefly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grazer\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hornworm\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"torpedo bug\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"predator\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"oyster\", \"type\": \"mollusk\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                    Value  \\\n",
       "0   {\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "1          {\"name\": \"louse\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "2    {\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "3         {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "4      {\"name\": \"marsh fly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "5          {\"name\": \"ostrich\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "6        {\"name\": \"firefly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "7         {\"name\": \"grazer\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "8        {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "9       {\"name\": \"hornworm\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "10          {\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "11   {\"name\": \"torpedo bug\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "12      {\"name\": \"predator\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "13       {\"name\": \"oyster\", \"type\": \"mollusk\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "14         {\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     225  2025-03-10 22:43:21  \n",
       "1   animals-topic-batch-classic-way          0     226  2025-03-10 22:43:21  \n",
       "2   animals-topic-batch-classic-way          0     227  2025-03-10 22:43:21  \n",
       "3   animals-topic-batch-classic-way          0     228  2025-03-10 22:43:21  \n",
       "4   animals-topic-batch-classic-way          0     229  2025-03-10 22:43:21  \n",
       "5   animals-topic-batch-classic-way          0     230  2025-03-10 22:43:21  \n",
       "6   animals-topic-batch-classic-way          0     231  2025-03-10 22:43:21  \n",
       "7   animals-topic-batch-classic-way          0     232  2025-03-10 22:43:21  \n",
       "8   animals-topic-batch-classic-way          0     233  2025-03-10 22:43:21  \n",
       "9   animals-topic-batch-classic-way          0     234  2025-03-10 22:43:21  \n",
       "10  animals-topic-batch-classic-way          0     235  2025-03-10 22:43:21  \n",
       "11  animals-topic-batch-classic-way          0     236  2025-03-10 22:43:21  \n",
       "12  animals-topic-batch-classic-way          0     237  2025-03-10 22:43:21  \n",
       "13  animals-topic-batch-classic-way          0     238  2025-03-10 22:43:21  \n",
       "14  animals-topic-batch-classic-way          0     239  2025-03-10 22:43:21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 15\n",
      "\n",
      "Batch index: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"trogonoptera\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>2025-03-10 22:43:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"oracle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"axolotl\", \"type\": \"amphibian\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"peacock\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider mite\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orcus\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ostrich\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0           {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "1   {\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "2     {\"name\": \"trogonoptera\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2025-03-10 18:43:21 EDT\"}   \n",
       "3          {\"name\": \"oracle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "4      {\"name\": \"axolotl\", \"type\": \"amphibian\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "5           {\"name\": \"peacock\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "6          {\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "7     {\"name\": \"spider mite\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "8          {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "9        {\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "10          {\"name\": \"orcus\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "11             {\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "12     {\"name\": \"crocodile\", \"type\": \"reptile\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "13          {\"name\": \"ostrich\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "14         {\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     240  2025-03-10 22:43:21  \n",
       "1   animals-topic-batch-classic-way          0     241  2025-03-10 22:43:21  \n",
       "2   animals-topic-batch-classic-way          0     242  2025-03-10 22:43:21  \n",
       "3   animals-topic-batch-classic-way          0     243  2025-03-10 22:43:22  \n",
       "4   animals-topic-batch-classic-way          0     244  2025-03-10 22:43:22  \n",
       "5   animals-topic-batch-classic-way          0     245  2025-03-10 22:43:22  \n",
       "6   animals-topic-batch-classic-way          0     246  2025-03-10 22:43:22  \n",
       "7   animals-topic-batch-classic-way          0     247  2025-03-10 22:43:22  \n",
       "8   animals-topic-batch-classic-way          0     248  2025-03-10 22:43:22  \n",
       "9   animals-topic-batch-classic-way          0     249  2025-03-10 22:43:22  \n",
       "10  animals-topic-batch-classic-way          0     250  2025-03-10 22:43:22  \n",
       "11  animals-topic-batch-classic-way          0     251  2025-03-10 22:43:22  \n",
       "12  animals-topic-batch-classic-way          0     252  2025-03-10 22:43:22  \n",
       "13  animals-topic-batch-classic-way          0     253  2025-03-10 22:43:22  \n",
       "14  animals-topic-batch-classic-way          0     254  2025-03-10 22:43:22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 16\n",
      "\n",
      "Batch index: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"skipper butterfly\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scorpion\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"huntsman spider\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"coyote\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fox\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"recluse\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grizzly bear\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"winged ant\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jumper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chimp\", \"type\": \"primate\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>2025-03-10 22:43:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                          Value  \\\n",
       "0   {\"name\": \"skipper butterfly\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "1          {\"name\": \"scorpion\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "2   {\"name\": \"huntsman spider\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "3              {\"name\": \"coyote\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "4                 {\"name\": \"fox\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "5             {\"name\": \"recluse\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "6              {\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "7        {\"name\": \"grizzly bear\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "8          {\"name\": \"winged ant\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "9          {\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "10             {\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "11             {\"name\": \"jumper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "12            {\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "13             {\"name\": \"chimp\", \"type\": \"primate\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "14        {\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2025-03-10 18:43:22 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     255  2025-03-10 22:43:22  \n",
       "1   animals-topic-batch-classic-way          0     256  2025-03-10 22:43:22  \n",
       "2   animals-topic-batch-classic-way          0     257  2025-03-10 22:43:22  \n",
       "3   animals-topic-batch-classic-way          0     258  2025-03-10 22:43:22  \n",
       "4   animals-topic-batch-classic-way          0     259  2025-03-10 22:43:22  \n",
       "5   animals-topic-batch-classic-way          0     260  2025-03-10 22:43:22  \n",
       "6   animals-topic-batch-classic-way          0     261  2025-03-10 22:43:22  \n",
       "7   animals-topic-batch-classic-way          0     262  2025-03-10 22:43:22  \n",
       "8   animals-topic-batch-classic-way          0     263  2025-03-10 22:43:22  \n",
       "9   animals-topic-batch-classic-way          0     264  2025-03-10 22:43:22  \n",
       "10  animals-topic-batch-classic-way          0     265  2025-03-10 22:43:22  \n",
       "11  animals-topic-batch-classic-way          0     266  2025-03-10 22:43:22  \n",
       "12  animals-topic-batch-classic-way          0     267  2025-03-10 22:43:22  \n",
       "13  animals-topic-batch-classic-way          0     268  2025-03-10 22:43:22  \n",
       "14  animals-topic-batch-classic-way          0     269  2025-03-10 22:43:22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 17\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tree cricket\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra butterfly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"black widow\", \"type\": \"arachnid\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"biter\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bristle beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chafers\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"porcupine\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hoverfly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"predator\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chimp\", \"type\": \"primate\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0      {\"name\": \"tree cricket\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "1             {\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "2   {\"name\": \"zebra butterfly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "3     {\"name\": \"black widow\", \"type\": \"arachnid\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "4             {\"name\": \"biter\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "5    {\"name\": \"bristle beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "6       {\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "7           {\"name\": \"chafers\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "8            {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "9         {\"name\": \"porcupine\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "10       {\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "11         {\"name\": \"hoverfly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "12          {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "13         {\"name\": \"predator\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "14           {\"name\": \"chimp\", \"type\": \"primate\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     270  2025-03-10 22:43:24  \n",
       "1   animals-topic-batch-classic-way          0     271  2025-03-10 22:43:24  \n",
       "2   animals-topic-batch-classic-way          0     272  2025-03-10 22:43:24  \n",
       "3   animals-topic-batch-classic-way          0     273  2025-03-10 22:43:24  \n",
       "4   animals-topic-batch-classic-way          0     274  2025-03-10 22:43:24  \n",
       "5   animals-topic-batch-classic-way          0     275  2025-03-10 22:43:24  \n",
       "6   animals-topic-batch-classic-way          0     276  2025-03-10 22:43:24  \n",
       "7   animals-topic-batch-classic-way          0     277  2025-03-10 22:43:24  \n",
       "8   animals-topic-batch-classic-way          0     278  2025-03-10 22:43:24  \n",
       "9   animals-topic-batch-classic-way          0     279  2025-03-10 22:43:24  \n",
       "10  animals-topic-batch-classic-way          0     280  2025-03-10 22:43:24  \n",
       "11  animals-topic-batch-classic-way          0     281  2025-03-10 22:43:24  \n",
       "12  animals-topic-batch-classic-way          0     282  2025-03-10 22:43:24  \n",
       "13  animals-topic-batch-classic-way          0     283  2025-03-10 22:43:24  \n",
       "14  animals-topic-batch-classic-way          0     284  2025-03-10 22:43:24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 18\n",
      "\n",
      "Batch index: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"humpbacked fly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"outlaw\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cobblers\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dor beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"brittle star\", \"type\": \"echinoderm\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"caterpillar\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stealer\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>2025-03-10 22:43:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pruner\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider wasp\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                         Value  \\\n",
       "0     {\"name\": \"humpbacked fly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "1              {\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "2             {\"name\": \"outlaw\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "3              {\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "4           {\"name\": \"cobblers\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "5         {\"name\": \"dor beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "6   {\"name\": \"brittle star\", \"type\": \"echinoderm\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "7     {\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "8        {\"name\": \"caterpillar\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "9            {\"name\": \"stealer\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "10       {\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "11            {\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 11, \"date_created\": \"2025-03-10 18:43:24 EDT\"}   \n",
       "12            {\"name\": \"pruner\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "13       {\"name\": \"spider wasp\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "14        {\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     285  2025-03-10 22:43:24  \n",
       "1   animals-topic-batch-classic-way          0     286  2025-03-10 22:43:24  \n",
       "2   animals-topic-batch-classic-way          0     287  2025-03-10 22:43:24  \n",
       "3   animals-topic-batch-classic-way          0     288  2025-03-10 22:43:24  \n",
       "4   animals-topic-batch-classic-way          0     289  2025-03-10 22:43:24  \n",
       "5   animals-topic-batch-classic-way          0     290  2025-03-10 22:43:24  \n",
       "6   animals-topic-batch-classic-way          0     291  2025-03-10 22:43:24  \n",
       "7   animals-topic-batch-classic-way          0     292  2025-03-10 22:43:24  \n",
       "8   animals-topic-batch-classic-way          0     293  2025-03-10 22:43:24  \n",
       "9   animals-topic-batch-classic-way          0     294  2025-03-10 22:43:24  \n",
       "10  animals-topic-batch-classic-way          0     295  2025-03-10 22:43:24  \n",
       "11  animals-topic-batch-classic-way          0     296  2025-03-10 22:43:24  \n",
       "12  animals-topic-batch-classic-way          0     297  2025-03-10 22:43:25  \n",
       "13  animals-topic-batch-classic-way          0     298  2025-03-10 22:43:25  \n",
       "14  animals-topic-batch-classic-way          0     299  2025-03-10 22:43:25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 19\n",
      "\n",
      "Batch index: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"weaver\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"psycho fly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scout\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"springtail\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"clam\", \"type\": \"mollusk\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"purple martin\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"giraffe\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sponge\", \"type\": \"porifera\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"deer\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0          {\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "1          {\"name\": \"weaver\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "2      {\"name\": \"psycho fly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "3           {\"name\": \"scout\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "4      {\"name\": \"springtail\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "5           {\"name\": \"clam\", \"type\": \"mollusk\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "6   {\"name\": \"purple martin\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "7          {\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "8         {\"name\": \"giraffe\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "9          {\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "10           {\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "11        {\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "12            {\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "13       {\"name\": \"sponge\", \"type\": \"porifera\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "14           {\"name\": \"deer\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     300  2025-03-10 22:43:25  \n",
       "1   animals-topic-batch-classic-way          0     301  2025-03-10 22:43:25  \n",
       "2   animals-topic-batch-classic-way          0     302  2025-03-10 22:43:25  \n",
       "3   animals-topic-batch-classic-way          0     303  2025-03-10 22:43:25  \n",
       "4   animals-topic-batch-classic-way          0     304  2025-03-10 22:43:25  \n",
       "5   animals-topic-batch-classic-way          0     305  2025-03-10 22:43:25  \n",
       "6   animals-topic-batch-classic-way          0     306  2025-03-10 22:43:25  \n",
       "7   animals-topic-batch-classic-way          0     307  2025-03-10 22:43:25  \n",
       "8   animals-topic-batch-classic-way          0     308  2025-03-10 22:43:25  \n",
       "9   animals-topic-batch-classic-way          0     309  2025-03-10 22:43:25  \n",
       "10  animals-topic-batch-classic-way          0     310  2025-03-10 22:43:25  \n",
       "11  animals-topic-batch-classic-way          0     311  2025-03-10 22:43:25  \n",
       "12  animals-topic-batch-classic-way          0     312  2025-03-10 22:43:25  \n",
       "13  animals-topic-batch-classic-way          0     313  2025-03-10 22:43:25  \n",
       "14  animals-topic-batch-classic-way          0     314  2025-03-10 22:43:25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 20\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Producer will disconnect due to inactivity in 8 Seconds.\n",
      "Producer will disconnect due to inactivity in 7 Seconds.\n",
      "Producer will disconnect due to inactivity in 6 Seconds.\n",
      "Producer will disconnect due to inactivity in 5 Seconds.\n",
      "Producer will disconnect due to inactivity in 4 Seconds.\n",
      "Producer will disconnect due to inactivity in 3 Seconds.\n",
      "Producer will disconnect due to inactivity in 2 Seconds.\n",
      "Producer will disconnect due to inactivity in 1 Seconds.\n",
      "Producer will disconnect due to inactivity in 0 Seconds.\n",
      "No new messages received in the last 10 seconds. Returning the current batch.\n",
      "Batch index: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"louse\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orb weaver\", \"type\": \"arachnid\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seahorse\", \"type\": \"fish\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nit\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"basker\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orcus\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>2025-03-10 22:43:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Key  \\\n",
       "0  Animal   \n",
       "1  Animal   \n",
       "2  Animal   \n",
       "3  Animal   \n",
       "4  Animal   \n",
       "5  Animal   \n",
       "6  Animal   \n",
       "7  Animal   \n",
       "8  Animal   \n",
       "\n",
       "                                                                                                       Value  \\\n",
       "0       {\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "1  {\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "2            {\"name\": \"louse\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "3     {\"name\": \"orb weaver\", \"type\": \"arachnid\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "4           {\"name\": \"seahorse\", \"type\": \"fish\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "5              {\"name\": \"nit\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "6           {\"name\": \"basker\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "7               {\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "8            {\"name\": \"orcus\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2025-03-10 18:43:25 EDT\"}   \n",
       "\n",
       "                             Topic  Partition  Offset            Timestamp  \n",
       "0  animals-topic-batch-classic-way          0     315  2025-03-10 22:43:25  \n",
       "1  animals-topic-batch-classic-way          0     316  2025-03-10 22:43:25  \n",
       "2  animals-topic-batch-classic-way          0     317  2025-03-10 22:43:25  \n",
       "3  animals-topic-batch-classic-way          0     318  2025-03-10 22:43:25  \n",
       "4  animals-topic-batch-classic-way          0     319  2025-03-10 22:43:25  \n",
       "5  animals-topic-batch-classic-way          0     320  2025-03-10 22:43:25  \n",
       "6  animals-topic-batch-classic-way          0     321  2025-03-10 22:43:25  \n",
       "7  animals-topic-batch-classic-way          0     322  2025-03-10 22:43:25  \n",
       "8  animals-topic-batch-classic-way          0     323  2025-03-10 22:43:25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 21\n",
      "\n",
      "Producer will disconnect due to inactivity in -1 Seconds.\n",
      "No new messages received in the last 10 seconds. Returning the current batch.\n",
      "[2025-03-10 22:43:36,079] INFO [GroupCoordinator 2]: Preparing to rebalance group my_consumer_group in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: Removing member rdkafka-5814c1bb-b9e2-4a74-9335-e80deb3f38db on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:36,079] INFO [GroupCoordinator 2]: Group my_consumer_group with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:43:36,081] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-5814c1bb-b9e2-4a74-9335-e80deb3f38db, groupInstanceId=None, clientId=rdkafka, clientHost=/172.17.0.2, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, roundrobin)) has left group my_consumer_group through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "def consume_messages(kafka_bootstrap_servers, topic, batch_size=20, timeout=10):\n",
    "    \"\"\"\n",
    "    Consume messages from a Kafka topic in batches and return them as a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        kafka_bootstrap_servers (str): Kafka bootstrap servers in the format \"host:port\".\n",
    "        topic (str): Kafka topic from which to consume messages.\n",
    "        batch_size (int): Size of each batch of messages to return as a DataFrame. Defaults to 20.\n",
    "        timeout (int): Maximum time to wait for new messages (in seconds) before returning the current batch. Defaults to 10 seconds.\n",
    "\n",
    "    Yields:\n",
    "        pandas.DataFrame: DataFrame containing the consumed batch of messages.\n",
    "\n",
    "    Raises:\n",
    "        KeyboardInterrupt: Raised when the consumer is stopped by the user (e.g., through keyboard interrupt).\n",
    "    \"\"\"\n",
    "    # Consumer configuration\n",
    "    conf = {\n",
    "        \"bootstrap.servers\": kafka_bootstrap_servers,  # Kafka bootstrap servers\n",
    "        \"group.id\": \"my_consumer_group\",  # Consumer group ID\n",
    "        \"auto.offset.reset\": \"earliest\",  # Set the starting offset to the earliest available\n",
    "    }\n",
    "\n",
    "    # Create consumer\n",
    "    consumer = Consumer(conf)\n",
    "\n",
    "    # Subscribe to the topic\n",
    "    consumer.subscribe([topic])\n",
    "\n",
    "    # List to store messages for each batch\n",
    "    messages = []\n",
    "\n",
    "    # Time tracking for timeout\n",
    "    last_message_time = time.time()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Wait for messages\n",
    "            msg = consumer.poll(1.0)\n",
    "\n",
    "            # Check if the timeout has been reached\n",
    "            time_limit = time.time() - last_message_time\n",
    "\n",
    "            # If no message received within the poll timeout\n",
    "            if msg is None:\n",
    "                print(\n",
    "                    f\"Producer will disconnect due to inactivity in {ceil(timeout - time_limit)} Seconds.\"\n",
    "                )\n",
    "                # If timeout exceeded, return the current batch\n",
    "                if time_limit > timeout:\n",
    "                    print(\n",
    "                        f\"No new messages received in the last {timeout} seconds. Returning the current batch.\"\n",
    "                    )\n",
    "                    if messages:\n",
    "                        # Convert the list of messages into a pandas DataFrame\n",
    "                        df = pd.DataFrame(messages)\n",
    "                        # Yield the DataFrame\n",
    "                        yield df\n",
    "                        # Clear the messages list for the next batch\n",
    "                        messages = []\n",
    "                    # If no messages received on timeout, break the loop\n",
    "                    else:\n",
    "                        break\n",
    "                continue\n",
    "\n",
    "            # Update last message time\n",
    "            last_message_time = time.time()\n",
    "\n",
    "            # Handle Kafka errors\n",
    "            if msg.error():\n",
    "                # If end of partition, continue with the next one\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    continue\n",
    "                else:\n",
    "                    # Otherwise, print the error and break the loop\n",
    "                    print(f\"Error receiving message: {msg.error()}\")\n",
    "                    break\n",
    "\n",
    "            # Decode the received value as JSON\n",
    "            try:\n",
    "                message = {\n",
    "                    \"Key\": msg.key().decode(\"utf-8\"),\n",
    "                    \"Value\": msg.value().decode(\"utf-8\"),\n",
    "                    \"Topic\": msg.topic(),\n",
    "                    \"Partition\": msg.partition(),\n",
    "                    \"Offset\": msg.offset(),\n",
    "                    \"Timestamp\": datetime.utcfromtimestamp(\n",
    "                        msg.timestamp()[1] / 1000\n",
    "                    ).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                }\n",
    "                messages.append(message)\n",
    "            except Exception as e:\n",
    "                # Print error if decoding fails\n",
    "                print(f\"Error processing message: {e}\")\n",
    "\n",
    "            # Check if the batch size has been reached\n",
    "            if len(messages) == batch_size:\n",
    "                # Convert the list of messages into a pandas DataFrame\n",
    "                df = pd.DataFrame(messages)\n",
    "                # Yield the DataFrame\n",
    "                yield df\n",
    "                # Clear the messages list for the next batch\n",
    "                messages = []\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # If KeyboardInterrupt occurs, print message and stop the consumer\n",
    "        print(\"Stopping the consumer...\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer\n",
    "        consumer.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch-classic-way\"\n",
    "\n",
    "for index, batch_df in enumerate(\n",
    "    consume_messages(kafka_bootstrap_servers, topic, batch_size=15)\n",
    "):\n",
    "    print(f\"Batch index:\", index)\n",
    "    display(batch_df)  # Display the batch DataFrame\n",
    "    # Perform operations on the batch DataFrame\n",
    "    print(f\"End Preprocessing batch {index}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043b562-ce26-4f1b-a291-4ef32c295555",
   "metadata": {},
   "source": [
    "# <center> SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072390a7-8284-4012-a43a-54d48ea249c3",
   "metadata": {},
   "source": [
    "# ANIMALS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f7b6c4-b8d0-44c2-b1cf-5ba74cb78a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    # Create a sample list with animal data\n",
    "    dataset = [\n",
    "        (\"lion\", \"mammal\"), (\"elephant\", \"mammal\"), (\"tiger\", \"feline\"), (\"whale\", \"mammal\"), (\"penguin\", \"bird\"), (\"gorilla\", \"primate\"), (\"leopard\", \"feline\"),\n",
    "        (\"crocodile\", \"reptile\"), (\"rhinoceros\", \"mammal\"), (\"zebra\", \"mammal\"), (\"hippopotamus\", \"mammal\"), (\"eagle\", \"bird\"), (\"orangutan\", \"primate\"),\n",
    "        (\"grizzly bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), (\"python\", \"reptile\"), (\"hawk\", \"bird\"), (\"wolf\", \"mammal\"), (\"tortoise\", \"reptile\"),\n",
    "        (\"swan\", \"bird\"), (\"cheetah\", \"feline\"), (\"seagull\", \"bird\"), (\"giraffe\", \"mammal\"), (\"deer\", \"mammal\"), (\"giraffe\", \"mammal\"), (\"lizard\", \"reptile\"),\n",
    "        (\"flamingo\", \"bird\"), (\"chimp\", \"primate\"), (\"buffalo\", \"mammal\"), (\"vulture\", \"bird\"), (\"bear\", \"mammal\"), (\"anaconda\", \"reptile\"), (\"pigeon\", \"bird\"),\n",
    "        (\"coyote\", \"mammal\"), (\"chameleon\", \"reptile\"), (\"ostrich\", \"bird\"), (\"jaguar\", \"feline\"), (\"owl\", \"bird\"), (\"beetle\", \"insect\"), (\"snail\", \"invertebrate\"),\n",
    "        (\"octopus\", \"cephalopod\"), (\"lobster\", \"crustacean\"), (\"koala\", \"marsupial\"), (\"crane\", \"bird\"), (\"iguana\", \"reptile\"), (\"lemur\", \"primate\"), (\"sloth\", \"mammal\"),\n",
    "        (\"gazelle\", \"mammal\"), (\"wombat\", \"marsupial\"), (\"hummingbird\", \"bird\"), (\"porcupine\", \"mammal\"), (\"macaw\", \"bird\"), (\"hyena\", \"mammal\"), (\"dolphin\", \"mammal\"),\n",
    "        (\"seahorse\", \"fish\"), (\"orca\", \"mammal\"), (\"kangaroo\", \"marsupial\"), (\"shark\", \"fish\"), (\"beaver\", \"mammal\"), (\"platypus\", \"mammal\"), (\"armadillo\", \"mammal\"),\n",
    "        (\"rabbit\", \"mammal\"), (\"camel\", \"mammal\"), (\"squirrel\", \"mammal\"), (\"peacock\", \"bird\"), (\"crow\", \"bird\"), (\"frog\", \"amphibian\"), (\"toad\", \"amphibian\"),\n",
    "        (\"newt\", \"amphibian\"), (\"axolotl\", \"amphibian\"), (\"butterfly\", \"insect\"), (\"dragonfly\", \"insect\"), (\"grasshopper\", \"insect\"), (\"mantis\", \"insect\"),\n",
    "        (\"beetle\", \"insect\"), (\"ant\", \"insect\"), (\"termite\", \"insect\"), (\"spider\", \"arachnid\"), (\"scorpion\", \"arachnid\"), (\"tick\", \"arachnid\"), (\"bee\", \"insect\"),\n",
    "        (\"wasp\", \"insect\"), (\"hornet\", \"insect\"), (\"fly\", \"insect\"), (\"mosquito\", \"insect\"), (\"cockroach\", \"insect\"), (\"ladybug\", \"insect\"), (\"firefly\", \"insect\"),\n",
    "        (\"millipede\", \"arthropod\"), (\"centipede\", \"arthropod\"), (\"crab\", \"crustacean\"), (\"shrimp\", \"crustacean\"), (\"barnacle\", \"crustacean\"), (\"clam\", \"mollusk\"),\n",
    "        (\"oyster\", \"mollusk\"), (\"mussel\", \"mollusk\"), (\"snail\", \"mollusk\"), (\"slug\", \"mollusk\"), (\"squid\", \"cephalopod\"), (\"cuttlefish\", \"cephalopod\"), (\"nautilus\", \"cephalopod\"),\n",
    "        (\"jellyfish\", \"cnidarian\"), (\"coral\", \"cnidarian\"), (\"hydra\", \"cnidarian\"), (\"anemone\", \"cnidarian\"), (\"sponge\", \"porifera\"), (\"sea cucumber\", \"echinoderm\"),\n",
    "        (\"starfish\", \"echinoderm\"), (\"sand dollar\", \"echinoderm\"), (\"sea urchin\", \"echinoderm\"), (\"brittle star\", \"echinoderm\"), (\"sea star\", \"echinoderm\"), (\"sea lily\", \"echinoderm\"),\n",
    "        (\"feather star\", \"echinoderm\"), (\"black widow\", \"arachnid\"), (\"brown recluse\", \"arachnid\"), (\"tarantula\", \"arachnid\"), (\"daddy longlegs\", \"arachnid\"),\n",
    "        (\"wolf spider\", \"arachnid\"), (\"jumping spider\", \"arachnid\"), (\"huntsman spider\", \"arachnid\"), (\"tarantula hawk\", \"insect\"), (\"assassin bug\", \"insect\"),\n",
    "        (\"lacewing\", \"insect\"), (\"stink bug\", \"insect\"), (\"cicada\", \"insect\"), (\"walking stick\", \"insect\"), (\"scorpionfly\", \"insect\"), (\"flower mantis\", \"insect\"),\n",
    "        (\"praying mantis\", \"insect\"), (\"earwig\", \"insect\"), (\"flea\", \"insect\"), (\"leaf insect\", \"insect\"), (\"planthopper\", \"insect\"), (\"scale insect\", \"insect\"),\n",
    "        (\"aphid\", \"insect\"), (\"mealybug\", \"insect\"), (\"thrips\", \"insect\"), (\"whitefly\", \"insect\"), (\"beetle\", \"insect\"), (\"antlion\", \"insect\"), (\"snakefly\", \"insect\"),\n",
    "        (\"dobsonfly\", \"insect\"), (\"webspinner\", \"insect\"), (\"mayfly\", \"insect\"), (\"stonefly\", \"insect\"), (\"silverfish\", \"insect\"), (\"firebrat\", \"insect\"),\n",
    "        (\"bristletail\", \"insect\"), (\"thysanuran\", \"insect\"), (\"dragonfly\", \"insect\"), (\"damselfly\", \"insect\"), (\"bluet\", \"insect\"), (\"darner\", \"insect\"),\n",
    "        (\"adder\", \"insect\"), (\"basker\", \"insect\"), (\"biter\", \"insect\"), (\"blister beetle\", \"insect\"), (\"bomber\", \"insect\"), (\"bristle beetle\", \"insect\"),\n",
    "        (\"burrower\", \"insect\"), (\"carrier\", \"insect\"), (\"caterpillar\", \"insect\"), (\"chafers\", \"insect\"), (\"chewer\", \"insect\"), (\"click beetle\", \"insect\"),\n",
    "        (\"cobblers\", \"insect\"), (\"cobweb spider\", \"arachnid\"), (\"cockroaches\", \"insect\"), (\"coil worm\", \"insect\"), (\"creeper\", \"insect\"), (\"cuckoo wasp\", \"insect\"),\n",
    "        (\"cutworm\", \"insect\"), (\"digger\", \"insect\"), (\"dor beetle\", \"insect\"), (\"earthworms\", \"insect\"), (\"eggfly\", \"insect\"), (\"elaters\", \"insect\"),\n",
    "        (\"emperor\", \"insect\"), (\"gadfly\", \"insect\"), (\"gnat\", \"insect\"), (\"grasshopper\", \"insect\"), (\"grazer\", \"insect\"), (\"ground beetle\", \"insect\"),\n",
    "        (\"harvester\", \"insect\"), (\"hornet\", \"insect\"), (\"hornworm\", \"insect\"), (\"humblebee\", \"insect\"), (\"humpbacked fly\", \"insect\"), (\"hoverfly\", \"insect\"),\n",
    "        (\"hunter\", \"insect\"), (\"jumper\", \"insect\"), (\"katydid\", \"insect\"), (\"lacewing\", \"insect\"), (\"leafcutter\", \"insect\"), (\"leafhopper\", \"insect\"),\n",
    "        (\"leafroller\", \"insect\"), (\"louse\", \"insect\"), (\"maggot\", \"insect\"), (\"mantisfly\", \"insect\"), (\"marsh fly\", \"insect\"), (\"marsh beetle\", \"insect\"),\n",
    "        (\"mason wasp\", \"insect\"), (\"mealybug\", \"insect\"), (\"miner\", \"insect\"), (\"mite\", \"insect\"), (\"mole cricket\", \"insect\"), (\"moth\", \"insect\"),\n",
    "        (\"nemesis\", \"insect\"), (\"net-winged insect\", \"insect\"), (\"nightcrawler\", \"insect\"), (\"nit\", \"insect\"), (\"nymph\", \"insect\"), (\"odorous ant\", \"insect\"),\n",
    "        (\"oracle\", \"insect\"), (\"orb weaver\", \"arachnid\"), (\"orcus\", \"insect\"), (\"ostracod\", \"insect\"), (\"outlaw\", \"insect\"), (\"peacock butterfly\", \"insect\"),\n",
    "        (\"pharaoh ant\", \"insect\"), (\"pillbug\", \"insect\"), (\"plankton\", \"insect\"), (\"pollinator\", \"insect\"), (\"potter wasp\", \"insect\"), (\"praying mantis\", \"insect\"),\n",
    "        (\"predator\", \"insect\"), (\"proboscis\", \"insect\"), (\"prophet\", \"insect\"), (\"pruner\", \"insect\"), (\"pseudoscorpion\", \"arachnid\"), (\"psycho\", \"insect\"),\n",
    "        (\"psycho fly\", \"insect\"), (\"psychodid\", \"insect\"), (\"pupa\", \"insect\"), (\"purple martin\", \"insect\"), (\"putter\", \"insect\"), (\"ranger\", \"insect\"),\n",
    "        (\"recluse\", \"insect\"), (\"reducer\", \"insect\"), (\"repeater\", \"insect\"), (\"riffle bug\", \"insect\"), (\"robber fly\", \"insect\"), (\"rootworm\", \"insect\"),\n",
    "        (\"rover\", \"insect\"), (\"saber wasp\", \"insect\"), (\"sawfly\", \"insect\"), (\"scarab\", \"insect\"), (\"scorpionfly\", \"insect\"), (\"scourge\", \"insect\"),\n",
    "        (\"scout\", \"insect\"), (\"scuttle fly\", \"insect\"), (\"silk spinner\", \"insect\"), (\"silverfish\", \"insect\"), (\"skipper butterfly\", \"insect\"), (\"snout butterfly\", \"insect\"),\n",
    "        (\"snout beetle\", \"insect\"), (\"snout moth\", \"insect\"), (\"sow bug\", \"insect\"), (\"spider mite\", \"insect\"), (\"spider wasp\", \"insect\"), (\"sphinx moth\", \"insect\"),\n",
    "        (\"spider\", \"arachnid\"), (\"spinner\", \"insect\"), (\"spittlebug\", \"insect\"), (\"spook\", \"insect\"), (\"springtail\", \"insect\"), (\"stag beetle\", \"insect\"),\n",
    "        (\"stealer\", \"insect\"), (\"stinger\", \"insect\"), (\"stink bug\", \"insect\"), (\"stinging ant\", \"insect\"), (\"stonefly\", \"insect\"), (\"strangler\", \"insect\"),\n",
    "        (\"sucking louse\", \"insect\"), (\"sweat bee\", \"insect\"), (\"tailor\", \"insect\"), (\"tanglefoot\", \"insect\"), (\"tarantula\", \"arachnid\"), (\"tarantula hawk\", \"insect\"),\n",
    "        (\"tick\", \"arachnid\"), (\"tiger beetle\", \"insect\"), (\"tiger moth\", \"insect\"), (\"tiphiid wasp\", \"insect\"), (\"titan beetle\", \"insect\"), (\"toad bug\", \"insect\"),\n",
    "        (\"torchbearer\", \"insect\"), (\"torpedo bug\", \"insect\"), (\"tortoise beetle\", \"insect\"), (\"trapper\", \"insect\"), (\"tree cricket\", \"insect\"), (\"trilobite beetle\", \"insect\"),\n",
    "        (\"trogonoptera\", \"insect\"), (\"twig borer\", \"insect\"), (\"vampire\", \"insect\"), (\"victorious\", \"insect\"), (\"vinegar fly\", \"insect\"), (\"vine (weevil\", \"insect\"),\n",
    "        (\"wanderer\", \"insect\"), (\"wasps\", \"insect\"), (\"weaver\", \"insect\"), (\"webworm moth\", \"insect\"), (\"weta\", \"insect\"), (\"whirligig beetle\", \"insect\"),\n",
    "        (\"whisperer\", \"insect\"), (\"whitefly\", \"insect\"), (\"widow spider\", \"arachnid\"), (\"willow fly\", \"insect\"), (\"winged ant\", \"insect\"), (\"wood wasp\", \"insect\"),\n",
    "        (\"woodworm\", \"insect\"), (\"woolly bear\", \"insect\"), (\"worm\", \"insect\"), (\"wrestler\", \"insect\"), (\"yucca moth\", \"insect\"), (\"zebra butterfly\", \"insect\"),\n",
    "        (\"zebra\", \"mammal\"), (\"koala\", \"marsupial\"), (\"cheetah\", \"feline\"), (\"dolphin\", \"mammal\"), (\"parrot\", \"bird\"), (\"rhino\", \"mammal\"), (\"panda\", \"mammal\"),\n",
    "        (\"kangaroo\", \"marsupial\"), (\"panther\", \"feline\"), (\"chimpanzee\", \"primate\"), (\"hippo\", \"mammal\"), (\"eagle\", \"bird\"), (\"orangutan\", \"primate\"),\n",
    "        (\"bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), (\"snake\", \"reptile\"), (\"hawk\", \"bird\"), (\"fox\", \"mammal\"), (\"turtle\", \"reptile\"),\n",
    "        (\"swan\", \"bird\"), (\"jaguar\", \"feline\"), (\"seagull\", \"bird\"), (\"gazelle\", \"mammal\"),\n",
    "    ]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfb762-517f-4751-9d95-470531a78e84",
   "metadata": {},
   "source": [
    "# DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cf8395-7cce-4af4-8f47-4aa0e30f4cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:43:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Directory where JARs are located\n",
    "jars_directory = \"/usr/local/spark/jars/\"\n",
    "\n",
    "# List of JAR filenames\n",
    "jar_files = [\n",
    "    \"commons-pool2-2.12.0.jar\",\n",
    "    \"kafka-clients-3.9.0.jar\",\n",
    "    \"spark-sql-kafka-0-10_2.12-3.5.5.jar\",\n",
    "    \"spark-token-provider-kafka-0-10_2.12-3.5.5.jar\",\n",
    "]\n",
    "\n",
    "dependencies = \",\".join([os.path.join(jars_directory, jar) for jar in jar_files])\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch\"\n",
    "\n",
    "# Create Spark session and add JARs\n",
    "spark_session = (\n",
    "    SparkSession.builder.appName(\"WriteKafkaAnimals\")\n",
    "    .config(\"spark.jars\", dependencies)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e05947-be49-4ba6-a986-3f20fe11babe",
   "metadata": {},
   "source": [
    "# BATCH WRITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f14306-a6e2-48c6-8fe8-7926efd1ff2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                        (0 + 16) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-10 22:43:43,977] INFO Creating topic animals-topic-batch with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)\n",
      "[2025-03-10 22:43:44,014] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(animals-topic-batch-0) (kafka.server.ReplicaFetcherManager)\n",
      "[2025-03-10 22:43:44,018] INFO [LogLoader partition=animals-topic-batch-0, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2025-03-10 22:43:44,018] INFO Created log for partition animals-topic-batch-0 in /usr/local/kafka/data/logs/broker_2/animals-topic-batch-0 with properties {} (kafka.log.LogManager)\n",
      "[2025-03-10 22:43:44,020] INFO [Partition animals-topic-batch-0 broker=2] No checkpointed highwatermark is found for partition animals-topic-batch-0 (kafka.cluster.Partition)\n",
      "[2025-03-10 22:43:44,020] INFO [Partition animals-topic-batch-0 broker=2] Log loaded for partition animals-topic-batch-0 with initial high watermark 0 (kafka.cluster.Partition)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:43:44 WARN NetworkClient: [Producer clientId=producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 1 : {animals-topic-batch=LEADER_NOT_AVAILABLE}\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 2 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 3 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 4 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 5 , Data written to Kafka topic (animals-topic-batch).\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "import pytz\n",
    "\n",
    "\n",
    "# Function to save batch data to a Kafka topic\n",
    "def save_batch_data(\n",
    "    spark_session,\n",
    "    kafka_bootstrap_servers,\n",
    "    dataset,\n",
    "    topic,\n",
    "    iterations=1,\n",
    "    empty=0,\n",
    "    random_sample=20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save batch data to a Kafka topic.\n",
    "\n",
    "    Args:\n",
    "        spark_session (SparkSession): Spark session object.\n",
    "        kafka_bootstrap_servers (str): Kafka bootstrap servers in the format \"host:port\".\n",
    "        dataset (list): List of tuples containing data to be written to Kafka.\n",
    "        topic (str): Kafka topic to which the data will be written.\n",
    "        iterations (int, optional): Number of iterations to run. Defaults to 1.\n",
    "        empty (int, optional): Placeholder for future use. Defaults to 0.\n",
    "        random_sample (int, optional): Number of random samples to select from the dataset for each iteration. Defaults to 20.\n",
    "    \"\"\"\n",
    "    # Define the columns for the DataFrame\n",
    "    columns = [\"topic_name\", \"name\", \"animal_type\", \"iteration\", \"date_created\"]\n",
    "\n",
    "    # Iterate through the specified number of iterations\n",
    "    for iteration in range(iterations):\n",
    "        # Select random elements from the dataset\n",
    "        selected_data = random.sample(dataset, random_sample)\n",
    "\n",
    "        # Write data to Kafka\n",
    "        local_timezone = pytz.timezone(\"America/New_York\")  # Set the local timezone\n",
    "        date_created = datetime.now(local_timezone).strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S %Z\"\n",
    "        )  # Get the current timestamp in the desired format\n",
    "\n",
    "        values = list()\n",
    "\n",
    "        # Create a list of tuples with animal data and other metadata\n",
    "        for name, animal_type in selected_data:\n",
    "            animal_data = (\"Animal\", name, animal_type, iteration + 1, date_created)\n",
    "            values.append(animal_data)\n",
    "\n",
    "        # Create a Spark DataFrame from the values and columns\n",
    "        df_animals = spark_session.createDataFrame(values, columns)\n",
    "\n",
    "        # Write the DataFrame to the Kafka topic\n",
    "        df_animals.selectExpr(\n",
    "            \"topic_name as key\",\n",
    "            \"to_json(struct(name, animal_type, iteration, date_created)) as value\",\n",
    "        ).write.format(\"kafka\").option(\n",
    "            \"kafka.bootstrap.servers\", kafka_bootstrap_servers\n",
    "        ).option(\n",
    "            \"topic\", topic\n",
    "        ).save()\n",
    "\n",
    "        # Print a message indicating that the data has been written to the Kafka topic\n",
    "        print(f\"Iteration {iteration + 1} , Data written to Kafka topic ({topic}).\")\n",
    "\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch\"\n",
    "dataset = get_dataset()\n",
    "save_batch_data(\n",
    "    spark_session=spark_session,\n",
    "    kafka_bootstrap_servers=kafka_bootstrap_servers,\n",
    "    dataset=dataset,\n",
    "    topic=topic,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18600232-19bf-42b8-a191-a096ba535b08",
   "metadata": {},
   "source": [
    "# BATCH READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc3e9cb-e24c-4366-a0da-27cb057aba45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:43:47 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------------------------------------+-------------------+---------+------+-----------------------+-------------+\n",
      "|key   |value                                                                                                    |topic              |partition|offset|timestamp              |timestampType|\n",
      "+------+---------------------------------------------------------------------------------------------------------+-------------------+---------+------+-----------------------+-------------+\n",
      "|Animal|{\"name\":\"vampire\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}         |animals-topic-batch|0        |0     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"saber wasp\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}      |animals-topic-batch|0        |1     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"crow\",\"animal_type\":\"bird\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}              |animals-topic-batch|0        |2     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"toad bug\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}        |animals-topic-batch|0        |3     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"wolf spider\",\"animal_type\":\"arachnid\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}   |animals-topic-batch|0        |4     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"psycho\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}          |animals-topic-batch|0        |5     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"strangler\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}       |animals-topic-batch|0        |6     |2025-03-10 22:43:44.119|0            |\n",
      "|Animal|{\"name\":\"tick\",\"animal_type\":\"arachnid\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}          |animals-topic-batch|0        |7     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"tarantula hawk\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}  |animals-topic-batch|0        |8     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"seagull\",\"animal_type\":\"bird\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}           |animals-topic-batch|0        |9     |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"pupa\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}            |animals-topic-batch|0        |10    |2025-03-10 22:43:44.119|0            |\n",
      "|Animal|{\"name\":\"digger\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}          |animals-topic-batch|0        |11    |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"louse\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}           |animals-topic-batch|0        |12    |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"tailor\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}          |animals-topic-batch|0        |13    |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"mealybug\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}        |animals-topic-batch|0        |14    |2025-03-10 22:43:44.119|0            |\n",
      "|Animal|{\"name\":\"twig borer\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}      |animals-topic-batch|0        |15    |2025-03-10 22:43:44.118|0            |\n",
      "|Animal|{\"name\":\"hippo\",\"animal_type\":\"mammal\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}           |animals-topic-batch|0        |16    |2025-03-10 22:43:44.134|0            |\n",
      "|Animal|{\"name\":\"whirligig beetle\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}|animals-topic-batch|0        |17    |2025-03-10 22:43:44.131|0            |\n",
      "|Animal|{\"name\":\"gnat\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}            |animals-topic-batch|0        |18    |2025-03-10 22:43:44.13 |0            |\n",
      "|Animal|{\"name\":\"scout\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2025-03-10 18:43:40 EDT\"}           |animals-topic-batch|0        |19    |2025-03-10 22:43:44.13 |0            |\n",
      "+------+---------------------------------------------------------------------------------------------------------+-------------------+---------+------+-----------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:48 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "25/03/10 22:43:52 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "# Define the hexadecimal decoding function\n",
    "@udf(returnType=StringType())\n",
    "def decode_hex(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            return bytes.fromhex(value).decode(\"utf-8\")\n",
    "        elif isinstance(value, bytearray):\n",
    "            return bytes(value).decode(\"utf-8\")\n",
    "        else:\n",
    "            return str(value)\n",
    "    except (ValueError, UnicodeDecodeError):\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "def read_batch_data(spark_session, kafka_bootstrap_servers, topic):\n",
    "\n",
    "    # Try to read data from Kafka\n",
    "    try:\n",
    "        # Read data from Kafka\n",
    "        df_kafka = (\n",
    "            spark_session.read.format(\"kafka\")\n",
    "            .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "            .option(\"subscribe\", topic)\n",
    "            .load()\n",
    "        )\n",
    "\n",
    "        # Decode hexadecimal values\n",
    "        df_decoded = df_kafka.withColumn(\"key\", decode_hex(\"key\")).withColumn(\n",
    "            \"value\", decode_hex(\"value\")\n",
    "        )\n",
    "\n",
    "        # Show the DataFrame with decoded data\n",
    "        df_decoded.show(truncate=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"UnknownTopicOrPartitionException\" in str(e):\n",
    "            print(f\"The topic '{topic}' does not exist in the Kafka cluster.\")\n",
    "        else:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Stop the Spark session\n",
    "        None\n",
    "\n",
    "\n",
    "topic = \"animals-topic-batch\"\n",
    "read_batch_data(spark_session, kafka_bootstrap_servers, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a48a04-8cb8-460b-b9dd-d1b1e601dff6",
   "metadata": {},
   "source": [
    "# STREAMING WRITING\n",
    "## MASSIVE DATA INSERTION TO KAFKA FOR STREAMING READ\n",
    "### COPY, PASTE, AND RUN THE FOLLOWING CODE IN ANOTHER NOTEBOOK TO OBSERVE STREAMING READING, AND EXECUTE THE NEXT 2 CELLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c759bab-bb0c-4279-8602-b24a5a6281c6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from time import sleep\n",
    "\n",
    "# Directory where JARs are located\n",
    "jars_directory = \"/usr/local/spark/jars/\"\n",
    "\n",
    "# List of JAR filenames\n",
    "jar_files = [\n",
    "    \"commons-pool2-2.12.0.jar\",\n",
    "    \"kafka-clients-3.9.0.jar\",\n",
    "    \"spark-sql-kafka-0-10_2.12-3.5.3.jar\",\n",
    "    \"spark-token-provider-kafka-0-10_2.12-3.5.3.jar\"\n",
    "]\n",
    "\n",
    "dependencies = \",\".join([os.path.join(jars_directory, jar) for jar in jar_files])\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch\"\n",
    "\n",
    "\n",
    "# Create Spark session and add JARs\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"WriteKafkaAnimals\") \\\n",
    "    .config(\"spark.jars\", dependencies) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "def save_batch_data(spark_session, kafka_bootstrap_servers, topic, iterations=1):\n",
    "\n",
    "    # Create a sample DataFrame with animal data\n",
    "    data = [(\"zebra\", \"mammal\"), (\"koala\", \"marsupial\"), (\"cheetah\", \"feline\"),(\"dolphin\", \"mammal\"),\n",
    "            (\"parrot\", \"bird\"), (\"rhino\", \"mammal\"), (\"panda\", \"mammal\"), (\"kangaroo\", \"marsupial\"), \n",
    "            (\"panther\", \"feline\"), (\"chimpanzee\", \"primate\"), (\"hippo\", \"mammal\"), (\"eagle\", \"bird\"), \n",
    "            (\"orangutan\", \"primate\"), (\"bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), \n",
    "            (\"snake\", \"reptile\"), (\"hawk\", \"bird\"), (\"fox\", \"mammal\"), (\"turtle\", \"reptile\"), \n",
    "            (\"swan\", \"bird\"), (\"jaguar\", \"feline\"), (\"seagull\", \"bird\"), (\"gazelle\", \"mammal\")]\n",
    "    \n",
    "    columns = [\"name\", \"type\"]\n",
    "    \n",
    "    df_animals = spark_session.createDataFrame(data, columns)\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        sleep(0.2)\n",
    "        # Write the DataFrame to Kafka topic\n",
    "        df_animals.selectExpr(\"name as key\", \"type as value\") \\\n",
    "            .write \\\n",
    "            .format(\"kafka\") \\\n",
    "            .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "            .option(\"topic\", topic) \\\n",
    "            .save()\n",
    "        print (f'Iteration {iteration}, completed!!!')\n",
    "    \n",
    "    # Print a message indicating that the data has been written to the Kafka topic\n",
    "    print(f\"{iterations} Iterations, Data written to Kafka topic ({topic}).\")\n",
    "\n",
    "     # Finally, stop the Spark session\n",
    "    spark_session.stop()\n",
    "\n",
    "save_batch_data(spark_session, kafka_bootstrap_servers, topic, iterations=13)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3268fa8-9fa5-49d3-87fd-d7db3c28bf07",
   "metadata": {},
   "source": [
    "# STREAMING READING\n",
    "## IT WILL BE LISTENING TO THE \"animals-topic-batch\" TOPIC\n",
    "## WHEN NEW DATA ARRIVES, IT READS AND STORES THEM IN THE \"animals-topic-streaming\" TOPIC\n",
    "## MAKE THE TRANSFORMATIONS\n",
    "### UPPER CASE, PROCCESS ROW BY ROW, USE UDF FUNCTION AND SEND PARAMETERS, CREATE PANDAS DATAFRAME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09ea76d-2f8b-4917-afe6-214f1da52d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:44:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "25/03/10 22:44:36 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafkaStream <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "transformedStream <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "query <class 'pyspark.sql.streaming.query.StreamingQuery'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:44:36 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/03/10 22:44:36 WARN StreamingQueryManager: Stopping existing streaming query [id=946a67a1-0b56-42e3-9217-bbd5acd60888, runId=8a4fcb75-ec5f-4209-b1ef-3a1212048d78], as a new run is being started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"VAMPIRE\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"SABER WASP\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"CROW\",\"ANIMAL_TYPE\":\"BIRD\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"TOAD BUG\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"WOLF SPIDER\",\"ANIMAL_TYPE\":\"ARACHNID\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"PRAYING MANTIS\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"COCKROACH\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"SPIDER WASP\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"POTTER WASP\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"CAMEL\",\"ANIMAL_TYPE\":\"MAMMAL\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "..     ...   \n",
       "95  Animal   \n",
       "96  Animal   \n",
       "97  Animal   \n",
       "98  Animal   \n",
       "99  Animal   \n",
       "\n",
       "                                                                                                      value  \\\n",
       "0          {\"NAME\":\"VAMPIRE\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}   \n",
       "1       {\"NAME\":\"SABER WASP\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}   \n",
       "2               {\"NAME\":\"CROW\",\"ANIMAL_TYPE\":\"BIRD\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}   \n",
       "3         {\"NAME\":\"TOAD BUG\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}   \n",
       "4    {\"NAME\":\"WOLF SPIDER\",\"ANIMAL_TYPE\":\"ARACHNID\",\"ITERATION\":1,\"DATE_CREATED\":\"2025-03-10 18:43:40 EDT\"}   \n",
       "..                                                                                                      ...   \n",
       "95  {\"NAME\":\"PRAYING MANTIS\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}   \n",
       "96       {\"NAME\":\"COCKROACH\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}   \n",
       "97     {\"NAME\":\"SPIDER WASP\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}   \n",
       "98     {\"NAME\":\"POTTER WASP\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}   \n",
       "99           {\"NAME\":\"CAMEL\",\"ANIMAL_TYPE\":\"MAMMAL\",\"ITERATION\":5,\"DATE_CREATED\":\"2025-03-10 18:43:45 EDT\"}   \n",
       "\n",
       "            input_topic             output_topic  \\\n",
       "0   animals-topic-batch  animals-topic-streaming   \n",
       "1   animals-topic-batch  animals-topic-streaming   \n",
       "2   animals-topic-batch  animals-topic-streaming   \n",
       "3   animals-topic-batch  animals-topic-streaming   \n",
       "4   animals-topic-batch  animals-topic-streaming   \n",
       "..                  ...                      ...   \n",
       "95  animals-topic-batch  animals-topic-streaming   \n",
       "96  animals-topic-batch  animals-topic-streaming   \n",
       "97  animals-topic-batch  animals-topic-streaming   \n",
       "98  animals-topic-batch  animals-topic-streaming   \n",
       "99  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "..                               ...                          ...  \n",
       "95  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "96  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "97  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "98  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "99  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing microbatch 0 at 2025_03_10_22_44_52\n",
      "+--------+-------------------+---------------------+----------------+-------------+----------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price|total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+----------------+------------------+----------------+\n",
      "|0       |2025_03_10_22_44_52|NULL                 | \\\"crustacean\\\")|NULL         |NULL            |NULL              |3               |\n",
      "|0       |2025_03_10_22_44_52|NULL                 | \\\"reptile\\\")   |NULL         |NULL            |NULL              |3               |\n",
      "|0       |2025_03_10_22_44_52|NULL                 | \\\"arachnid\\\")  |NULL         |NULL            |NULL              |5               |\n",
      "|0       |2025_03_10_22_44_52|NULL                 | \\\"mammal\\\")    |NULL         |NULL            |NULL              |6               |\n",
      "|0       |2025_03_10_22_44_52|NULL                 |NULL            |NULL         |NULL            |NULL              |7               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+----------------+------------------+----------------+\n",
      "\n",
      "+----+-----------+-------+--------------+--------------+---------------+------------+------------+--------------+----------------+-----------+--------+--------------+-------------+-------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+----------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|secure_code|airline|departure_city|departure_date|arrival_airport|arrival_city|arrival_time|passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+-----------+-------+--------------+--------------+---------------+------------+------------+--------------+----------------+-----------+--------+--------------+-------------+-------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+----------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2025_03_10_22_44_52|\n",
      "+----+-----------+-------+--------------+--------------+---------------+------------+------------+--------------+----------------+-----------+--------+--------------+-------------+-------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+----------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 1 at 2025_03_10_22_45_10\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|1       |2025_03_10_22_45_10|Brazil               |Male            |53           |690.0966666666667 |2070.29           |3               |\n",
      "|1       |2025_03_10_22_45_10|Brazil               |Male            |56           |353.31333333333333|1059.94           |3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Female          |47           |666.9266666666666 |2000.78           |3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Female          |68           |91.99333333333334 |275.98            |3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |35           |270.90000000000003|812.7             |3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |57           |653.4266666666667 |1960.2800000000002|3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |30           |450.3299999999999 |1350.9899999999998|3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |56           |479.7666666666667 |1439.3000000000002|3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |45           |273.32666666666665|819.98            |3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |21           |474.1233333333333 |1422.37           |3               |\n",
      "|1       |2025_03_10_22_45_10|Indonesia            |Female          |20           |500.2833333333333 |1500.85           |3               |\n",
      "|1       |2025_03_10_22_45_10|Indonesia            |Female          |82           |525.33            |1575.99           |3               |\n",
      "|1       |2025_03_10_22_45_10|Indonesia            |Male            |41           |538.02            |1614.06           |3               |\n",
      "|1       |2025_03_10_22_45_10|Philippines          |Female          |93           |460.9166666666667 |1382.75           |3               |\n",
      "|1       |2025_03_10_22_45_10|China                |Female          |72           |511.3875          |2045.55           |4               |\n",
      "|1       |2025_03_10_22_45_10|China                |Female          |87           |554.2025          |2216.81           |4               |\n",
      "|1       |2025_03_10_22_45_10|China                |Female          |69           |347.235           |1388.94           |4               |\n",
      "|1       |2025_03_10_22_45_10|China                |Male            |34           |414.83250000000004|1659.3300000000002|4               |\n",
      "|1       |2025_03_10_22_45_10|Indonesia            |Male            |52           |560.5999999999999 |2242.3999999999996|4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+---+--------------------+--------+-------------------+--------------+---------------+-----------------+----------------+--------------------+----------------+-----------+--------+--------------+-------------+--------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "| id|         secure_code| airline|     departure_city|departure_date|arrival_airport|     arrival_city|    arrival_time|      passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|       co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|          pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+---+--------------------+--------+-------------------+--------------+---------------+-----------------+----------------+--------------------+----------------+-----------+--------+--------------+-------------+--------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  1|01H4EEMGMG9VADVF0...| EasyFly|             Berlin|    25/12/2022|            PEI|          Pereira|27/12/2022 14:13|    Nathalie Cardona|          Female|         A1|     EUR|            B2|      On Time|       Hart Blunkett| Embraer E190|         7916.39|        1|         1978|              CFQ|          Germany|6/7/2023 04:42|       Colombia|  27/12/2022|          14.18|            0|             Colombia|      797.24|         43.85|          E5|           Sunny Few|               9|               N12345|        1400.24|       1|2025_03_10_22_45_10|\n",
      "|  2|01H4EEMGMYP8GX4GR...|   Delta|Les Sables-d'Olonne|      4/1/2022|            YHU|         Westport|  6/7/2023 06:53|    Willie Childrens|          Female|         B2|     EUR|            A1|      Delayed|     Leanor Gribbins|  Airbus A320|         9666.36|        2|         2337|              ONG|           France|6/7/2023 17:31|    New Zealand|  23/12/2022|          13.54|           29|               Sweden|      383.63|         35.78|          D4|      Donielle Strut|               4|               N12345|         465.84|       1|2025_03_10_22_45_10|\n",
      "|  3|01H4EEMGN3BZJ9RR7...|  United|                Oyo|      3/4/2022|            KWJ|            Jabon|  6/7/2023 03:44|        Fifine Luten|          Female|         B2|     NGN|            C3|      On Time|    Christie Wakeley|   Boeing 737|         8047.44|        3|         7588|              TEX|          Nigeria|6/7/2023 11:08|      Indonesia|   30/9/2022|           6.28|           34|            Argentina|      439.09|         47.81|          D4|   Shelly Paddefield|               3|               N67890|        3151.78|       1|2025_03_10_22_45_10|\n",
      "|  4|01H4EEMGN9DFF5XJC...|   Delta|    Kuragaki-kosugi|     31/5/2022|            ANP|         Xianyuan|  6/7/2023 18:56|   Doll Sommerscales|          Female|         C3|     JPY|            A1|      Delayed|          Mia Vannah|  Airbus A320|         5156.19|        4|         7545|              ORB|            Japan|6/7/2023 11:11|          China|  14/10/2022|            5.6|           34|                China|      706.19|         25.79|          D4|   Babara Kretschmer|               6|               N12345|         264.64|       1|2025_03_10_22_45_10|\n",
      "|  5|01H4EEMGNFX6T41V6...|   Delta|        Ko Pha Ngan|     10/7/2022|            QUB|Sovetskaya Gavan’|  6/7/2023 16:55|       Norman Crosen|            Male|         A1|     THB|            A1|      On Time|         Barn Timmes|   Boeing 737|         7584.07|        5|         4553|              WEW|         Thailand|6/7/2023 10:40|         Russia|  13/10/2022|          14.71|           40|              Uruguay|      906.66|          11.6|          E5|       Bert Mathison|               5|               N67890|        2158.97|       1|2025_03_10_22_45_10|\n",
      "|  6|01H4EEMGNM5EFYXD9...|  United|       Cândido Mota|     3/12/2022|            VDM|            Légua|  6/7/2023 08:02|     Ingram Reicherz|            Male|         C3|     BRL|            C3|    Cancelled|Leicester McEntagart|   Boeing 737|         2035.88|        6|         2803|              BBV|           Brazil|6/7/2023 18:37|       Portugal|   29/3/2022|          15.39|           42|          South Korea|      131.44|         29.75|          D4|     Sergent Scarffe|               5|               N67890|        4838.19|       1|2025_03_10_22_45_10|\n",
      "|  7|01H4EEMGNT502Q3TQ...|American|          Zhangatas|     22/2/2022|            OGL|        Caibarién|  6/7/2023 11:55|          Jock Braam|            Male|         B2|     KZT|            C3|      On Time|       Rollin Leedal|   Boeing 737|         8287.38|        7|          757|              JUT|       Kazakhstan|6/7/2023 10:07|           Cuba|    2/9/2022|          17.45|           36|               Brazil|      476.27|         31.51|          D4|     Rayner Pennyman|               3|               N67890|         1777.3|       1|2025_03_10_22_45_10|\n",
      "|  8|01H4EEMGNZQZMS1G5...|  United|             Nevers|    20/10/2022|            MBG|            Tivat|  6/7/2023 15:03|         Shea Fedder|            Male|         A1|     EUR|            C3|      On Time|       Flynn Symmons|   Boeing 737|         4142.26|        8|         8642|              ELQ|           France|6/7/2023 23:13|     Montenegro|    4/2/2022|           4.77|           53|               Brazil|      640.94|         26.07|          E5|Johnathan Liversedge|               6|               NABCDE|         109.33|       1|2025_03_10_22_45_10|\n",
      "|  9|01H4EEMGP5RRF1T84...|   Delta|             Gaoyao|    27/12/2022|            SXM|     Chaoyangdong|  6/7/2023 17:35|    Cherise Anscombe|          Female|         C3|     CNY|            C3|      On Time|        Raquel Jeves|  Airbus A320|         9916.74|        9|         2765|              IZA|            China|6/7/2023 18:28|          China|    7/1/2022|           2.94|           57|                China|      133.09|         22.26|          F6|  Willette Episcopio|               4|               N12345|        3589.68|       1|2025_03_10_22_45_10|\n",
      "| 10|01H4EEMGPAR2YFG70...|   Delta|             Chatan|      6/1/2022|            YOL|           Istres|  6/7/2023 13:29|     Amara McGebenay|          Female|         A1|     JPY|            B2|      Delayed|       Philly Hickin| Embraer E190|          7003.2|       10|         6815|              LEE|            Japan|6/7/2023 12:14|         France|    5/8/2022|          21.62|           52|               Greece|      116.34|         27.61|          D4|         Lilah Kempe|               5|               N67890|         228.93|       1|2025_03_10_22_45_10|\n",
      "| 11|01H4EEMGPGM90HM7B...|   Delta|           Forninho|     15/1/2022|            PRM|           Kornyn|  6/7/2023 08:00|     Hoebart Fruchon|            Male|         C3|     EUR|            B2|      Delayed|     Cesare Janovsky| Embraer E190|         6868.05|       11|         6610|              KPB|         Portugal|6/7/2023 03:30|        Ukraine|    7/1/2022|           9.21|           70|                 Peru|      459.82|         45.14|          E5|         Hodge Polak|               5|               N12345|        3974.33|       1|2025_03_10_22_45_10|\n",
      "| 12|01H4EEMGPP9H8CR43...|American|             Lomboy|     16/3/2022|            DMU|       Ballinteer|  6/7/2023 00:25|        Rockie Huett|            Male|         C3|     PHP|            B2|    Cancelled|     Zerk Le Hucquet|   Boeing 737|         5346.91|       12|         8756|              OGL|      Philippines|6/7/2023 20:41|        Ireland|   1/11/2022|           3.86|           94|            Argentina|      462.73|         49.57|          D4|      Lauren Bussons|               5|               N67890|        2646.13|       1|2025_03_10_22_45_10|\n",
      "| 13|01H4EEMGPVCXFW2VZ...|  United|             Essang|    23/10/2022|            WLA|      Três Passos|  6/7/2023 16:28|        Lorrin Armit|          Female|         A1|     IDR|            B2|    Cancelled|     Inessa Bradnock| Embraer E190|          7185.9|       13|         3976|              NVY|        Indonesia|6/7/2023 18:56|         Brazil|  28/11/2022|          23.51|           66|               Sweden|       930.5|         39.47|          F6|    Lisetta Proudler|               1|               N12345|        2442.77|       1|2025_03_10_22_45_10|\n",
      "| 14|01H4EEMGQ0ETBKDEA...|American|           Zipárion|    15/12/2022|            LDN|      Courtaboeuf|  6/7/2023 07:03|       Burke Ruspine|            Male|         A1|     EUR|            C3|      Delayed|        Noach Gudgen|  Airbus A320|         2121.62|       14|          506|              ZTA|           Greece|6/7/2023 00:55|         France|   25/3/2022|          22.49|           66|              Ukraine|      963.38|          6.13|          F6|     Thorny Eggleson|               3|               NABCDE|        3944.21|       1|2025_03_10_22_45_10|\n",
      "| 15|01H4EEMGQ6HJV44PC...|American|              Gialo|     17/8/2022|            FKN|           Beigou|  6/7/2023 02:52|      Frank Beastall|            Male|         C3|     LYD|            B2|    Cancelled|          Salim Shay|  Airbus A320|         6812.66|       15|         1420|              RUK|            Libya|6/7/2023 13:08|          China|   25/1/2022|           12.5|           79|              Bolivia|      721.82|         11.42|          D4|       Field McEntee|               7|               NABCDE|         745.48|       1|2025_03_10_22_45_10|\n",
      "| 16|01H4EEMGQBFQP91SE...|American|              Rusip|    18/12/2022|            QCY|         Oštarije|  6/7/2023 03:22|    Richie Rosindill|            Male|         A1|     IDR|            B2|    Cancelled|    Dolph Lanchberry|  Airbus A320|         5704.86|       16|         6843|              MTY|        Indonesia|6/7/2023 07:41|        Croatia|  20/12/2022|          19.42|           86|               Poland|      723.34|         43.14|          D4|       Josh Docharty|               9|               NABCDE|        1008.69|       1|2025_03_10_22_45_10|\n",
      "| 17|01H4EEMGQG22ER3ZS...|   Delta|             Panyam|     20/5/2022|            OXR|         El Limon|  6/7/2023 03:55|Shellysheldon Bubeer|            Male|         C3|     NGN|            B2|      Delayed|      Julius Kelsall|  Airbus A320|         7480.92|       17|          933|              PCO|          Nigeria|6/7/2023 18:12|         Mexico|   17/4/2022|          21.86|           45|               Norway|      983.86|         34.47|          E5|     Edward Pavolini|               5|               N67890|        3659.46|       1|2025_03_10_22_45_10|\n",
      "| 18|01H4EEMGQPE6HCDYD...|   Delta|         Xiaomenjia|      3/9/2022|            VDS|         Trinidad|  6/7/2023 21:31|    Amelia Ralestone|          Female|         B2|     CNY|            B2|    Cancelled|        Veda Stollen| Embraer E190|         2859.73|       18|         9051|              DHG|            China|6/7/2023 09:46|           Peru|    1/1/2022|           6.62|           60|             Portugal|      216.07|          2.59|          F6|       Arlana Pudner|               3|               N67890|        4842.87|       1|2025_03_10_22_45_10|\n",
      "| 19|01H4EEMGQVNVPC68C...|   Delta|          Xujiadian|    28/11/2022|            CGV|           Vannes|  6/7/2023 19:38|       Kylie Dowdall|          Female|         B2|     CNY|            C3|      Delayed|     Klarika Dulanty|   Boeing 737|         1982.61|       19|         2934|              HAO|            China|6/7/2023 08:26|         France|  12/10/2022|          13.13|           82|               Greece|      835.35|         43.71|          F6|      Nadean Verrell|               4|               N12345|        4133.64|       1|2025_03_10_22_45_10|\n",
      "| 20|01H4EEMGR16AZ5ZR3...|American|             Mainit|     11/6/2022|            IOU|             Gujō|  6/7/2023 23:12|       Elston Greson|            Male|         C3|     PHP|            B2|      Delayed|      Ethelred Wyche| Embraer E190|          2882.4|       20|         8761|              TCZ|      Philippines|6/7/2023 07:20|          Japan|    2/9/2022|          14.22|           29|               France|      861.69|          20.1|          F6|        Andre Gatiss|               7|               NABCDE|        2833.98|       1|2025_03_10_22_45_10|\n",
      "+---+--------------------+--------+-------------------+--------------+---------------+-----------------+----------------+--------------------+----------------+-----------+--------+--------------+-------------+--------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 2 at 2025_03_10_22_45_15\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |53           |286.78000000000003|860.34            |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |57           |315.3066666666667 |945.9200000000001 |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |54           |678.1066666666667 |2034.3200000000002|3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |61           |314.9766666666667 |944.9300000000001 |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |73           |390.07666666666665|1170.23           |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |78           |654.3733333333333 |1963.1200000000001|3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |51           |395.4766666666667 |1186.43           |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Female          |93           |426.99333333333334|1280.98           |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Male            |74           |594.3433333333334 |1783.0300000000002|3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Male            |49           |732.3266666666667 |2196.98           |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Male            |66           |733.0766666666667 |2199.23           |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Male            |96           |473.55            |1420.65           |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Male            |93           |559.5             |1678.5            |3               |\n",
      "|2       |2025_03_10_22_45_15|China                |Male            |21           |418.32            |1254.96           |3               |\n",
      "|2       |2025_03_10_22_45_15|Indonesia            |Female          |76           |659.92            |1979.76           |3               |\n",
      "|2       |2025_03_10_22_45_15|Indonesia            |Female          |32           |463.46000000000004|1390.38           |3               |\n",
      "|2       |2025_03_10_22_45_15|Indonesia            |Male            |96           |612.04            |1836.12           |3               |\n",
      "|2       |2025_03_10_22_45_15|Philippines          |Female          |75           |571.68            |1715.04           |3               |\n",
      "|2       |2025_03_10_22_45_15|Russia               |Male            |63           |441.71999999999997|1325.1599999999999|3               |\n",
      "|2       |2025_03_10_22_45_15|United States        |Male            |27           |479.26            |1437.78           |3               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+--------------------+--------+--------------+--------------+---------------+----------------+--------------+--------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline|departure_city|departure_date|arrival_airport|    arrival_city|  arrival_time|      passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|      co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|     arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|        pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+----------------+--------------+--------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|1001|01H4EEMMVYAY9VQRE...|American|  Nakhon Nayok|     2/11/2022|            CUI|          Bromma|6/7/2023 08:54|     Murielle Raulin|     Genderfluid|         A1|     THB|            B2|    Cancelled|    Kelbee Franzman|   Boeing 737|         8950.14|     1001|          776|              GTS|         Thailand|6/7/2023 02:21|              Sweden|   29/4/2022|           6.51|           19|               Poland|      568.46|         38.15|          F6|Henriette Chopping|               2|               N67890|        3090.45|       2|2025_03_10_22_45_15|\n",
      "|1002|01H4EEMMW1YT1DA0S...|   Delta|     Ulaan-Uul|     7/12/2022|            RGS|        Xiaozhai|6/7/2023 04:47|         Meris Katte|          Female|         B2|     MNT|            A1|      On Time|Anna-diana Shillito| Embraer E190|         6007.32|     1002|         3193|              GUU|         Mongolia|6/7/2023 18:37|               China|  10/10/2022|          12.95|           24|              Armenia|      886.62|         45.62|          E5| Mignonne Peperell|               2|               N12345|        4177.52|       2|2025_03_10_22_45_15|\n",
      "|1003|01H4EEMMW7ZA8JA1T...|   Delta|  Kuala Lumpur|     30/9/2022|            ENV|           Mólos|6/7/2023 00:38|        Amber Sheber|          Female|         C3|     MYR|            C3|      On Time|  Courtenay Salters| Embraer E190|         3601.69|     1003|         5991|              HZV|         Malaysia|6/7/2023 11:58|              Greece|    9/4/2022|           7.76|           73|                China|       78.31|         42.15|          F6|       Tanya Coult|               7|               N12345|        1179.22|       2|2025_03_10_22_45_15|\n",
      "|1004|01H4EEMMWCBCMSN1W...|  United| Baltasar Brum|     17/7/2022|            NHD|  Ciudad Sandino|6/7/2023 08:35|Konstantine McFet...|            Male|         A1|     UYU|            A1|      Delayed|     Jaimie D'Cruze| Embraer E190|         9653.98|     1004|          911|              MXB|          Uruguay|6/7/2023 00:44|           Nicaragua|   20/8/2022|          13.01|           64|              Vietnam|      975.68|         38.98|          D4|   Anthony McKinty|               6|               NABCDE|        1151.95|       2|2025_03_10_22_45_15|\n",
      "|1005|01H4EEMMWJTDDHW8Y...|  United|   Paucarcolla|     1/10/2022|            VDS|        Beltinci|6/7/2023 23:19|      Lulita Penhale|          Female|         A1|     PEN|            B2|    Cancelled|       Valry Bixley|   Boeing 737|         8869.95|     1005|         9426|              SOO|             Peru|6/7/2023 14:39|            Slovenia|   24/9/2022|           8.68|           81|             Mongolia|      509.32|         19.52|          D4|      Evy Clemenzi|               7|               N67890|        3513.93|       2|2025_03_10_22_45_15|\n",
      "|1006|01H4EEMMWQSX2RHG4...|   Delta|        Anding|     14/8/2022|            RZZ|       Zhuyeping|6/7/2023 00:00|      Branden Hugnin|            Male|         B2|     CNY|            C3|      On Time|     Skipton Sammon| Embraer E190|         8116.37|     1006|         4160|              PSH|            China|6/7/2023 03:35|               China|   27/8/2022|          20.45|           52|          Switzerland|      904.72|         36.29|          D4|    Taylor Ballach|               7|               NABCDE|        3039.29|       2|2025_03_10_22_45_15|\n",
      "|1007|01H4EEMMWXSGWXTJ8...|American| Sihanoukville|      6/8/2022|            TPQ|       Bandhagen|6/7/2023 03:42|     Zilvia Pickrell|          Female|         A1|     KHR|            B2|      Delayed|         Kandace Do|   Boeing 737|         3947.15|     1007|         3069|              HZH|         Cambodia|6/7/2023 10:41|              Sweden|   19/3/2022|          22.93|           70|                Sudan|      338.41|         14.08|          E5|    Tove MacGeaney|               3|               NABCDE|         353.36|       2|2025_03_10_22_45_15|\n",
      "|1008|01H4EEMMX2E1ENFMN...|American|       Itiruçu|     31/3/2022|            MAP|           Daliu|6/7/2023 15:22|     Allyson Devaney|          Female|         A1|     BRL|            C3|      Delayed|       Remy Bonnick|  Airbus A320|         1102.01|     1008|         5923|              FCH|           Brazil|6/7/2023 10:31|               China|   20/5/2022|          23.62|           27|                China|      815.73|         12.44|          D4|   Frederique Reef|              10|               N12345|        4875.94|       2|2025_03_10_22_45_15|\n",
      "|1009|01H4EEMMX65CZSPES...|   Delta|Montréal-Ouest|     23/1/2022|            THM|Gaspar Hernández|6/7/2023 00:32|    Zacharias Boagey|            Male|         A1|     CAD|            A1|      Delayed|      Dagny Pipping|   Boeing 737|         5779.58|     1009|         7445|              KIP|           Canada|6/7/2023 00:01|  Dominican Republic|   13/1/2022|          22.62|           48|                China|      912.96|           3.0|          D4|     Tracy McMyler|               1|               NABCDE|        3793.43|       2|2025_03_10_22_45_15|\n",
      "|1010|01H4EEMMX9JMTD9AG...|   Delta|          Nara|     3/10/2022|            MVT|            Ugba|6/7/2023 03:48|      Budd Schneidau|            Male|         B2|     XOF|            B2|      Delayed|Tybalt Clarricoates|   Boeing 737|         1311.62|     1010|         9423|              ARY|             Mali|6/7/2023 06:35|             Nigeria|   13/7/2022|           8.56|           24|               France|      882.91|         23.16|          D4|      Erwin Adamik|               3|               N12345|        3116.84|       2|2025_03_10_22_45_15|\n",
      "|1011|01H4EEMMXCJPG909B...|   Delta|        Pandak|      7/5/2022|            XIN|           Dijon|6/7/2023 05:54|      Erskine Rodman|            Male|         B2|     IDR|            A1|      Delayed|   Lenard Andreutti|   Boeing 737|         4267.26|     1011|         9710|              XPP|        Indonesia|6/7/2023 22:25|              France|   10/4/2022|           11.4|           94|                Chile|      137.15|         46.45|          E5|    Tailor Oughton|               8|               N12345|        3529.43|       2|2025_03_10_22_45_15|\n",
      "|1012|01H4EEMMXFP26SZSD...|   Delta|      Paris 10|    14/11/2022|            SHR|        Barbalha|6/7/2023 16:55|         Tish Grills|          Female|         C3|     EUR|            B2|      Delayed|             Ag Ash|  Airbus A320|         4081.97|     1012|         7262|              KBL|           France|6/7/2023 03:33|              Brazil|    8/3/2022|          16.43|           66|              Germany|       988.2|         35.59|          F6|    Leda McPartlin|               2|               N12345|        4403.12|       2|2025_03_10_22_45_15|\n",
      "|1013|01H4EEMMXJT24WGPM...|  United|    Nanxindian|     10/8/2022|            YFG|            Piru|6/7/2023 20:49|        Jared Seldon|            Male|         A1|     CNY|            B2|    Cancelled|          Neil Laye| Embraer E190|         5001.06|     1013|         6819|              AEB|            China|6/7/2023 00:17|           Indonesia|   22/8/2022|          20.76|           75|          Switzerland|      145.67|           0.4|          E5|   Sansone Sandars|               1|               N67890|        1799.16|       2|2025_03_10_22_45_15|\n",
      "|1014|01H4EEMMXN9PVFGSP...|  United| Bulahblangaro|     17/3/2022|            JHL|       Gračanica|6/7/2023 20:45|      Giacobo Trappe|            Male|         C3|     IDR|            A1|      Delayed|       Brandy Elwin| Embraer E190|         5399.15|     1014|         5525|              CSX|        Indonesia|6/7/2023 13:37|Bosnia and Herzeg...|   16/8/2022|          20.91|           27|        United States|      999.53|         22.73|          E5|   Keven Jurgenson|               1|               N67890|         344.09|       2|2025_03_10_22_45_15|\n",
      "|1015|01H4EEMMXQW35SA18...|American|        Sigavé|     27/1/2022|            YGC|       Pampanito|6/7/2023 09:34|      Harriot Fodden|          Female|         A1|     XPF|            A1|      On Time|       Tori Mapholm|   Boeing 737|         1550.71|     1015|         3584|              LGW|Wallis and Futuna|6/7/2023 15:28|           Venezuela|  15/10/2022|          22.91|           87|          Philippines|      264.39|         32.72|          D4|    Ranna Fursland|               9|               N12345|        2059.08|       2|2025_03_10_22_45_15|\n",
      "|1016|01H4EEMMXTKFV0WD6...|   Delta|         Ḏânan|     22/6/2022|            EMA|      Washington|6/7/2023 01:13|        Heida Cousen|          Female|         B2|     DJF|            A1|      On Time|    Mame Kirkbright|  Airbus A320|         6828.06|     1016|         5349|              VDI|         Djibouti|6/7/2023 23:51|       United States|    3/5/2022|           23.8|           26|              Nigeria|      348.88|         26.46|          E5|          Meg Folk|               4|               N67890|        1716.74|       2|2025_03_10_22_45_15|\n",
      "|1017|01H4EEMMXY6BZ2E9A...|  United|    Vila Maior|      9/8/2022|            YXZ|            Kaum|6/7/2023 11:53|         Barri Tower|            Male|         B2|     EUR|            A1|    Cancelled|   Thatch Whatmough|   Boeing 737|         7170.89|     1017|         9284|              ADY|         Portugal|6/7/2023 02:52|           Indonesia|  26/11/2022|          13.43|           60|              Belarus|       90.45|         34.03|          F6|    Felike Fereday|               6|               NABCDE|        4461.17|       2|2025_03_10_22_45_15|\n",
      "|1018|01H4EEMMY2N98Z4WE...|American|      Zhangzhu|    15/11/2022|            KOK|       Širvintos|6/7/2023 00:17|         Lana Hawton|          Female|         A1|     CNY|            B2|      On Time|    Drusilla Denney| Embraer E190|         2462.14|     1018|         4614|              AXA|            China|6/7/2023 15:41|           Lithuania|   29/7/2022|           1.16|           56|         South Africa|      945.66|         23.59|          E5|  Frederica Nassie|               6|               N12345|         1413.1|       2|2025_03_10_22_45_15|\n",
      "|1019|01H4EEMMY60MBFAVH...|   Delta|       Dubrava|     15/7/2022|            OMM|       Mnelalete|6/7/2023 06:30|       Merry MacGoun|          Female|         A1|     HRK|            A1|      Delayed|      Lindie Dungay|   Boeing 737|         3735.49|     1019|         4077|              TFS|          Croatia|6/7/2023 10:14|           Indonesia|   20/9/2022|          19.56|           96|                China|      207.65|         23.81|          F6|   Tomasine Sleany|               9|               N12345|         4650.5|       2|2025_03_10_22_45_15|\n",
      "|1020|01H4EEMMY9XP71MGH...|   Delta|        Māymay|     6/11/2022|            SHS|        Yancheng|6/7/2023 05:38|       Fields Yedall|      Non-binary|         C3|     AFN|            A1|      Delayed|      Aldwin Faivre|  Airbus A320|         8037.25|     1020|         8548|              FAA|      Afghanistan|6/7/2023 17:21|               China|   29/7/2022|            2.0|           87|            Indonesia|      730.91|         18.95|          F6|   Quincey Copcutt|               2|               N12345|        3435.56|       2|2025_03_10_22_45_15|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+----------------+--------------+--------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 3 at 2025_03_10_22_45_20\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|3       |2025_03_10_22_45_20|China                |Female          |38           |330.07            |990.21            |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Female          |32           |481.4433333333333 |1444.33           |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Female          |18           |560.2833333333334 |1680.8500000000001|3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Female          |79           |263.59999999999997|790.8             |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Female          |56           |464.8566666666666 |1394.57           |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |38           |655.42            |1966.2599999999998|3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |29           |579.73            |1739.19           |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |37           |327.15            |981.4499999999999 |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |69           |441.94            |1325.82           |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |92           |551.1             |1653.3000000000002|3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |50           |690.7966666666666 |2072.39           |3               |\n",
      "|3       |2025_03_10_22_45_20|Indonesia            |Female          |57           |293.09999999999997|879.3             |3               |\n",
      "|3       |2025_03_10_22_45_20|China                |Female          |80           |473.98749999999995|1895.9499999999998|4               |\n",
      "|3       |2025_03_10_22_45_20|China                |Male            |33           |448.2925          |1793.17           |4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+----+--------------------+--------+----------------+--------------+---------------+--------------------+--------------+------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline|  departure_city|departure_date|arrival_airport|        arrival_city|  arrival_time|    passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|      co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|     arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|        pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+----------------+--------------+---------------+--------------------+--------------+------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|2001|01H4EEMR8K4ZX4H7G...|  United|       Ust’-Isha|    21/10/2022|            UVL|        Kristinehamn|6/7/2023 19:03|  Othello Spittall|     Genderfluid|         C3|     RUB|            C3|      Delayed|       Carson Ayres| Embraer E190|         4841.93|     2001|         6150|              TAM|           Russia|6/7/2023 17:28|              Sweden|   23/8/2022|          14.79|           68|              Senegal|      982.47|          7.43|          F6|     Gordy Finessy|               3|               N67890|        2905.35|       3|2025_03_10_22_45_20|\n",
      "|2002|01H4EEMR8PFBCHHYE...|  United|        Khoyniki|    17/10/2022|            MPG|            Miracema|6/7/2023 17:53|Fletch Pendlington|            Male|         C3|     BYR|            B2|    Cancelled|     Grantley Rozea|  Airbus A320|         3779.14|     2002|          481|                0|          Belarus|6/7/2023 20:10|              Brazil|   18/2/2022|          17.85|           29|                China|      474.16|          19.3|          F6|      Ernest Robbe|               1|               NABCDE|        2007.26|       3|2025_03_10_22_45_20|\n",
      "|2003|01H4EEMR8SKKFFPJA...|  United|          Osório|     29/7/2022|            LNA|   Vilar do Pinheiro|6/7/2023 06:38|    Susie Presidey|          Female|         C3|     BRL|            A1|      Delayed|Philly Franzettoini| Embraer E190|         9311.26|     2003|          115|              SWM|           Brazil|6/7/2023 19:54|            Portugal|  27/10/2022|          11.04|           84|               Brazil|      701.09|          7.03|          E5|    Karina Coveley|               7|               N12345|        3716.09|       3|2025_03_10_22_45_20|\n",
      "|2004|01H4EEMR8VBDBCEB4...|  United|            Trới|     10/4/2022|            CMC|              Nanger|6/7/2023 22:19|        Dunn Steel|            Male|         A1|     VND|            B2|      On Time|         Hunt Soles|  Airbus A320|         9448.42|     2004|         2190|              INL|          Vietnam|6/7/2023 08:09|           Indonesia|   27/8/2022|          14.06|           55|                 Peru|      328.59|         20.49|          F6| Worden Hutchcraft|               9|               NABCDE|        4402.55|       3|2025_03_10_22_45_20|\n",
      "|2005|01H4EEMR8Y8QZB4EB...|   Delta|    La Esmeralda|      2/1/2022|            NOM|          Calebasses|6/7/2023 13:25|    Mischa Rihosek|            Male|         B2|     VEF|            B2|      Delayed|           Car Sams| Embraer E190|         9137.93|     2005|          146|              YUA|        Venezuela|6/7/2023 15:30|           Mauritius|   14/1/2022|           15.0|           80|          Philippines|       357.2|         25.66|          F6|         Ugo Tutin|               7|               N12345|        2534.23|       3|2025_03_10_22_45_20|\n",
      "|2006|01H4EEMR91N5YZBW4...|American|         Obihiro|     21/4/2022|            WGN|              Vihāri|6/7/2023 04:40|     Markos Jancic|            Male|         A1|     JPY|            B2|      On Time|     Allard Dewdeny|   Boeing 737|         5775.05|     2006|          347|              CMI|            Japan|6/7/2023 04:33|            Pakistan|    4/4/2022|          17.26|           89|                Egypt|       790.4|         41.77|          E5|    Lucias Haswell|              10|               N67890|        4070.81|       3|2025_03_10_22_45_20|\n",
      "|2007|01H4EEMR94CV09C1G...|American|           Hotsk|     28/6/2022|            OHO|              Masjid|6/7/2023 04:04|  Loretta Duggleby|          Female|         A1|     BYR|            B2|    Cancelled|      Perri Faucett| Embraer E190|         9162.91|     2007|         8287|              NOP|          Belarus|6/7/2023 13:15|           Indonesia|    5/7/2022|          11.73|           34|        United States|      471.23|          3.73|          E5|     Norene Stoeck|               5|               N12345|        4610.89|       3|2025_03_10_22_45_20|\n",
      "|2008|01H4EEMR99RHGGY8S...|   Delta|            Ujar|     21/3/2022|            NRT|         Yanghuxiang|6/7/2023 14:33|        Dory Proud|          Female|         B2|     AZN|            A1|      Delayed|      Bobbee Voller|  Airbus A320|         3349.44|     2008|         7627|              EVA|       Azerbaijan|6/7/2023 23:46|               China|   26/5/2022|           8.96|           77|               Canada|      809.92|         42.05|          F6|   Teriann Mugford|               1|               NABCDE|        2663.78|       3|2025_03_10_22_45_20|\n",
      "|2009|01H4EEMR9CM89ZM8F...|American|         Linshui|     30/3/2022|            JUI|          Maluanluan|6/7/2023 17:19|     Selie Lanston|          Female|         A1|     CNY|            A1|    Cancelled|   Caresse McGaugie|   Boeing 737|         2628.44|     2009|         8084|              JMK|            China|6/7/2023 03:51|         Philippines|   27/4/2022|           10.8|           67|             Slovenia|      869.76|         39.28|          E5| Lavena Innerstone|               7|               N67890|        3016.51|       3|2025_03_10_22_45_20|\n",
      "|2010|01H4EEMR9F1SCQSJY...|American|           Modot|      5/5/2022|            BBH|                 Uyo|6/7/2023 16:42|   Charil Cullinan|     Genderfluid|         C3|     MNT|            C3|      On Time|       Myron Ayrton| Embraer E190|         4374.83|     2010|         9037|              PBF|         Mongolia|6/7/2023 09:13|             Nigeria|  30/12/2022|           2.54|          100|                China|      541.74|         22.81|          F6|       Con Warlawe|               7|               N67890|        1633.32|       3|2025_03_10_22_45_20|\n",
      "|2011|01H4EEMR9J3B21X0Q...|  United|  Jaraguá do Sul|     16/6/2022|            EBW|             Dobřany|6/7/2023 19:15|      Donna Strass|          Female|         A1|     BRL|            A1|    Cancelled|    Gretel Caulcott|  Airbus A320|         1689.77|     2011|         4229|              LDH|           Brazil|6/7/2023 13:27|      Czech Republic|   19/9/2022|           7.62|           38|                China|      481.35|         16.82|          E5|Kissiah Giacomelli|               5|               NABCDE|        3129.88|       3|2025_03_10_22_45_20|\n",
      "|2012|01H4EEMR9NRFARRFR...|  United|   Campo Quijano|    12/11/2022|            BIL|          As Sukhnah|6/7/2023 09:24|       Flinn Petti|            Male|         B2|     ARS|            B2|      Delayed|       Pavel Ivanov| Embraer E190|         8201.46|     2012|         4265|              VPY|        Argentina|6/7/2023 16:36|               Syria|   29/7/2022|          22.31|           92|               Sweden|       136.2|          8.04|          E5|       Bronny Tuke|               2|               NABCDE|         3375.1|       3|2025_03_10_22_45_20|\n",
      "|2013|01H4EEMR9RWAPHP7Y...|   Delta|Krajan Tegalombo|     28/8/2022|            THA|        Dorp Antriol|6/7/2023 06:49|     Corrine Marty|        Bigender|         A1|     IDR|            B2|      On Time|       Petr Vautrey|   Boeing 737|         7475.08|     2013|         4368|              RAF|        Indonesia|6/7/2023 10:50|Bonaire, Saint Eu...|   25/9/2022|          11.78|           57|                China|      639.19|         33.16|          E5| Juline Minchinden|               3|               N12345|        2380.44|       3|2025_03_10_22_45_20|\n",
      "|2014|01H4EEMR9V9N9MEKZ...|American|    Casa Quemada|     18/7/2022|            NJA|                Saki|6/7/2023 11:53|      Mella Durdle|          Female|         A1|     HNL|            A1|      Delayed|          Sal Samme| Embraer E190|         6494.78|     2014|         5955|              CZX|         Honduras|6/7/2023 08:23|             Nigeria|   13/3/2022|          19.22|          100|                China|      786.04|         31.25|          E5|    Rianon Milkins|               7|               NABCDE|        2841.42|       3|2025_03_10_22_45_20|\n",
      "|2015|01H4EEMR9XD3JVK7N...|  United| Juvisy-sur-Orge|     15/8/2022|            DBY|Shangcheng Chengg...|6/7/2023 11:31|       Glori Todeo|     Genderfluid|         C3|     EUR|            B2|      Delayed|    Walden Runnalls| Embraer E190|         4656.42|     2015|         8703|              LEA|           France|6/7/2023 20:51|               China|   16/8/2022|          20.12|           34|                China|      441.04|         44.61|          E5|      Evita Kegley|               8|               N12345|         422.97|       3|2025_03_10_22_45_20|\n",
      "|2016|01H4EEMRA04BRM4YY...|   Delta|            Mesa|     24/9/2022|            ATG|                Gōdo|6/7/2023 06:06|   Clim Durrington|            Male|         C3|     USD|            B2|    Cancelled|    Cullin Shergold|   Boeing 737|         2315.39|     2016|         9250|              JAF|    United States|6/7/2023 04:52|               Japan|   18/4/2022|          22.33|           38|                China|      874.39|           5.8|          F6|      Paul Broggio|              10|               N67890|        2530.48|       3|2025_03_10_22_45_20|\n",
      "|2017|01H4EEMRA3XKBXCQ7...|   Delta|  Vanderbijlpark|    12/11/2022|            VAK|          Lindavista|6/7/2023 13:03|     Brandy Traves|          Female|         B2|     ZAR|            B2|      On Time|    Barbi Robillard| Embraer E190|         2619.94|     2017|         8778|              FAC|     South Africa|6/7/2023 02:50|              Mexico|  13/12/2022|          15.84|           95|              Senegal|      941.73|         39.77|          D4|     Jeniece Villa|               4|               N67890|        2028.72|       3|2025_03_10_22_45_20|\n",
      "|2018|01H4EEMRA6F41VYEC...|American|Cachoeira do Sul|     27/5/2022|            SCV|         Chapultepec|6/7/2023 08:29|   Isabel Purchall|          Female|         B2|     BRL|            B2|      On Time|    Gail Giacomuzzo| Embraer E190|         3407.78|     2018|         9432|              PNS|           Brazil|6/7/2023 12:24|              Mexico|   22/2/2022|          15.92|           75|              Ukraine|      600.92|         49.94|          E5|      Cassi Gorton|               6|               NABCDE|        3141.88|       3|2025_03_10_22_45_20|\n",
      "|2019|01H4EEMRA9QNK333T...|American|      Kotatengah|      3/1/2022|            YXL|             Arcueil|6/7/2023 06:04|      Lita Burrell|          Female|         A1|     IDR|            A1|      Delayed|      Kimmie Regitz|   Boeing 737|         1660.32|     2019|         3598|              YLY|        Indonesia|6/7/2023 06:56|              France|    6/1/2022|          11.81|           78|               Russia|      242.65|         39.71|          F6|      Rhodia Hesey|               5|               N12345|        4846.85|       3|2025_03_10_22_45_20|\n",
      "|2020|01H4EEMRACD95JMMZ...|American|         Gandara|    19/10/2022|            KRC|           Abadiânia|6/7/2023 00:33|Doralynne Eversley|          Female|         B2|     EUR|            C3|      Delayed|     Agnese Bertlin|   Boeing 737|         7780.92|     2020|         2780|              MXY|         Portugal|6/7/2023 01:23|              Brazil|  14/11/2022|          19.01|          100|             Mongolia|      257.91|         49.54|          D4|   Stevena Cathery|               2|               N67890|        4819.25|       3|2025_03_10_22_45_20|\n",
      "+----+--------------------+--------+----------------+--------------+---------------+--------------------+--------------+------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 4 at 2025_03_10_22_45_25\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|4       |2025_03_10_22_45_25|China                |Female          |88           |689.8100000000001 |2069.4300000000003|3               |\n",
      "|4       |2025_03_10_22_45_25|China                |Female          |40           |405.80999999999995|1217.4299999999998|3               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |75           |251.74            |755.22            |3               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |81           |455.77000000000004|1367.3100000000002|3               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |67           |543.4133333333333 |1630.2399999999998|3               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |74           |182.43666666666664|547.31            |3               |\n",
      "|4       |2025_03_10_22_45_25|Indonesia            |Female          |72           |379.4433333333333 |1138.33           |3               |\n",
      "|4       |2025_03_10_22_45_25|Indonesia            |Male            |18           |484.02666666666664|1452.08           |3               |\n",
      "|4       |2025_03_10_22_45_25|Poland               |Male            |85           |826.87            |2480.61           |3               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |79           |514.655           |2058.62           |4               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |18           |452.0274999999999 |1808.1099999999997|4               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |91           |636.2925          |2545.17           |4               |\n",
      "|4       |2025_03_10_22_45_25|China                |Male            |58           |704.3225          |2817.29           |4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+----+--------------------+--------+---------------+--------------+---------------+------------+--------------+-----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline| departure_city|departure_date|arrival_airport|arrival_city|  arrival_time|   passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|     co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|     arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|          pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+---------------+--------------+---------------+------------+--------------+-----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|3001|01H4EEMVMVDV5SDHP...|  United|     Lewograran|      4/2/2022|            BGO|     Čajniče|6/7/2023 05:14|    Paquito Molan|            Male|         C3|     IDR|            B2|      Delayed|     Jud Goldspink|   Boeing 737|         1140.93|     3001|         6712|              DRW|        Indonesia|6/7/2023 05:22|Bosnia and Herzeg...|    9/9/2022|           1.82|           58|               Poland|      409.92|         36.57|          F6|          Bil Gittis|               7|               N67890|         347.53|       4|2025_03_10_22_45_25|\n",
      "|3002|01H4EEMVMYRMKR5RY...|  United|   Capitão Poço|     26/3/2022|            AUU|      Llauta|6/7/2023 15:33|    Otis Izkovici|            Male|         C3|     BRL|            C3|      Delayed|    Dougie Hendron|   Boeing 737|         9927.09|     3002|         6018|              KRV|           Brazil|6/7/2023 20:35|                Peru|   15/4/2022|           4.09|           31|               France|      663.18|          30.6|          E5|     Lock O'Hartigan|               5|               N12345|        1326.09|       4|2025_03_10_22_45_25|\n",
      "|3003|01H4EEMVN126AAKF6...|  United|          Enzan|    25/10/2022|            GIS|    Kil’mez’|6/7/2023 13:40|    Xena Georgins|          Female|         A1|     JPY|            C3|      Delayed|      Ketti Domini|   Boeing 737|         3519.36|     3003|          907|              RAV|            Japan|6/7/2023 21:54|              Russia|  20/10/2022|          17.54|           26|               Poland|      111.71|         18.78|          D4|Jillane De Cristo...|               9|               N67890|        3257.31|       4|2025_03_10_22_45_25|\n",
      "|3004|01H4EEMVN4BA0PYWX...|  United|    Phitsanulok|     17/8/2022|            TEN|       Thala|6/7/2023 01:14|     Corrie Maken|          Female|         A1|     THB|            C3|      Delayed| Loretta Wellesley|   Boeing 737|          6988.0|     3004|         6756|              JAP|         Thailand|6/7/2023 22:57|             Tunisia|   25/1/2022|           5.47|           60|                 Iran|      359.91|         28.69|          D4|    Elisabeth Hylden|              10|               N67890|        3887.37|       4|2025_03_10_22_45_25|\n",
      "|3005|01H4EEMVN79C0X9KZ...|  United|      Changxing|    28/10/2022|            BCM|      Zhaixi|6/7/2023 17:58| Jarred Shoesmith|            Male|         C3|     CNY|            C3|      Delayed|Maximilien Windham|   Boeing 737|         5603.39|     3005|         3574|              BDG|            China|6/7/2023 15:40|               China|   1/10/2022|          20.06|           35|             Mongolia|      518.89|         46.99|          F6|       Rodger Lampen|               4|               NABCDE|        1547.72|       4|2025_03_10_22_45_25|\n",
      "|3006|01H4EEMVNANRMJPN7...|   Delta|      Biny Selo|     2/11/2022|            AIV|        Rama|6/7/2023 08:03|     Anni Barbery|          Female|         B2|     AZN|            C3|    Cancelled|  Matelda Alldritt|   Boeing 737|         3152.84|     3006|         3974|              DNK|       Azerbaijan|6/7/2023 00:44|           Nicaragua|   29/6/2022|          23.84|           88|               Poland|      899.77|         30.96|          D4|      Margy Guerreru|               9|               N67890|         407.14|       4|2025_03_10_22_45_25|\n",
      "|3007|01H4EEMVND8FZCEX2...|American|          Saijō|     21/5/2022|            SHK|    Erdaocha|6/7/2023 20:26|   Lonny Stickels|            Male|         B2|     JPY|            C3|      On Time|  Mitchael Boteman|   Boeing 737|         4737.05|     3007|         2086|              IQA|            Japan|6/7/2023 00:52|               China|    7/3/2022|           8.94|           73|            Indonesia|      713.57|         45.07|          F6|      Balduin Dickie|               9|               NABCDE|        2037.57|       4|2025_03_10_22_45_25|\n",
      "|3008|01H4EEMVNFF0G20ZK...|  United|          Uthal|      1/8/2022|            MDY|      Skoura|6/7/2023 02:48|      Ragnar Wais|            Male|         C3|     PKR|            A1|    Cancelled|   Jamesy Rickerby|  Airbus A320|         6080.46|     3008|         6897|              GCJ|         Pakistan|6/7/2023 04:16|             Morocco|   7/12/2022|          12.65|           61|            Indonesia|      821.35|         11.86|          E5|  Westleigh Andrioli|               7|               N12345|        2854.91|       4|2025_03_10_22_45_25|\n",
      "|3009|01H4EEMVNJ9EHNKWN...|   Delta|        Baolong|     27/1/2022|            PUX|      Yelan’|6/7/2023 07:28|   Bryant Cropton|            Male|         A1|     CNY|            B2|      Delayed|    Erick Readhead|   Boeing 737|         7073.32|     3009|         3990|              CTH|            China|6/7/2023 18:23|              Russia|   17/2/2022|          23.87|           80|               Russia|      379.46|         49.81|          F6|       Billy Burdess|              10|               N12345|        4723.92|       4|2025_03_10_22_45_25|\n",
      "|3010|01H4EEMVNNWKJM9QV...|  United|    Prosperidad|    19/12/2022|            AQP|     Yên Bái|6/7/2023 13:36|       Kalvin Bow|            Male|         A1|     PHP|            C3|    Cancelled|   Pietrek Playden|  Airbus A320|         5665.73|     3010|         7103|              SVA|      Philippines|6/7/2023 08:35|             Vietnam|  28/12/2022|           1.99|           92|               Russia|      550.73|         31.96|          E5|       Grove Cossell|               2|               N12345|        2951.54|       4|2025_03_10_22_45_25|\n",
      "|3011|01H4EEMVNR8W9ZGAE...|   Delta|        Taikang|     21/9/2022|            RZA|     Haumeni|6/7/2023 02:15|       Lyn Kittle|          Female|         C3|     CNY|            C3|    Cancelled|        Bibi Carik| Embraer E190|         6803.72|     3011|         2923|              SLN|            China|6/7/2023 11:13|           Indonesia|   30/3/2022|          18.81|           32|                China|      695.46|         39.13|          E5|   Fay O'Kynsillaghe|               9|               N12345|        1159.33|       4|2025_03_10_22_45_25|\n",
      "|3012|01H4EEMVNV23FPBP7...|American|          Pelem|     31/7/2022|            VCV|     Jihlava|6/7/2023 13:02|   Basil Mozzetti|            Male|         A1|     IDR|            C3|    Cancelled|     Talbert Barck| Embraer E190|         6101.28|     3012|         1561|              PBH|        Indonesia|6/7/2023 10:46|      Czech Republic|   20/5/2022|          19.08|           48|            Indonesia|      115.28|         12.64|          E5|     Jeremy Petrenko|               2|               N67890|         443.26|       4|2025_03_10_22_45_25|\n",
      "|3013|01H4EEMVNYX6VS5D6...|  United|      Xitieshan|     29/7/2022|            AGE|  Nueva Loja|6/7/2023 08:36|      Kelsy Navan|          Female|         B2|     CNY|            A1|      On Time|       Rani Tabert|   Boeing 737|         6298.39|     3013|         4624|              BOY|            China|6/7/2023 02:44|             Ecuador|   16/8/2022|          16.23|           67|            Argentina|      288.93|         38.04|          E5|     Tammie Crommett|               5|               N12345|        4399.32|       4|2025_03_10_22_45_25|\n",
      "|3014|01H4EEMVP1RK5T6SX...|  United|       Tabalong|    20/12/2022|            IQQ|      Miętne|6/7/2023 10:53|    Jarrad Anglin|            Male|         A1|     PHP|            C3|    Cancelled|       Patric Nani|   Boeing 737|         1406.07|     3014|         7268|              LZI|      Philippines|6/7/2023 11:29|              Poland|   19/3/2022|          13.76|           93|            Indonesia|      844.43|         39.72|          F6|       Eugene Hurles|               1|               NABCDE|        1667.79|       4|2025_03_10_22_45_25|\n",
      "|3015|01H4EEMVP4N8WF1TM...|American|         Khōshī|    12/12/2022|            DEP|    Nahāvand|6/7/2023 11:58|Emlynne Clemensen|          Female|         A1|     AFN|            B2|      Delayed|   Bertine Gilbert| Embraer E190|         6451.83|     3015|          993|              NCO|      Afghanistan|6/7/2023 14:26|                Iran|   26/8/2022|          16.16|           35|              Germany|      163.23|         46.21|          D4|Jessalin Domenich...|               4|               NABCDE|        3874.91|       4|2025_03_10_22_45_25|\n",
      "|3016|01H4EEMVP7A3H0FGZ...|  United| Kout na Šumavě|     25/1/2022|            CXR|      Bilice|6/7/2023 13:31|  Jodie Philippon|            Male|         B2|     CZK|            C3|      On Time|Tobit Kettlestring| Embraer E190|         7765.82|     3016|         4814|                0|   Czech Republic|6/7/2023 15:27|             Croatia|    2/1/2022|          11.86|           49|            Indonesia|      595.83|         32.91|          F6|       Gill Steggles|               5|               N12345|         1537.0|       4|2025_03_10_22_45_25|\n",
      "|3017|01H4EEMVPAX52FR68...|  United|       Petřvald|     8/11/2022|            CGP|   Zhangyelu|6/7/2023 09:01|Stephan Pottberry|            Male|         B2|     CZK|            B2|      On Time|    Gardie Chawner|   Boeing 737|         5751.91|     3017|         7809|              MJL|   Czech Republic|6/7/2023 13:38|               China|    3/9/2022|          10.17|           32|               Panama|      948.05|         23.63|          F6|   Newton MacCulloch|               6|               N12345|        2810.95|       4|2025_03_10_22_45_25|\n",
      "|3018|01H4EEMVPEW03WB5W...|   Delta|          Oefau|     15/1/2022|            HEW|      Lianyi|6/7/2023 00:47|       Drona Riby|          Female|         B2|     IDR|            C3|    Cancelled|   Kissiah Karpets|  Airbus A320|          7239.6|     3018|          530|              AIL|        Indonesia|6/7/2023 13:16|               China|   22/2/2022|           22.1|           71|               Brazil|      601.57|          2.14|          D4|       Sharon Deamer|               1|               N67890|        4829.68|       4|2025_03_10_22_45_25|\n",
      "|3019|01H4EEMVPHRNE5KYQ...|  United|Vitry-sur-Seine|    29/12/2022|            CAP|     Lannion|6/7/2023 01:04|    Reid Daniells|            Male|         C3|     EUR|            A1|    Cancelled|   Leonid Carnduff|   Boeing 737|         8743.02|     3019|         3885|              URZ|           France|6/7/2023 10:36|              France|   29/3/2022|          15.44|           26|            Macedonia|      922.98|         21.39|          D4|          Jeno Morot|              10|               NABCDE|        3446.17|       4|2025_03_10_22_45_25|\n",
      "|3020|01H4EEMVPKDYN838W...|   Delta|       Rockford|    22/12/2022|            LUL|   Whakatane|6/7/2023 19:28|  Luise Sinisbury|          Female|         A1|     USD|            B2|    Cancelled|    Mareah Chesher| Embraer E190|         6488.22|     3020|         9455|              GNM|    United States|6/7/2023 09:05|         New Zealand|   20/5/2022|           6.52|           63|               Sweden|      889.22|         28.83|          E5|       Wendi Patroni|               3|               NABCDE|        3070.89|       4|2025_03_10_22_45_25|\n",
      "+----+--------------------+--------+---------------+--------------+---------------+------------+--------------+-----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 5 at 2025_03_10_22_45_35\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|5       |2025_03_10_22_45_35|China                |Female          |40           |310.0433333333333 |930.1299999999999 |3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Female          |88           |637.7766666666666 |1913.33           |3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Female          |26           |243.08333333333334|729.25            |3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Male            |57           |754.3233333333333 |2262.97           |3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Male            |99           |527.57            |1582.71           |3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Male            |86           |487.79            |1463.3700000000001|3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Male            |26           |501.40333333333325|1504.2099999999998|3               |\n",
      "|5       |2025_03_10_22_45_35|China                |Male            |30           |702.2133333333335 |2106.6400000000003|3               |\n",
      "|5       |2025_03_10_22_45_35|Indonesia            |Female          |57           |377.4433333333333 |1132.33           |3               |\n",
      "|5       |2025_03_10_22_45_35|Indonesia            |Female          |89           |456.5866666666666 |1369.7599999999998|3               |\n",
      "|5       |2025_03_10_22_45_35|Indonesia            |Male            |34           |408.89000000000004|1226.67           |3               |\n",
      "|5       |2025_03_10_22_45_35|Indonesia            |Male            |36           |257.6266666666667 |772.8800000000001 |3               |\n",
      "|5       |2025_03_10_22_45_35|Indonesia            |Male            |24           |650.1233333333333 |1950.37           |3               |\n",
      "|5       |2025_03_10_22_45_35|Russia               |Male            |69           |435.7966666666666 |1307.3899999999999|3               |\n",
      "|5       |2025_03_10_22_45_35|Indonesia            |Female          |85           |706.0025          |2824.01           |4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+----+--------------------+--------+--------------+--------------+---------------+--------------------+--------------+----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline|departure_city|departure_date|arrival_airport|        arrival_city|  arrival_time|  passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|     co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|          pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+--------------------+--------------+----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|4001|01H4EEMZ2SXKZAF4E...|  United|     Xiabaishi|     1/12/2022|            VPZ|         Saltsjö-Boo|6/7/2023 07:38|    Erasmus Grim|     Genderqueer|         C3|     CNY|            A1|      On Time|       Brandy Epps| Embraer E190|         2394.39|     4001|         4693|              NTD|            China|6/7/2023 09:12|         Sweden|   16/5/2022|          11.36|           81|                China|      150.89|         29.04|          F6|     Karlik Clemetts|               8|               N12345|        3621.45|       5|2025_03_10_22_45_35|\n",
      "|4002|01H4EEMZ2WS3WW5CZ...|  United|       Mê Linh|     12/8/2022|            MWD|              Sogati|6/7/2023 13:29|      Cam Aucock|            Male|         B2|     VND|            C3|    Cancelled|Stanleigh Pickring|   Boeing 737|         7216.32|     4002|         8158|              UNK|          Vietnam|6/7/2023 21:27|      Indonesia|  29/11/2022|          12.04|           21|                 Peru|      455.35|         48.34|          F6|    Bentley Liddyard|               6|               N12345|        1711.91|       5|2025_03_10_22_45_35|\n",
      "|4003|01H4EEMZ2ZW67GYEM...|  United|  Buenos Aires|    25/12/2022|            WPK|       Weiwangzhuang|6/7/2023 16:50|   Finlay Wickes|            Male|         A1|     PEN|            B2|    Cancelled|      Fee Bilsford|   Boeing 737|         8360.83|     4003|         2466|              YPY|             Peru|6/7/2023 05:09|          China|  25/12/2022|          19.34|           66|               Brazil|      215.23|         11.09|          E5|  Garreth O'Doireidh|               2|               N12345|          296.9|       5|2025_03_10_22_45_35|\n",
      "|4004|01H4EEMZ31684170Q...|  United|  Tosontsengel|     27/3/2022|            FXO|           Luozhuang|6/7/2023 21:10|     Hyman Bever|            Male|         B2|     MNT|            C3|      On Time|Jefferson McSorley|  Airbus A320|         5421.46|     4004|         4808|              OBI|         Mongolia|6/7/2023 13:19|          China|   19/7/2022|          13.39|           55|       Czech Republic|      943.96|          0.44|          F6|       Prent Durston|               5|               N67890|        3848.62|       5|2025_03_10_22_45_35|\n",
      "|4005|01H4EEMZ34D4N4G1A...|American|       Lingion|    13/11/2022|            TUM|           Razumnoye|6/7/2023 18:32| Nicholas Shoute|         Agender|         C3|     PHP|            C3|      Delayed|   Munmro Shobrook|  Airbus A320|         4692.56|     4005|         7780|              WOW|      Philippines|6/7/2023 12:58|         Russia|   23/6/2022|           5.97|           50|            Guatemala|      800.65|         39.53|          E5|         Ilse Boleyn|               5|               N12345|        2686.87|       5|2025_03_10_22_45_35|\n",
      "|4006|01H4EEMZ3715ATHW6...|  United|         Xi’an|     20/7/2022|            AGE|               Dadus|6/7/2023 17:31|    Anna Janusik|          Female|         B2|     CNY|            A1|    Cancelled|     Starr Muttitt|  Airbus A320|          9098.8|     4006|         3020|              CYX|            China|6/7/2023 19:06|    Philippines|  24/12/2022|           5.97|           65|             Thailand|        88.2|         14.71|          E5|     Chloris Clemson|               8|               NABCDE|        2550.13|       5|2025_03_10_22_45_35|\n",
      "|4007|01H4EEMZ3A36BRPP7...|  United|    Louisville|     19/4/2022|            SBQ|             Pengshi|6/7/2023 16:22|    Galvan Conen|            Male|         A1|     USD|            A1|      Delayed|       Mick Yeeles|  Airbus A320|         7936.96|     4007|         9094|              APR|    United States|6/7/2023 08:16|          China|   28/8/2022|           1.25|           69|               Russia|      591.46|         30.86|          F6| Eziechiele Yanukhin|               6|               N12345|         508.38|       5|2025_03_10_22_45_35|\n",
      "|4008|01H4EEMZ3DH0JP5ZW...|American|     Tianhekou|    18/12/2022|            FAN|             Byczyna|6/7/2023 02:07|  Elga Brittoner|     Genderqueer|         B2|     CNY|            B2|      On Time|   Merrilee Hepher|   Boeing 737|         6015.65|     4008|         3479|              NIA|            China|6/7/2023 16:06|         Poland|   29/4/2022|          16.78|           89|                China|      606.42|         37.33|          F6|L;urette Klemensi...|               9|               NABCDE|        2732.92|       5|2025_03_10_22_45_35|\n",
      "|4009|01H4EEMZ3GA5ERHG2...|   Delta|       Palmira|    10/11/2022|            HOY|         Puente Alto|6/7/2023 05:35| Giulia Stanyard|          Female|         A1|     CUP|            C3|      On Time|     Kimberley Cox|  Airbus A320|          2313.6|     4009|         6575|              HAN|             Cuba|6/7/2023 06:49|          Chile|  21/10/2022|          18.92|           66|               Brazil|      510.82|         37.64|          D4|        Milka Phelip|              10|               N12345|        2244.74|       5|2025_03_10_22_45_35|\n",
      "|4010|01H4EEMZ3JM7SVK45...|  United|       Saratov|      4/2/2022|            URC|                Erqu|6/7/2023 06:43|   Yorgo Crevagh|            Male|         A1|     RUB|            B2|      Delayed|      Tonnie Sugge|  Airbus A320|         4166.37|     4010|         7556|              COB|           Russia|6/7/2023 03:35|          China|    9/4/2022|           7.39|           27|                China|      352.64|         18.91|          E5|         Chuck Karle|               6|               N12345|        2054.21|       5|2025_03_10_22_45_35|\n",
      "|4011|01H4EEMZ3NJXP2YQ6...|  United|        Wichit|     16/7/2022|            SWH|          Pindi Gheb|6/7/2023 18:38|   Zora Gransden|      Polygender|         C3|     THB|            C3|    Cancelled|      Olin Niblock|   Boeing 737|          7841.5|     4011|         7459|              ZUL|         Thailand|6/7/2023 20:04|       Pakistan|    7/4/2022|          23.35|           74|               Uganda|       752.9|          6.87|          D4|        Lilly Selman|               1|               N67890|         933.04|       5|2025_03_10_22_45_35|\n",
      "|4012|01H4EEMZ3R8717JMW...|   Delta|        Siaton|     27/1/2022|            LID|           Liangting|6/7/2023 08:24|    Hadria Palek|          Female|         A1|     PHP|            A1|      On Time|    Evania Milmith|   Boeing 737|         2251.44|     4012|         4222|              STC|      Philippines|6/7/2023 23:14|          China|    6/8/2022|          20.64|           71|               Russia|      146.37|          28.4|          F6|        Calli Duffer|               9|               N67890|        3071.08|       5|2025_03_10_22_45_35|\n",
      "|4013|01H4EEMZ3VN81QE2K...|  United|      Kengyuan|      1/3/2022|            BSW|               Lebak|6/7/2023 04:41| Tobias Madgwick|     Genderqueer|         B2|     CNY|            A1|    Cancelled|     Portie Armour|  Airbus A320|         9524.27|     4013|         9396|              TOC|            China|6/7/2023 02:58|      Indonesia|  12/10/2022|           6.23|           42|               Poland|      789.11|         40.11|          E5|   Gorden Biaggiotti|              10|               NABCDE|         4339.5|       5|2025_03_10_22_45_35|\n",
      "|4014|01H4EEMZ3Y8X5GCPW...|  United|     Yuqunweng|    29/11/2022|            IGG|           Gujiadian|6/7/2023 20:58|  Adolph Authers|            Male|         B2|     CNY|            C3|      On Time|  Theodoric Winear|  Airbus A320|         2898.94|     4014|         1974|              VCF|            China|6/7/2023 21:41|          China|   15/8/2022|          20.56|           41|               Russia|      220.54|         34.67|          E5|        Brew Jerrems|               4|               NABCDE|        1593.54|       5|2025_03_10_22_45_35|\n",
      "|4015|01H4EEMZ41ZW530RC...|  United|      Křižanov|     13/7/2022|            CUU|            Diaofeng|6/7/2023 02:01|  Merrel Maroney|            Male|         A1|     CZK|            B2|      Delayed| Forrester Keohane|   Boeing 737|         3862.35|     4015|         8595|              PBP|   Czech Republic|6/7/2023 09:56|          China|   13/3/2022|          18.34|           21|               Serbia|      372.29|         44.18|          E5|        Arny Whatham|               5|               NABCDE|        4975.33|       5|2025_03_10_22_45_35|\n",
      "|4016|01H4EEMZ43S0AWGF3...|American|         Panay|     29/5/2022|            MAX|              Huazhu|6/7/2023 01:04|Sebastian Allitt|            Male|         C3|     PHP|            B2|      Delayed|   Camey Barkhouse|  Airbus A320|         8720.71|     4016|         6493|              BOA|      Philippines|6/7/2023 21:23|          China|   15/6/2022|          16.61|           19|              Austria|      580.01|          4.57|          F6|      Riobard Skitch|               9|               NABCDE|        4069.38|       5|2025_03_10_22_45_35|\n",
      "|4017|01H4EEMZ46GS5AYC8...|  United|       Canillo|    22/10/2022|            QGP|          Kryvyy Rih|6/7/2023 00:10|    Katti Surgen|          Female|         C3|     EUR|            A1|      Delayed|     Bobbye Scryne| Embraer E190|         3497.85|     4017|         2533|              TIP|          Andorra|6/7/2023 18:04|        Ukraine|  18/11/2022|          22.79|          100|               Russia|      291.34|          0.08|          E5|   Jocelin Jendrusch|               3|               N67890|        3745.24|       5|2025_03_10_22_45_35|\n",
      "|4018|01H4EEMZ499STC5SE...|   Delta| Rio Brilhante|     21/9/2022|            YYM|                Hōfu|6/7/2023 22:10|  Farley Iltchev|            Male|         C3|     BRL|            C3|      Delayed|  Earlie Chasemore|   Boeing 737|         6980.72|     4018|         8297|              RBT|           Brazil|6/7/2023 17:40|          Japan|   19/7/2022|          22.03|           68|            Indonesia|      549.51|          4.76|          E5|       Thatch Earley|              10|               N67890|        4776.57|       5|2025_03_10_22_45_35|\n",
      "|4019|01H4EEMZ4CMYK6PEK...|  United|       Chapecó|    30/11/2022|            TJC|         Montbéliard|6/7/2023 21:10|   Rosene Chiles|          Female|         A1|     BRL|            B2|      Delayed|   April O' Timony|  Airbus A320|         7990.26|     4019|         1216|              RDG|           Brazil|6/7/2023 22:54|         France|   2/11/2022|           7.07|           30|              Senegal|      695.27|           7.1|          D4|   Gertrudis Marklew|               8|               N12345|        2954.73|       5|2025_03_10_22_45_35|\n",
      "|4020|01H4EEMZ4FK7SXVVN...|American|      Lamalera|     17/3/2022|            IFA|Kedungbanteng Krajan|6/7/2023 16:41|  Fowler Leggitt|     Genderqueer|         B2|     IDR|            C3|    Cancelled|    Terrel Gowrich|  Airbus A320|         4548.78|     4020|         9387|              JVL|        Indonesia|6/7/2023 07:56|      Indonesia|   11/6/2022|          22.12|           30|              Ukraine|      722.77|         39.26|          F6|   Garreth Kornousek|               7|               NABCDE|        4409.26|       5|2025_03_10_22_45_35|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+--------------------+--------------+----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark_session = SparkSession.builder.appName(\"KafkaStreamingApp\").getOrCreate()\n",
    "\n",
    "def read_streaming_data(\n",
    "    spark_session,\n",
    "    kafka_bootstrap_servers,\n",
    "    input_topic,\n",
    "    output_topic,\n",
    "    checkpoint_location,\n",
    "    files_directory,\n",
    "):\n",
    "\n",
    "    # Read from Kafka in streaming mode\n",
    "    kafkaStream = (\n",
    "        spark_session.readStream.format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "        .option(\"subscribe\", input_topic)\n",
    "        .option(\"startingOffsets\", \"earliest\")\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "    # Perform some transformation on the data (here we are simply renaming the columns and uppercase the values)\n",
    "    kafkaTransformedStream = kafkaStream.selectExpr(\n",
    "        \"CAST(key AS STRING) as key\", \"UPPER(CAST(value AS STRING)) as value\"\n",
    "    )\n",
    "\n",
    "    # Configure a streaming write query to write data to Parquet format\n",
    "    kafkaStreamSaveToParquet = (\n",
    "        kafkaTransformedStream.writeStream.outputMode(\"append\")\n",
    "        .format(\"parquet\")\n",
    "        .option(\"path\", files_directory)\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .trigger(processingTime=\"1 minute\")\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    # Define a function to process each batch and print it without truncating\n",
    "    def process_batch(\n",
    "        batch_df,\n",
    "        batch_id,\n",
    "        kafka_bootstrap_servers,\n",
    "        input_topic,\n",
    "        output_topic,\n",
    "        checkpoint_location,\n",
    "        files_directory,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Processes each batch of the streaming DataFrame and displays it as a Pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - batch_df (DataFrame): The DataFrame containing the batch data.\n",
    "        - batch_id (int): The ID of the batch being processed.\n",
    "        - kafka_bootstrap_servers (str): The Kafka bootstrap servers.\n",
    "        - input_topic (str): The input Kafka topic.\n",
    "        - output_topic (str): The output Kafka topic.\n",
    "        - checkpoint_location (str): The location for checkpointing.\n",
    "        - files_directory (str): The directory path for saving files.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Print the batch ID for identification\n",
    "        print(f\"Batch ID : {batch_id}\")\n",
    "\n",
    "        # Collect key-value pairs from the batch DataFrame\n",
    "        key_values = batch_df.select(col(\"key\"), col(\"value\")).collect()\n",
    "\n",
    "        # Initialize an empty list to store data for the Pandas DataFrame\n",
    "        data = []\n",
    "\n",
    "        # Iterate through key-value pairs\n",
    "        for row in key_values:\n",
    "            # Extract the key and value directly as they are not JSON\n",
    "            row_data = {\n",
    "                \"key\": row[\"key\"],\n",
    "                \"value\": row[\"value\"],\n",
    "                \"input_topic\": input_topic,\n",
    "                \"output_topic\": output_topic,\n",
    "                \"checkpoint_location\": checkpoint_location,\n",
    "                \"files_directory\": files_directory\n",
    "            }\n",
    "\n",
    "            # Append the dictionary to the data list\n",
    "            data.append(row_data)\n",
    "\n",
    "        # Create a Pandas DataFrame from the collected data\n",
    "        df_pandas = pd.DataFrame(data)\n",
    "\n",
    "        # Display the Pandas DataFrame\n",
    "        display(df_pandas)\n",
    "\n",
    "    from functools import partial\n",
    "\n",
    "    # Create a partial function with the additional parameters\n",
    "    partial_process_batch = partial(\n",
    "        process_batch,\n",
    "        kafka_bootstrap_servers=kafka_bootstrap_servers,\n",
    "        input_topic=input_topic,\n",
    "        output_topic=output_topic,\n",
    "        checkpoint_location=checkpoint_location,\n",
    "        files_directory=files_directory,\n",
    "    )\n",
    "\n",
    "    # Configure a streaming write query to send data to Kafka, and use a function into foreach for show content without truncate\n",
    "    kafkaStreamWriter = (\n",
    "        kafkaTransformedStream.writeStream.option(\"failOnDataLoss\", \"false\")\n",
    "        .outputMode(\"append\")\n",
    "        .format(\"kafka\")\n",
    "        .option(\"truncate\", \"false\")\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "        .option(\"topic\", output_topic)\n",
    "        .foreachBatch(partial_process_batch)\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    print(\"kafkaStream\", type(kafkaStream))\n",
    "    print(\"transformedStream\", type(kafkaTransformedStream))\n",
    "    print(\"query\", type(kafkaStreamWriter))\n",
    "\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "input_topic = \"animals-topic-batch\"\n",
    "output_topic = \"animals-topic-streaming\"\n",
    "# Checkpoint directory within the Kafka directory\n",
    "checkpoint_location = \"/usr/local/kafka/data/checkpoint\"\n",
    "files_directory = \"/usr/local/kafka/data/files\"\n",
    "\n",
    "read_streaming_data(\n",
    "    spark_session,\n",
    "    kafka_bootstrap_servers,\n",
    "    input_topic,\n",
    "    output_topic,\n",
    "    checkpoint_location,\n",
    "    files_directory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0bf92-d064-4727-a24e-1f6b06f02ca2",
   "metadata": {},
   "source": [
    "# STREAMING FILES USING FROM DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a87ecc-d707-4e67-a9a5-eaabca9461f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:44:52 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/03/10 22:44:52 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/03/10 22:44:53 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Spark-Kafka-Confluence-Batch-Streaming-MlLib.ipynb\n",
      "25/03/10 22:44:53 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled2.ipynb\n",
      "25/03/10 22:44:53 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled.ipynb\n",
      "25/03/10 22:44:53 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled1.ipynb\n",
      "25/03/10 22:44:54 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled1.ipynb\n",
      "25/03/10 22:44:54 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled2.ipynb\n",
      "25/03/10 22:44:54 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled.ipynb\n",
      "25/03/10 22:44:54 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Spark-Kafka-Confluence-Batch-Streaming-MlLib.ipynb\n",
      "25/03/10 22:44:56 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Spark-Kafka-Confluence-Batch-Streaming-MlLib.ipynb\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, expr, lit\n",
    "from pyspark.sql.types import (\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "\n",
    "def process_batch(directory_to_save_files, df, epoch_id):\n",
    "\n",
    "    # Generate a timestamp\n",
    "    timestamp_str = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Add epoch_id and timestamp_str as new columns\n",
    "    df = df.withColumn(\"batch_id\", lit(epoch_id)).withColumn(\n",
    "        \"timestamp\", lit(timestamp_str)\n",
    "    )\n",
    "\n",
    "    # Print information about the new batch\n",
    "    print(f\"Processing microbatch {epoch_id} at {timestamp_str}\")\n",
    "\n",
    "    # Group by specified columns and calculate the average ticket price\n",
    "    grouped_df = df.groupBy(\n",
    "        \"batch_id\",\n",
    "        \"timestamp\",\n",
    "        \"passenger_nationality\",\n",
    "        \"passenger_gender\",\n",
    "        \"passenger_age\",\n",
    "    ).agg(\n",
    "        F.avg(\"ticket_price\").alias(\"avg_ticket_price\"),\n",
    "        F.sum(\"ticket_price\").alias(\"total_ticket_price\"),\n",
    "        F.count(\"passenger_name\").alias(\"total_passengers\"),\n",
    "    )\n",
    "\n",
    "    # Filter out groups where the total number of passengers is greater than 1\n",
    "    # filtered_df = grouped_df.filter(grouped_df.total_passengers > 1)\n",
    "    # Multiple filter conditions\n",
    "    filtered_df = grouped_df.filter(\n",
    "        (col(\"total_passengers\") > 2) & (col(\"total_passengers\") <= 7)\n",
    "    )\n",
    "\n",
    "    # Sort the DataFrame by passenger_nationality and passenger_age\n",
    "    sorted_df = filtered_df.orderBy(\n",
    "        \"total_passengers\", \"passenger_nationality\", \"passenger_gender\"\n",
    "    )\n",
    "\n",
    "    # Show the sorted DataFrame\n",
    "    sorted_df.show(truncate=False)\n",
    "\n",
    "    # Coalesce to a single partition and write the DataFrame as Parquet with timestamp\n",
    "    maximum_parquet_files_per_batch = 3\n",
    "    sorted_df.coalesce(maximum_parquet_files_per_batch).write.parquet(\n",
    "        f\"{directory_to_save_files}/microbatch_{epoch_id}_{timestamp_str}\"\n",
    "    )\n",
    "\n",
    "    # Show the original DataFrame\n",
    "    df.show()\n",
    "\n",
    "\n",
    "def read_file_like_streaming(\n",
    "    spark_session, customSchema, format, checkpoint_location, directory_to_save_files\n",
    "):\n",
    "\n",
    "    # Read the DataFrame as a continuous stream\n",
    "    streaming_df = (\n",
    "        spark_session.readStream.schema(customSchema)\n",
    "        .format(format)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(folder_files_path)\n",
    "    )\n",
    "\n",
    "    # Display the DataFrame in the console and count the records per microbatch\n",
    "    # .trigger(processingTime='5 seconds') specifies that Spark Structured Streaming should process micro-batches of data from the specified directory every 5 seconds.\n",
    "    query = (\n",
    "        streaming_df.writeStream.outputMode(\"append\")\n",
    "        .trigger(processingTime=\"5 seconds\")\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .option(\"basePath\", directory_to_save_files)\n",
    "        .foreachBatch(\n",
    "            lambda df, epoch_id: process_batch(directory_to_save_files, df, epoch_id)\n",
    "        )\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    # Wait for the streaming to complete\n",
    "    # query.awaitTermination()\n",
    "\n",
    "\n",
    "# Define the schema\n",
    "customSchema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"secure_code\", StringType(), True),\n",
    "        StructField(\"airline\", StringType(), True),\n",
    "        StructField(\"departure_city\", StringType(), True),\n",
    "        StructField(\"departure_date\", StringType(), True),\n",
    "        StructField(\"arrival_airport\", StringType(), True),\n",
    "        StructField(\"arrival_city\", StringType(), True),\n",
    "        StructField(\"arrival_time\", StringType(), True),\n",
    "        StructField(\"passenger_name\", StringType(), True),\n",
    "        StructField(\"passenger_gender\", StringType(), True),\n",
    "        StructField(\"seat_number\", StringType(), True),\n",
    "        StructField(\"currency\", StringType(), True),\n",
    "        StructField(\"departure_gate\", StringType(), True),\n",
    "        StructField(\"flight_status\", StringType(), True),\n",
    "        StructField(\"co_pilot_name\", StringType(), True),\n",
    "        StructField(\"aircraft_type\", StringType(), True),\n",
    "        StructField(\"fuel_consumption\", DoubleType(), True),\n",
    "        StructField(\"flight_id\", IntegerType(), True),\n",
    "        StructField(\"flight_number\", IntegerType(), True),\n",
    "        StructField(\"departure_airport\", StringType(), True),\n",
    "        StructField(\"departure_country\", StringType(), True),\n",
    "        StructField(\"departure_time\", StringType(), True),\n",
    "        StructField(\"arrival_country\", StringType(), True),\n",
    "        StructField(\"arrival_date\", StringType(), True),\n",
    "        StructField(\"flight_duration\", DoubleType(), True),\n",
    "        StructField(\"passenger_age\", IntegerType(), True),\n",
    "        StructField(\"passenger_nationality\", StringType(), True),\n",
    "        StructField(\"ticket_price\", DoubleType(), True),\n",
    "        StructField(\"baggage_weight\", DoubleType(), True),\n",
    "        StructField(\"arrival_gate\", StringType(), True),\n",
    "        StructField(\"pilot_name\", StringType(), True),\n",
    "        StructField(\"cabin_crew_count\", IntegerType(), True),\n",
    "        StructField(\"aircraft_registration\", StringType(), True),\n",
    "        StructField(\"flight_distance\", DoubleType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "format = \"csv\"\n",
    "folder_files_path = \"/notebooks\"\n",
    "directory_to_save_files = \"/usr/local/kafka/data/files/batch\"\n",
    "shutil.rmtree(directory_to_save_files, ignore_errors=True)\n",
    "\n",
    "# Delete the checkpoint directory\n",
    "checkpoint_location = \"/usr/local/kafka/data/batch\"\n",
    "shutil.rmtree(checkpoint_location, ignore_errors=True)\n",
    "\n",
    "read_file_like_streaming(\n",
    "    spark_session=spark_session,\n",
    "    customSchema=customSchema,\n",
    "    format=format,\n",
    "    checkpoint_location=checkpoint_location,\n",
    "    directory_to_save_files=directory_to_save_files,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cf897-dcf0-40ca-a082-d446b80f44e4",
   "metadata": {},
   "source": [
    "# COPY, PASTE, AND RUN THE FOLLOWING CODE IN ANOTHER NOTEBOOK TO OBSERVE STREAMING REDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4f8d6-35aa-460f-a14d-b0c792be1933",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "for index in range(1,6):\n",
    "\n",
    "    part_1 = index\n",
    "    part_2 = index + 5\n",
    "\n",
    "    file_name = 'flight_logs'\n",
    "    final_file = f'{file_name}_{index}.csv'\n",
    "    \n",
    "    file_1 = f'{file_name}_part_1_{index}.csv'\n",
    "    base_url1 = f'https://raw.githubusercontent.com/JorgeCardona/recursos/main/datasets/{file_1}'\n",
    "    df1 = pd.read_csv(base_url1)\n",
    "    \n",
    "    file_2 = f'{file_name}_part_2_{index}.csv'\n",
    "    base_url2 = f'https://raw.githubusercontent.com/JorgeCardona/recursos/main/datasets/{file_2}'\n",
    "    df2 = pd.read_csv(base_url2)\n",
    "\n",
    "    df3 = pd.merge(df1, df2, left_on='id', right_on='flight_id', how='inner')\n",
    "    df3.to_csv(f'{final_file}',index=False)\n",
    "\n",
    "    print(f'{final_file} saved Successfully!!')\n",
    "    sleep(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f64fe-6aac-48d9-95ff-34f9d8a007f6",
   "metadata": {},
   "source": [
    "# LOAD PARQUET FILES DIRECTORY ON DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa23a9d-027e-4fe5-9559-6b3098df2b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>passenger_nationality</th>\n",
       "      <th>passenger_gender</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>avg_ticket_price</th>\n",
       "      <th>total_ticket_price</th>\n",
       "      <th>total_passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Female</td>\n",
       "      <td>88</td>\n",
       "      <td>689.810000</td>\n",
       "      <td>2069.43</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>405.810000</td>\n",
       "      <td>1217.43</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>74</td>\n",
       "      <td>182.436667</td>\n",
       "      <td>547.31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>67</td>\n",
       "      <td>543.413333</td>\n",
       "      <td>1630.24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>455.770000</td>\n",
       "      <td>1367.31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>75</td>\n",
       "      <td>251.740000</td>\n",
       "      <td>755.22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Male</td>\n",
       "      <td>85</td>\n",
       "      <td>826.870000</td>\n",
       "      <td>2480.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>704.322500</td>\n",
       "      <td>2817.29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>91</td>\n",
       "      <td>636.292500</td>\n",
       "      <td>2545.17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>452.027500</td>\n",
       "      <td>1808.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>China</td>\n",
       "      <td>Male</td>\n",
       "      <td>79</td>\n",
       "      <td>514.655000</td>\n",
       "      <td>2058.62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Female</td>\n",
       "      <td>72</td>\n",
       "      <td>379.443333</td>\n",
       "      <td>1138.33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>2025_03_10_22_45_25</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>484.026667</td>\n",
       "      <td>1452.08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_id            timestamp passenger_nationality passenger_gender  \\\n",
       "0          4  2025_03_10_22_45_25                 China           Female   \n",
       "1          4  2025_03_10_22_45_25                 China           Female   \n",
       "2          4  2025_03_10_22_45_25                 China             Male   \n",
       "3          4  2025_03_10_22_45_25                 China             Male   \n",
       "4          4  2025_03_10_22_45_25                 China             Male   \n",
       "5          4  2025_03_10_22_45_25                 China             Male   \n",
       "6          4  2025_03_10_22_45_25                Poland             Male   \n",
       "7          4  2025_03_10_22_45_25                 China             Male   \n",
       "8          4  2025_03_10_22_45_25                 China             Male   \n",
       "9          4  2025_03_10_22_45_25                 China             Male   \n",
       "10         4  2025_03_10_22_45_25                 China             Male   \n",
       "11         4  2025_03_10_22_45_25             Indonesia           Female   \n",
       "12         4  2025_03_10_22_45_25             Indonesia             Male   \n",
       "\n",
       "    passenger_age  avg_ticket_price  total_ticket_price  total_passengers  \n",
       "0              88        689.810000             2069.43                 3  \n",
       "1              40        405.810000             1217.43                 3  \n",
       "2              74        182.436667              547.31                 3  \n",
       "3              67        543.413333             1630.24                 3  \n",
       "4              81        455.770000             1367.31                 3  \n",
       "5              75        251.740000              755.22                 3  \n",
       "6              85        826.870000             2480.61                 3  \n",
       "7              58        704.322500             2817.29                 4  \n",
       "8              91        636.292500             2545.17                 4  \n",
       "9              18        452.027500             1808.11                 4  \n",
       "10             79        514.655000             2058.62                 4  \n",
       "11             72        379.443333             1138.33                 3  \n",
       "12             18        484.026667             1452.08                 3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "def find_microbatch_file(directory):\n",
    "    \"\"\"\n",
    "    Busca un archivo en el directorio especificado que contiene el término \"microbatch\" en su nombre.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): La ruta del directorio donde se buscarán los archivos.\n",
    "\n",
    "    Returns:\n",
    "    - str: El nombre del archivo que contiene el término \"microbatch\" en su nombre, o una cadena vacía si no se encuentra.\n",
    "    \"\"\"\n",
    "    # Listar todos los archivos en el directorio\n",
    "    all_files = os.listdir(directory)\n",
    "\n",
    "    # Inicializar la variable para almacenar el nombre del archivo microbatch\n",
    "    microbatch_file_name = \"\"\n",
    "\n",
    "    # Buscar el archivo que contiene el término \"microbatch\" en su nombre\n",
    "    for file_name in all_files:\n",
    "        if \"microbatch\" in file_name:\n",
    "            microbatch_file_name = file_name\n",
    "\n",
    "    return microbatch_file_name\n",
    "\n",
    "\n",
    "def read_parquet_directory_into_dataframe(directory_path):\n",
    "    \"\"\"\n",
    "    Reads all Parquet files from a directory into a single pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path (str): Path to the directory containing Parquet files.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Combined DataFrame containing data from all Parquet files.\n",
    "    \"\"\"\n",
    "    # Use glob to get a list of all Parquet file paths in the specified directory\n",
    "    parquet_files = glob.glob(f\"{directory_path}/*.parquet\")\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through each Parquet file and read it into a DataFrame\n",
    "    for parquet_file in parquet_files:\n",
    "        # Read Parquet file into a DataFrame\n",
    "        df = pq.read_table(parquet_file).to_pandas()\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Specify the directory where Parquet files are located\n",
    "directory_to_save_files = \"/usr/local/kafka/data/files/batch\"\n",
    "microbatch_parquet_directory_name = find_microbatch_file(\n",
    "    directory=directory_to_save_files\n",
    ")\n",
    "directory_path = f\"{directory_to_save_files}/{microbatch_parquet_directory_name}/\"\n",
    "\n",
    "read_parquet_directory_into_dataframe(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912aab18-669b-4d64-b6fb-31b3b6c71114",
   "metadata": {},
   "source": [
    "# SPARK MLLIB + SCIKIT LEARN\n",
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07f88fea-b54c-4d62-9a6a-80bea1dd0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator,\n",
    "    RegressionEvaluator,\n",
    ")\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, format_number, lit, udf, when\n",
    "from pyspark.sql.types import FloatType, StringType, StructField, StructType\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6799c2-aa8c-4637-9922-3572221f7462",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f2e294-6a8a-4699-881d-a66c347b91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    Create a Spark session.\n",
    "\n",
    "    Returns:\n",
    "    - spark_session (SparkSession): A SparkSession object.\n",
    "    \"\"\"\n",
    "    spark_session = (\n",
    "        SparkSession.builder.master(\"local\")\n",
    "        .appName(\"scikit-learn-with-spark\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    return spark_session\n",
    "\n",
    "\n",
    "def create_dataframe_from_dataset(\n",
    "    dataset,\n",
    "    dataset_data_key=\"data\",\n",
    "    dataset_columns=[\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"],\n",
    "    dataset_data_target=\"target\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame from a dataset dictionary.\n",
    "\n",
    "    Args:\n",
    "    - dataset (dict): The dataset dictionary containing data and target keys.\n",
    "    - dataset_data_key (str): The key in the dataset dictionary corresponding to the data.\n",
    "    - dataset_columns (list): List of column names for the DataFrame.\n",
    "    - dataset_data_target (str): The key in the dataset dictionary corresponding to the target.\n",
    "\n",
    "    Returns:\n",
    "    - df (DataFrame): A pandas DataFrame containing the data and target from the dataset dictionary.\n",
    "    \"\"\"\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(dataset[dataset_data_key], columns=dataset_columns)\n",
    "    df[dataset_data_target] = dataset[dataset_data_target]\n",
    "\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def create_multiple_samples_datasets(\n",
    "    original_dataset, n_datasets, n_records, delay_time=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Create multiple datasets from an original dataset.\n",
    "\n",
    "    Args:\n",
    "    - original_dataset (Bunch): The original dataset from which to create new datasets.\n",
    "    - n_datasets (int): Number of datasets to create.\n",
    "    - n_records (int): Number of records in each new dataset.\n",
    "    - delay_time (int): Time to wait (in seconds) between creating each dataset.\n",
    "\n",
    "    Returns:\n",
    "    - datasets (list): A list of pandas DataFrames, each representing a new dataset.\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "\n",
    "    for dataset_index in range(n_datasets):\n",
    "        # Create a new dataset with n random records\n",
    "        indices = np.random.choice(\n",
    "            range(len(original_dataset.data)), size=n_records, replace=False\n",
    "        )\n",
    "        data = original_dataset.data[indices]\n",
    "        target = original_dataset.target[indices]\n",
    "        new_dataset = pd.DataFrame(data, columns=original_dataset.feature_names)\n",
    "        new_dataset[\"target\"] = target\n",
    "        datasets.append(new_dataset)\n",
    "\n",
    "        # Write new dataset to a CSV file\n",
    "        new_dataset.to_csv(f\"new_dataset_{dataset_index}.csv\", index=False)\n",
    "\n",
    "        # Wait for a specified delay time\n",
    "        sleep(delay_time)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the Iris dataset and display it as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - data_features (array): Array containing the features of the Iris dataset.\n",
    "    - target_classes (array): Array containing the target classes of the Iris dataset.\n",
    "    \"\"\"\n",
    "    # Load the Iris dataset\n",
    "    dataset = load_iris()\n",
    "    data_features, target_classes = dataset.data, dataset.target\n",
    "    key_column = \"data\"\n",
    "    features_columns = [\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"]\n",
    "    taget_column = \"target\"\n",
    "\n",
    "    create_dataframe_from_dataset(\n",
    "        dataset,\n",
    "        dataset_data_key=key_column,\n",
    "        dataset_columns=features_columns,\n",
    "        dataset_data_target=taget_column,\n",
    "    )\n",
    "\n",
    "    return data_features, target_classes\n",
    "\n",
    "\n",
    "def load_dataset_from_csv(csv_file):\n",
    "    \"\"\"\n",
    "    Load the Iris dataset from a CSV file and display it as a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file containing the Iris dataset.\n",
    "\n",
    "    Returns:\n",
    "        - data_features (array): Array containing the features of the Iris dataset.\n",
    "        - target_classes (array): Array containing the target classes of the Iris dataset.\n",
    "    \"\"\"\n",
    "    # Load the Iris dataset from the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Separate the feature columns and the target column\n",
    "    features_columns = [\n",
    "        \"sepal length (cm)\",\n",
    "        \"sepal width (cm)\",\n",
    "        \"petal length (cm)\",\n",
    "        \"petal width (cm)\",\n",
    "    ]\n",
    "    target_column = \"class\"\n",
    "\n",
    "    data_features = df[features_columns].values\n",
    "    target_classes = df[target_column].values\n",
    "\n",
    "    return data_features, target_classes\n",
    "\n",
    "\n",
    "def split_dataset_train_testing(data_features, target_classes):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "    - data_features (array): Array containing the features of the dataset.\n",
    "    - target_classes (array): Array containing the target classes of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - data_features_train_splitted (array): Features of the training set.\n",
    "    - data_features_test_splitted (array): Features of the testing set.\n",
    "    - target_classes_train_splitted (array): Target classes of the training set.\n",
    "    - target_classes_test_splitted (array): Target classes of the testing set.\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    (\n",
    "        data_features_train_splitted,\n",
    "        data_features_test_splitted,\n",
    "        target_classes_train_splitted,\n",
    "        target_classes_test_splitted,\n",
    "    ) = train_test_split(data_features, target_classes, test_size=0.2, random_state=42)\n",
    "\n",
    "    return (\n",
    "        data_features_train_splitted,\n",
    "        data_features_test_splitted,\n",
    "        target_classes_train_splitted,\n",
    "        target_classes_test_splitted,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_filtered_dataset(data_features_dataset, target_classes_dataset):\n",
    "    \"\"\"\n",
    "    Convert dataset features and target classes to appropriate formats.\n",
    "\n",
    "    Args:\n",
    "    - data_features_dataset (array): Array containing the features of the dataset.\n",
    "    - target_classes_dataset (array): Array containing the target classes of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - data_features_filtered (list): List of feature vectors converted to Vectors.dense format.\n",
    "    - target_classes_filtered (list): List of target classes converted to floats.\n",
    "    \"\"\"\n",
    "    # Convert numpy values to Python floats\n",
    "    data_features_filtered = [\n",
    "        Vectors.dense(features) for features in data_features_dataset\n",
    "    ]\n",
    "    target_classes_filtered = [\n",
    "        float(label) for label in target_classes_dataset\n",
    "    ]  # Convert to float\n",
    "\n",
    "    return data_features_filtered, target_classes_filtered\n",
    "\n",
    "\n",
    "def create_spark_dataframe(\n",
    "    sparkml_session, data_features_dataset, target_classes_dataset\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a Spark DataFrame from the dataset features and target classes.\n",
    "\n",
    "    Args:\n",
    "    - data_features_dataset (array): Array containing the features of the dataset.\n",
    "    - target_classes_dataset (array): Array containing the target classes of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - final_data_set (DataFrame): A Spark DataFrame containing the features and target classes.\n",
    "    \"\"\"\n",
    "    # Create Spark DataFrames from training data\n",
    "    data_set = list(zip(data_features_dataset, target_classes_dataset))\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"features\", VectorUDT(), True),\n",
    "            StructField(\"label\", FloatType(), True),\n",
    "        ]\n",
    "    )\n",
    "    final_data_set = sparkml_session.createDataFrame(data_set, schema=schema)\n",
    "\n",
    "    return final_data_set\n",
    "\n",
    "\n",
    "def create_ml_trained_model(train_df):\n",
    "    \"\"\"\n",
    "    Create and train a logistic regression model.\n",
    "\n",
    "    Args:\n",
    "    - train_df (DataFrame): DataFrame containing the training data.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained logistic regression model.\n",
    "    \"\"\"\n",
    "    # Create and train a logistic regression model\n",
    "    lr = LogisticRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        maxIter=10,\n",
    "        regParam=0.3,\n",
    "        elasticNetParam=0.8,\n",
    "    )\n",
    "    model = lr.fit(train_df)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_prediction(model, test_df):\n",
    "    \"\"\"\n",
    "    Make predictions using a trained model and display the results.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained machine learning model.\n",
    "    - test_df (DataFrame): DataFrame containing the test data.\n",
    "\n",
    "    Returns:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "    \"\"\"\n",
    "    # Make predictions on the test data\n",
    "    prediction_result = model.transform(test_df)\n",
    "    # Format prediction column to display two decimal places\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"formatted_prediction\", format_number(\"prediction\", 2)\n",
    "    )\n",
    "\n",
    "    # Map numeric labels back to target names\n",
    "    target_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    label_to_name_udf = udf(lambda label: target_names[int(label)], StringType())\n",
    "\n",
    "    # Create new columns with predicted and actual class names\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"predicted_class_name\", label_to_name_udf(\"prediction\")\n",
    "    )\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"actual_class_name\", label_to_name_udf(\"label\")\n",
    "    )\n",
    "\n",
    "    # Add new column to indicate correct or incorrect classification\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"correctly_classified\",\n",
    "        when(\n",
    "            prediction_result[\"predicted_class_name\"]\n",
    "            == prediction_result[\"actual_class_name\"],\n",
    "            \"✓\",\n",
    "        ).otherwise(\"❌\"),\n",
    "    )\n",
    "\n",
    "    # Display the results\n",
    "    prediction_result.show()\n",
    "\n",
    "    return prediction_result\n",
    "\n",
    "\n",
    "def mse_rmse_mae_r2_avaluator(prediction_result):\n",
    "    \"\"\"\n",
    "    Evaluate regression metrics including MSE, RMSE, MAE, and R2 score.\n",
    "\n",
    "    Args:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    regression_evaluator_mse = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mse\"\n",
    "    )\n",
    "    print(\n",
    "        \"Mean Squared Error (Regression):\",\n",
    "        round(regression_evaluator_mse.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    regression_evaluator_rmse = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\"\n",
    "    )\n",
    "    print(\n",
    "        \"Root Mean Squared Error (Regression):\",\n",
    "        round(regression_evaluator_rmse.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    regression_evaluator_mae = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mae\"\n",
    "    )\n",
    "    print(\n",
    "        \"Mean Absolute Error (Regression):\",\n",
    "        round(regression_evaluator_mae.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    # R2 Score (Regression)\n",
    "    r2_evaluator = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"r2\"\n",
    "    )\n",
    "    print(\n",
    "        \"R2 Score (Regression):\",\n",
    "        round(r2_evaluator.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "\n",
    "def accuracy_f1Score_precision_recall_evaluator(prediction_result):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using accuracy, F1 score, precision, and recall metrics.\n",
    "\n",
    "    Args:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Accuracy\n",
    "    evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\"\n",
    "    )\n",
    "    accuracy = evaluator_accuracy.evaluate(prediction_result)\n",
    "    print(f\"Accuracy: {round(accuracy,4)*100} %\")\n",
    "\n",
    "    # F1 Score\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\"\n",
    "    )\n",
    "    f1_score = evaluator_f1.evaluate(prediction_result)\n",
    "    print(f\"F1 Score: {round(f1_score,4)*100} %\")\n",
    "\n",
    "    # Precision\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedPrecision\"\n",
    "    )\n",
    "    precision = evaluator_precision.evaluate(prediction_result)\n",
    "    print(f\"Precision: {round(precision,4)*100} %\")\n",
    "\n",
    "    # Recall\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedRecall\"\n",
    "    )\n",
    "    recall = evaluator_recall.evaluate(prediction_result)\n",
    "    print(f\"Recall: {round(recall,4)*100} %\")\n",
    "\n",
    "\n",
    "def area_under_curve_confusion_matrix_evaluator(prediction_result):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using area under ROC curve and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Binary Classification Evaluator for ROC\n",
    "    binary_evaluator = BinaryClassificationEvaluator(\n",
    "        rawPredictionCol=\"prediction\", labelCol=\"label\"\n",
    "    )\n",
    "    roc_auc = binary_evaluator.evaluate(\n",
    "        prediction_result, {binary_evaluator.metricName: \"areaUnderROC\"}\n",
    "    )\n",
    "    print(f\"Area Under ROC: {round(roc_auc,4)*100} %\")\n",
    "\n",
    "    # Extract predictions and labels as RDD\n",
    "    prediction_and_label = prediction_result.select(\"prediction\", \"label\").rdd.map(\n",
    "        lambda row: (float(row[\"prediction\"]), float(row[\"label\"]))\n",
    "    )\n",
    "\n",
    "    # Create a MulticlassMetrics object\n",
    "    metrics = MulticlassMetrics(prediction_and_label)\n",
    "\n",
    "    # Output the confusion matrix\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "\n",
    "def create_pandas_dataframe(spark_dataframe):\n",
    "    \"\"\"\n",
    "    Convert a Spark DataFrame to a Pandas DataFrame and display the results.\n",
    "\n",
    "    Args:\n",
    "    - spark_dataframe (DataFrame): Spark DataFrame to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - df_pandas (DataFrame): Pandas DataFrame containing the data from the Spark DataFrame.\n",
    "    \"\"\"\n",
    "    # Display the results like a pandas DataFrame\n",
    "    df_pandas = spark_dataframe.toPandas()\n",
    "    display(df_pandas)\n",
    "    return df_pandas\n",
    "\n",
    "def display_classification_results(df_results):\n",
    "    \"\"\"\n",
    "    Display classification results based on the DataFrame provided.\n",
    "\n",
    "    Args:\n",
    "    - df_results (DataFrame): DataFrame containing classification results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Obtain unique classes from the 'correctly_classified' column\n",
    "    unique_classes = df_results['correctly_classified'].unique()\n",
    "\n",
    "    # Print total number of unique classes\n",
    "    print(\"Total unique classes:\", len(unique_classes))\n",
    "    print(\"Unique classes:\", unique_classes)\n",
    "    print(\"Total Records on Dataset:\", df_results.shape[0])\n",
    "\n",
    "    # Iterate over each unique class and calculate the percentage of records classified as that class\n",
    "    for class_value in unique_classes:\n",
    "        # Filter DataFrame to get records classified as the current class\n",
    "        class_records = df_results.query(f'correctly_classified == \"{class_value}\"')\n",
    "        \n",
    "        # Calculate percentage of records classified as the current class\n",
    "        total_percentage = (class_records.shape[0] / df_results.shape[0]) * 100\n",
    "        \n",
    "        # Print the number of records classified as the current class and the percentage\n",
    "        print(f'Records classified \"{class_value}\": {class_records.shape[0]}/{df_results.shape[0]} = {round(total_percentage, 2)}%')\n",
    "\n",
    "\n",
    "def export_spark_model(model, model_path, overwrite=False):\n",
    "    \"\"\"\n",
    "    Export a trained Spark model to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - model (pyspark.ml.Model): The trained Spark model to export.\n",
    "    - model_path (str): The path where the model will be saved.\n",
    "    - overwrite (bool, optional): Whether to overwrite the model if it already exists. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Save the model to the specified path\n",
    "    if overwrite:\n",
    "        model.write().overwrite().save(model_path)\n",
    "    else:\n",
    "        model.write().save(model_path)\n",
    "\n",
    "    print(f\"Model saved successfully at: {model_path}\")\n",
    "\n",
    "\n",
    "def load_spark_model(model_path: str) -> Union[LogisticRegressionModel, None]:\n",
    "    \"\"\"\n",
    "    Load a trained Spark model from the specified path.\n",
    "\n",
    "    Args:\n",
    "    - model_path (str): The path from where the model will be loaded.\n",
    "\n",
    "    Returns:\n",
    "    - Union[LogisticRegressionModel, None]: The loaded Spark model or None if loading fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the model from the specified path\n",
    "        loaded_model = LogisticRegressionModel.load(model_path)\n",
    "        print(f\"Model loaded successfully from: {model_path}\")\n",
    "        return loaded_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4151b-579b-448e-9d97-dace939f4a29",
   "metadata": {},
   "source": [
    "# RUNNING ML PROCCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a494ea33-3b85-4c9e-b9eb-aec1fdc88d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:45:44 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2  feature_3  feature_4  target\n",
       "0          5.1        3.5        1.4        0.2       0\n",
       "1          4.9        3.0        1.4        0.2       0\n",
       "2          4.7        3.2        1.3        0.2       0\n",
       "3          4.6        3.1        1.5        0.2       0\n",
       "4          5.0        3.6        1.4        0.2       0\n",
       "..         ...        ...        ...        ...     ...\n",
       "145        6.7        3.0        5.2        2.3       2\n",
       "146        6.3        2.5        5.0        1.9       2\n",
       "147        6.5        3.0        5.2        2.0       2\n",
       "148        6.2        3.4        5.4        2.3       2\n",
       "149        5.9        3.0        5.1        1.8       2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:45:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: /notebooks/spark_ml_model/dataset_iris\n",
      "Model loaded successfully from: /notebooks/spark_ml_model/dataset_iris\n",
      "+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|formatted_prediction|predicted_class_name|actual_class_name|correctly_classified|\n",
      "+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "|[6.34,3.03,4.29,1.1]|  1.0|[-0.5405590083053...|[0.28644828464755...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[6.08,2.62,3.93,1...|  1.0|[-0.5466408257513...|[0.27689074407750...|       2.0|                2.00|           virginica|       versicolor|                   ❌|\n",
      "|[5.24,2.6,4.74,1.11]|  1.0|[-0.6615694617345...|[0.26211433883602...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[4.75,3.12,1.32,0...|  0.0|[0.47294985742743...|[0.54758662353233...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[6.76,3.21,5.29,1...|  2.0|[-1.0773019594656...|[0.17272724854531...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.66,2.61,3.88,1.3]|  1.0|[-0.4979637814550...|[0.28977899348067...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[7.34,2.9,4.08,0.97]|  1.0|[-0.4435353588106...|[0.31025496235700...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[7.72,3.23,6.03,2...|  2.0|[-1.3583358480790...|[0.13154999753580...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "| [5.0,2.92,1.42,0.2]|  0.0|[0.50178183887836...|[0.55956091035566...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[7.35,3.16,5.4,1.99]|  2.0|[-1.1190335437155...|[0.16603723307095...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.42,3.47,5.41,2...|  2.0|[-1.1701838678711...|[0.15614141190010...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.15,3.75,1.46,0...|  0.0|[0.47189971616237...|[0.55048494054842...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[4.48,3.45,1.65,0...|  0.0|[0.39305266828324...|[0.52831027614363...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[6.59,3.31,4.13,1...|  1.0|[-0.5407455069699...|[0.28293832367297...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[5.22,3.27,6.14,2...|  2.0|[-1.4097740531015...|[0.12462871550908...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.28,3.43,1.26,0...|  0.0|[0.55983506484927...|[0.57520218844506...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[5.77,2.47,5.02,1.6]|  1.0|[-0.8933931025491...|[0.20870144707264...|       2.0|                2.00|           virginica|       versicolor|                   ❌|\n",
      "|[4.92,3.38,1.19,0.2]|  0.0|[0.56197790561056...|[0.57433893507614...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[6.31,3.28,6.03,2...|  2.0|[-1.3648069285941...|[0.13047120321374...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[6.79,3.15,6.45,1...|  2.0|[-1.3711928926468...|[0.13517439851462...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Mean Squared Error (Regression): 15.0 %\n",
      "Root Mean Squared Error (Regression): 38.73 %\n",
      "Mean Absolute Error (Regression): 15.0 %\n",
      "R2 Score (Regression): 77.64999999999999 %\n",
      "Accuracy: 85.0 %\n",
      "F1 Score: 84.17 %\n",
      "Precision: 89.8 %\n",
      "Recall: 85.0 %\n",
      "Area Under ROC: 99.72999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[225.   0.   0.]\n",
      " [  2. 104.  88.]\n",
      " [  0.   0. 181.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>formatted_prediction</th>\n",
       "      <th>predicted_class_name</th>\n",
       "      <th>actual_class_name</th>\n",
       "      <th>correctly_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.34, 3.03, 4.29, 1.1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.5405590083053462, -0.2903442505059095, -0.3526444944609881]</td>\n",
       "      <td>[0.2864482846475503, 0.3678858759322097, 0.34566583942024]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6.08, 2.62, 3.93, 1.41]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.5466408257513535, -0.2903442505059095, -0.2694660890118239]</td>\n",
       "      <td>[0.2768907440775039, 0.35778046710014466, 0.3653287888223515]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5.24, 2.6, 4.74, 1.11]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.6615694617345766, -0.2903442505059095, -0.3499613200916602]</td>\n",
       "      <td>[0.26211433883602786, 0.3799372196266485, 0.3579484415373237]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.75, 3.12, 1.32, 0.37]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.4729498574274341, -0.2903442505059095, -0.5485162234219233]</td>\n",
       "      <td>[0.5475866235323344, 0.2552456864888572, 0.1971676899788083]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[6.76, 3.21, 5.29, 1.95]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-1.0773019594656783, -0.2903442505059095, -0.12457467306811842]</td>\n",
       "      <td>[0.17272724854531635, 0.37943050643351023, 0.44784224502117337]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[4.96, 3.66, 1.45, 0.47]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.40657059104699544, -0.2903442505059095, -0.5216844797286445]</td>\n",
       "      <td>[0.5281608796017105, 0.26308734622354973, 0.20875177417473978]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[6.37, 3.22, 4.94, 1.66]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.8918685817527083, -0.2903442505059095, -0.20238672977862693]</td>\n",
       "      <td>[0.20757304550354766, 0.3787997250602228, 0.41362722943622954]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[4.9, 3.78, 1.37, 0.1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.5472233429171686, -0.2903442505059095, -0.620961931393776]</td>\n",
       "      <td>[0.5734955869655829, 0.24818703820020993, 0.1783173748342071]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[5.32, 3.14, 4.03, 1.17]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.49516006249772593, -0.2903442505059095, -0.333862273875693]</td>\n",
       "      <td>[0.2939158980766695, 0.3607226849682492, 0.3453614169550811]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[5.82, 2.68, 4.9, 1.43]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.8069822746587454, -0.2903442505059095, -0.2640997402731681]</td>\n",
       "      <td>[0.22741006974530434, 0.3812261949779958, 0.39136373527669993]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     features  label  \\\n",
       "0     [6.34, 3.03, 4.29, 1.1]    1.0   \n",
       "1    [6.08, 2.62, 3.93, 1.41]    1.0   \n",
       "2     [5.24, 2.6, 4.74, 1.11]    1.0   \n",
       "3    [4.75, 3.12, 1.32, 0.37]    0.0   \n",
       "4    [6.76, 3.21, 5.29, 1.95]    2.0   \n",
       "..                        ...    ...   \n",
       "595  [4.96, 3.66, 1.45, 0.47]    0.0   \n",
       "596  [6.37, 3.22, 4.94, 1.66]    2.0   \n",
       "597    [4.9, 3.78, 1.37, 0.1]    0.0   \n",
       "598  [5.32, 3.14, 4.03, 1.17]    1.0   \n",
       "599   [5.82, 2.68, 4.9, 1.43]    1.0   \n",
       "\n",
       "                                                        rawPrediction  \\\n",
       "0     [-0.5405590083053462, -0.2903442505059095, -0.3526444944609881]   \n",
       "1     [-0.5466408257513535, -0.2903442505059095, -0.2694660890118239]   \n",
       "2     [-0.6615694617345766, -0.2903442505059095, -0.3499613200916602]   \n",
       "3      [0.4729498574274341, -0.2903442505059095, -0.5485162234219233]   \n",
       "4    [-1.0773019594656783, -0.2903442505059095, -0.12457467306811842]   \n",
       "..                                                                ...   \n",
       "595   [0.40657059104699544, -0.2903442505059095, -0.5216844797286445]   \n",
       "596  [-0.8918685817527083, -0.2903442505059095, -0.20238672977862693]   \n",
       "597     [0.5472233429171686, -0.2903442505059095, -0.620961931393776]   \n",
       "598   [-0.49516006249772593, -0.2903442505059095, -0.333862273875693]   \n",
       "599   [-0.8069822746587454, -0.2903442505059095, -0.2640997402731681]   \n",
       "\n",
       "                                                         probability  \\\n",
       "0         [0.2864482846475503, 0.3678858759322097, 0.34566583942024]   \n",
       "1      [0.2768907440775039, 0.35778046710014466, 0.3653287888223515]   \n",
       "2      [0.26211433883602786, 0.3799372196266485, 0.3579484415373237]   \n",
       "3       [0.5475866235323344, 0.2552456864888572, 0.1971676899788083]   \n",
       "4    [0.17272724854531635, 0.37943050643351023, 0.44784224502117337]   \n",
       "..                                                               ...   \n",
       "595   [0.5281608796017105, 0.26308734622354973, 0.20875177417473978]   \n",
       "596   [0.20757304550354766, 0.3787997250602228, 0.41362722943622954]   \n",
       "597    [0.5734955869655829, 0.24818703820020993, 0.1783173748342071]   \n",
       "598     [0.2939158980766695, 0.3607226849682492, 0.3453614169550811]   \n",
       "599   [0.22741006974530434, 0.3812261949779958, 0.39136373527669993]   \n",
       "\n",
       "     prediction formatted_prediction predicted_class_name actual_class_name  \\\n",
       "0           1.0                 1.00           versicolor        versicolor   \n",
       "1           2.0                 2.00            virginica        versicolor   \n",
       "2           1.0                 1.00           versicolor        versicolor   \n",
       "3           0.0                 0.00               setosa            setosa   \n",
       "4           2.0                 2.00            virginica         virginica   \n",
       "..          ...                  ...                  ...               ...   \n",
       "595         0.0                 0.00               setosa            setosa   \n",
       "596         2.0                 2.00            virginica         virginica   \n",
       "597         0.0                 0.00               setosa            setosa   \n",
       "598         1.0                 1.00           versicolor        versicolor   \n",
       "599         2.0                 2.00            virginica        versicolor   \n",
       "\n",
       "    correctly_classified  \n",
       "0                      ✓  \n",
       "1                      ❌  \n",
       "2                      ✓  \n",
       "3                      ✓  \n",
       "4                      ✓  \n",
       "..                   ...  \n",
       "595                    ✓  \n",
       "596                    ✓  \n",
       "597                    ✓  \n",
       "598                    ✓  \n",
       "599                    ❌  \n",
       "\n",
       "[600 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique classes: 2\n",
      "Unique classes: ['✓' '❌']\n",
      "Total Records on Dataset: 600\n",
      "Records classified \"✓\": 510/600 = 85.0%\n",
      "Records classified \"❌\": 90/600 = 15.0%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a Spark ML session\n",
    "spark_ml_session = create_spark_session()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "data_features, target_classes = load_dataset()\n",
    "\n",
    "# Step 2.1: Load the sample dataset for esternal source\n",
    "dataset_file = \"https://raw.githubusercontent.com/JorgeCardona/recursos/main/datasets/iris_dataset.csv\"\n",
    "data_features, target_classes = load_dataset_from_csv(dataset_file)\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "(\n",
    "    data_features_train_splitted,\n",
    "    data_features_test_splitted,\n",
    "    target_classes_train_splitted,\n",
    "    target_classes_test_splitted,\n",
    ") = split_dataset_train_testing(data_features, target_classes)\n",
    "\n",
    "# Step 4: Filter the split datasets\n",
    "data_features_train, target_classes_train = get_filtered_dataset(\n",
    "    data_features_train_splitted, target_classes_train_splitted\n",
    ")\n",
    "data_features_test, target_classes_test = get_filtered_dataset(\n",
    "    data_features_test_splitted, target_classes_test_splitted\n",
    ")\n",
    "\n",
    "# Step 5: Create Spark train and avlidation dataframes from the filtered datasets\n",
    "# 5.1 Dataset for Training the Model\n",
    "train_df = create_spark_dataframe(\n",
    "    spark_ml_session, data_features_train, target_classes_train\n",
    ")\n",
    "# 5.2 Dataset for Validating the Model\n",
    "test_df = create_spark_dataframe(\n",
    "    spark_ml_session, data_features_test, target_classes_test\n",
    ")\n",
    "\n",
    "# Step 6: Train a machine learning model\n",
    "model_trained = create_ml_trained_model(train_df)\n",
    "\n",
    "# Step 7: Export the trained model to a specified location\n",
    "model_path = \"/notebooks/spark_ml_model/dataset_iris\"\n",
    "export_spark_model(model_trained, model_path, overwrite=True)\n",
    "\n",
    "# Step 8: Load the trained model from the specified location\n",
    "model = load_spark_model(model_path)\n",
    "\n",
    "# Step 9: Make predictions using the loaded model\n",
    "prediction_result = model_prediction(model, test_df)\n",
    "\n",
    "# Step 10: Evaluate the model's performance on specified evaluation metrics\n",
    "mse_rmse_mae_r2_avaluator(prediction_result)\n",
    "accuracy_f1Score_precision_recall_evaluator(prediction_result)\n",
    "area_under_curve_confusion_matrix_evaluator(prediction_result)\n",
    "\n",
    "# Step 11: Create a Pandas dataframe from the resulting Spark dataframe of predictions\n",
    "df_results = create_pandas_dataframe(spark_dataframe=prediction_result)\n",
    "\n",
    "# Step 12: Close the Spark ML session\n",
    "spark_ml_session.stop()\n",
    "        \n",
    "# Step 13: Check the results\n",
    "display_classification_results(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043a80f-8e0b-4426-99b9-e91b38222c9c",
   "metadata": {},
   "source": [
    "# METRICS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255dc71-9a92-4af0-a4c7-5f78e74576c1",
   "metadata": {},
   "source": [
    "| Métrica             | Descripción  | Cuando Usar                                                    | Valor   | Explicación del Valor| Fórmula|\n",
    "|---------------------|--------------|----------------------------------------------------------------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Mean Squared Error (MSE) | La media del error cuadrático entre las predicciones y los valores reales. Un valor bajo indica una mejor predicción. | En problemas de regresión donde se desea penalizar más los errores grandes. Por ejemplo, en la predicción de precios de viviendas. | 15.0%   | El MSE calcula el promedio de los errores al cuadrado entre las predicciones del modelo y los valores reales. Cuanto más bajo sea el valor, más cerca estarán las predicciones del modelo de los valores reales. En este caso, un valor de 15.0% indica que, en promedio, las predicciones del modelo tienen un error cuadrático del 15.0% en relación con los valores reales. | \\( MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\)|\n",
    "| Root Mean Squared Error (RMSE) | La raíz cuadrada de la media del error cuadrático entre las predicciones y los valores reales. Un valor bajo indica una mejor predicción. | Similar al MSE, pero proporciona una interpretación más intuitiva, ya que está en la misma escala que la variable objetivo. | 38.73%  | El RMSE es la raíz cuadrada del MSE. Proporciona una medida del error promedio en la misma unidad que la variable de destino. Un RMSE de 38.73% significa que las predicciones del modelo tienden a desviarse en promedio en un 38.73% de los valores reales. | \\( RMSE = \\sqrt{MSE} \\)|\n",
    "| Mean Absolute Error (MAE) | La media del error absoluto entre las predicciones y los valores reales. Un valor bajo indica una mejor predicción. | Cuando se quieren evitar valores atípicos que pueden influir en el MSE. Por ejemplo, en la predicción de la demanda de un producto. | 15.0%   | El MAE calcula la media de las diferencias absolutas entre las predicciones del modelo y los valores reales. Un MAE de 15.0% indica que las predicciones del modelo tienden a desviarse en promedio en un 15.0% de los valores reales. | \\( MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\)|\n",
    "| R2 Score            | El porcentaje de variación en la variable objetivo que se explica por la regresión. Un valor alto indica una buena explicación. | Útil cuando se quiere entender cuánta variabilidad del objetivo es explicada por el modelo. Por ejemplo, en la predicción del rendimiento de un motor. | 77.65%  | El R2 Score representa la proporción de la variabilidad en la variable objetivo que es explicada por el modelo. Un valor de 77.65% indica que el modelo es capaz de explicar el 77.65% de la variabilidad en los datos. | \\( R^2 = 1 - \\frac{SSE}{SST} \\)|\n",
    "| Accuracy            | La proporción de instancias correctamente clasificadas. Un valor alto indica una buena precisión.                        | En problemas de clasificación binaria o multiclase donde todas las clases son igualmente importantes. Por ejemplo, en la detección de spam en correos electrónicos. | 85.0%   | La Exactitud es la proporción de instancias correctamente clasificadas por el modelo. Un valor de 85.0% significa que el modelo clasifica correctamente el 85.0% de las instancias. | \\( \\text{Accuracy} = \\frac{\\text{Número de predicciones correctas}}{\\text{Número total de predicciones}} \\)|\n",
    "| F1 Score            | La media aritmética del recall y la precisión. Un valor alto indica una buena precisión y un buen recuerdo.            | Cuando se necesita encontrar un equilibrio entre precisión y recuerdo en problemas de clasificación desequilibrados. Por ejemplo, en la detección de enfermedades en pruebas médicas. | 84.17%  | El F1 Score es una medida del equilibrio entre precisión y recall. Un valor de 84.17% indica un buen equilibrio entre precisión y recall del modelo. | \\( F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\)|\n",
    "| Precision           | La proporción de instancias verdaderamente positivas entre todas las instancias clasificadas como positivas. Un valor alto indica una buena precisión. | Importante cuando el costo de los falsos positivos es alto. Por ejemplo, en la detección de fraudes en transacciones financieras. | 89.8%   | La precisión es la proporción de instancias positivas correctamente identificadas por el modelo entre todas las instancias identificadas como positivas. Un valor de 89.8% indica que el 89.8% de las instancias identificadas como positivas son realmente positivas. | \\( \\text{Precision} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Positivos}} \\)|\n",
    "| Recall              | La proporción de instancias verdaderamente positivas entre todas las instancias reales positivas. Un valor alto indica un buen recuerdo. | Crucial cuando el costo de los falsos negativos es alto. Por ejemplo, en la detección de enfermedades graves. | 85.0%   | El recall es la proporción de instancias positivas correctamente identificadas por el modelo entre todas las instancias positivas reales. Un valor de 85.0% indica que el modelo identifica correctamente el 85.0% de todas las instancias positivas. | \\( \\text{Recall} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}} \\)|\n",
    "| Area Under ROC (AUC-ROC)   | El área bajo la curva de recepción-operación, que mide la capacidad del modelo para discriminar entre clases. Un valor alto indica una buena capacidad de discriminación. | Útil cuando se necesita evaluar el desempeño del modelo en todas las configuraciones de umbral de clasificación. Por ejemplo, en la detección de enfermedades en pruebas de laboratorio. | 99.73%  | El área bajo la curva ROC (AUC-ROC) es una medida de la capacidad del modelo para discriminar entre clases. Un valor de 99.73% indica que el modelo tiene una capacidad muy alta para distinguir entre las clases. | Calculado mediante la integración de la curva ROC, que representa la tasa de verdaderos positivos frente a la tasa de falsos positivos en diferentes umbrales de clasificación. | -\n",
    "| Confusion Matrix    | Matriz de confusión que muestra los resultados de la clasificación. | Para evaluar el rendimiento del modelo de clasificación. | [[225.   0.   0.]  [  2. 104.  88.]  [  0.   0. 181.]] | La matriz de confusión muestra el conteo de las instancias clasificadas correctamente e incorrectamente por el modelo en cada clase. En este caso, hay 225 instancias de la clase 1 correctamente clasificadas, 104 instancias de la clase 2 correctamente clasificadas, y 181 instancias de la clase 3 correctamente clasificadas. Además, hay 2 instancias de la clase 1 que fueron clasificadas como clase 2, 88 instancias de la clase 2 que fueron clasificadas como clase 3, y ningún error en la clasificación de la clase 3. | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c55a4a-ce6c-43aa-bc46-219f8c21af2b",
   "metadata": {},
   "source": [
    "# CLOSE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91c34848-c0ee-42ff-acce-5da36868368b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0f0c7-7b28-455b-8772-f03dbc4ac47d",
   "metadata": {},
   "source": [
    "# IRIS DATASET GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89075290-83f2-4723-9df5-89bcc9c7e9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datset Shape: (150, 4)\n",
      "Total number of samples: 150\n",
      "Total number of classes: 3\n",
      "Total number of rows or Features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.50</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.72</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.57</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.64</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.02</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>6.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>6.30</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>6.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>6.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>5.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0                  4.50              3.11               1.42   \n",
       "1                  4.72              3.01               1.39   \n",
       "2                  4.57              3.15               1.57   \n",
       "3                  4.64              3.58               1.41   \n",
       "4                  5.02              3.68               1.60   \n",
       "...                 ...               ...                ...   \n",
       "2995               6.70              3.00               5.20   \n",
       "2996               6.30              2.50               5.00   \n",
       "2997               6.50              3.00               5.20   \n",
       "2998               6.20              3.40               5.40   \n",
       "2999               5.90              3.00               5.10   \n",
       "\n",
       "      petal width (cm)  class  \n",
       "0                 0.21      0  \n",
       "1                 0.33      0  \n",
       "2                 0.28      0  \n",
       "3                 0.10      0  \n",
       "4                 0.29      0  \n",
       "...                ...    ...  \n",
       "2995              2.30      2  \n",
       "2996              1.90      2  \n",
       "2997              2.00      2  \n",
       "2998              2.30      2  \n",
       "2999              1.80      2  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:46:00 ERROR MicroBatchExecution: Query [id = faca0387-b48d-4c1c-a375-1daec81e7d7e, runId = 0ae46104-6849-451b-9667-9ca2a95e8e4b] terminated with error\n",
      "java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\n",
      "This stopped SparkContext was created at:\n",
      "\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)\n",
      "java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "\n",
      "The currently active SparkContext was created at:\n",
      "\n",
      "(No active SparkContext.)\n",
      "         \n",
      "\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:122)\n",
      "\tat org.apache.spark.SparkContext.broadcastInternal(SparkContext.scala:1654)\n",
      "\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1639)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:138)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:129)\n",
      "\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:346)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:548)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:537)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:575)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:207)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:206)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:30)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "25/03/10 22:46:00 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@6cf1bd2f[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@74317992[Wrapped task = org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1@70a4141b]] rejected from java.util.concurrent.ScheduledThreadPoolExecutor@23a5f978[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\n",
      "Exception in thread \"stream execution thread for [id = faca0387-b48d-4c1c-a375-1daec81e7d7e, runId = 0ae46104-6849-451b-9667-9ca2a95e8e4b]\" org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef.deactivateInstances(StateStoreCoordinator.scala:119)\n",
      "\tat org.apache.spark.sql.streaming.StreamingQueryManager.notifyQueryTermination(StreamingQueryManager.scala:426)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$3(StreamExecution.scala:360)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:340)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:100)\n",
      "\t... 11 more\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# data values\n",
    "dataset_shape = X.shape\n",
    "num_samples = len(X)  # Total number of samples (rows)\n",
    "num_classes = len(np.unique(y))  # Total number of classes (categories)\n",
    "num_features = X.shape[1]\n",
    "\n",
    "print(f\"Datset Shape: {dataset_shape}\")\n",
    "print(f\"Total number of samples: {num_samples}\")\n",
    "print(f\"Total number of classes: {num_classes}\")\n",
    "print(f\"Total number of rows or Features: {num_features}\")\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Generate synthetic samples for each class\n",
    "for index in range(num_classes):\n",
    "    class_data = X[y == index]\n",
    "\n",
    "    # Generate 400 new, synthetic samples based on the class\n",
    "    new_data = []\n",
    "    for index_column in range(num_features):\n",
    "        mean, std = (\n",
    "            class_data[:, index_column].mean(),\n",
    "            class_data[:, index_column].std(),\n",
    "        )\n",
    "        new_values = np.round(np.random.normal(mean, std, (950,)), 2)\n",
    "        new_data.append(new_values)\n",
    "\n",
    "    # Convert the new data to a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        np.array(new_data).T,\n",
    "        columns=[\n",
    "            \"sepal length (cm)\",\n",
    "            \"sepal width (cm)\",\n",
    "            \"petal length (cm)\",\n",
    "            \"petal width (cm)\",\n",
    "        ],\n",
    "    )\n",
    "    df[\"class\"] = index\n",
    "\n",
    "    # Add the new DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_complete = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on the columns you want to consider unique (e.g., 'sepal_length', 'petal_length', 'sepal_width', 'petal_width')\n",
    "df_unique = df_complete.drop_duplicates(\n",
    "    subset=[\n",
    "        \"sepal length (cm)\",\n",
    "        \"sepal width (cm)\",\n",
    "        \"petal length (cm)\",\n",
    "        \"petal width (cm)\",\n",
    "        \"class\",\n",
    "    ],\n",
    "    keep=\"first\",\n",
    ")\n",
    "\n",
    "# Add the original dataset to df_unique\n",
    "df_original = pd.DataFrame(data=X, columns=iris.feature_names)\n",
    "df_original[\"class\"] = iris.target\n",
    "df_unique = pd.concat([df_unique, df_original], ignore_index=True)\n",
    "\n",
    "df_unique.to_csv(\"iris_dataset.csv\", index=False)\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f15f01-44c9-4d9d-bf38-08e4fc36ad30",
   "metadata": {},
   "source": [
    "# STOP ZOOKEEPER AND BROKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db5c47e9-ff80-4e5c-bce6-5f59bdc9cfa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch,animals-topic-streaming\n",
      "\n",
      "Executing: /usr/local/kafka/bin/zookeeper-server-stop.sh\n",
      "\n",
      "Executing: /usr/local/kafka/bin/kafka-server-stop.sh\n",
      "\n",
      "[2025-03-10 22:46:04,755] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)\n",
      "[2025-03-10 22:46:04,757] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:46:04,758] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:46:04,769] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)\n",
      "[2025-03-10 22:46:04,772] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2025-03-10 22:46:04,773] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2025-03-10 22:46:04,773] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2025-03-10 22:46:04,773] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)\n",
      "[2025-03-10 22:46:04,775] INFO [NodeToControllerChannelManager id=2 name=forwarding] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:46:04,781] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)\n",
      "[2025-03-10 22:46:04,781] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)\n",
      "[2025-03-10 22:46:04,782] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)\n",
      "[2025-03-10 22:46:04,784] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,785] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,785] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,786] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)\n",
      "[2025-03-10 22:46:04,787] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,787] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,787] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,788] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2025-03-10 22:46:04,789] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)\n",
      "[2025-03-10 22:46:04,789] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2025-03-10 22:46:04,789] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2025-03-10 22:46:04,789] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2025-03-10 22:46:04,790] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2025-03-10 22:46:04,790] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:46:04,791] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,791] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,791] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,792] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,792] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,792] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,793] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2025-03-10 22:46:04,793] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)\n",
      "[2025-03-10 22:46:04,794] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2025-03-10 22:46:04,794] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2025-03-10 22:46:04,794] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2025-03-10 22:46:04,794] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)\n",
      "[2025-03-10 22:46:04,795] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)\n",
      "[2025-03-10 22:46:04,795] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)\n",
      "[2025-03-10 22:46:04,796] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)\n",
      "[2025-03-10 22:46:04,796] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,796] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,796] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,796] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,797] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,797] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,797] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,798] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,798] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,798] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,798] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,798] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,799] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,799] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,799] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2025-03-10 22:46:04,809] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)\n",
      "[2025-03-10 22:46:04,810] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)\n",
      "[2025-03-10 22:46:04,810] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)\n",
      "[2025-03-10 22:46:04,810] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)\n",
      "[2025-03-10 22:46:04,811] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:46:04,811] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:46:04,811] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:46:04,813] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)\n",
      "[2025-03-10 22:46:04,813] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:46:04,813] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:46:04,813] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)\n",
      "[2025-03-10 22:46:04,814] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)\n",
      "[2025-03-10 22:46:04,814] INFO Shutting down. (kafka.log.LogManager)\n",
      "[2025-03-10 22:46:04,815] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)\n",
      "[2025-03-10 22:46:04,815] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)\n",
      "[2025-03-10 22:46:04,815] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)\n",
      "[2025-03-10 22:46:04,847] INFO [ProducerStateManager partition=__consumer_offsets-35] Wrote producer snapshot at offset 6 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:46:04 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:04 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-10 22:46:04,965] INFO [ProducerStateManager partition=animals-topic-batch-0] Wrote producer snapshot at offset 100 with 1 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)\n",
      "[2025-03-10 22:46:05,000] INFO [ProducerStateManager partition=animals-topic-batch-classic-way-0] Wrote producer snapshot at offset 324 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)\n",
      "[2025-03-10 22:46:05,072] INFO Shutdown complete. (kafka.log.LogManager)\n",
      "[2025-03-10 22:46:05,077] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2025-03-10 22:46:05,077] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2025-03-10 22:46:05,077] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2025-03-10 22:46:05,078] WARN Session 0x100005479200000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)\n",
      "EndOfStreamException: Unable to read additional data from server sessionid 0x100005479200000, likely server has closed socket\n",
      "\tat org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)\n",
      "\tat org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)\n",
      "\tat org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)\n",
      "[2025-03-10 22:46:05,078] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:46:05 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:05 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-10 22:46:05,280] INFO Session: 0x100005479200000 closed (org.apache.zookeeper.ZooKeeper)\n",
      "[2025-03-10 22:46:05,280] INFO EventThread shut down for session: 0x100005479200000 (org.apache.zookeeper.ClientCnxn)\n",
      "[2025-03-10 22:46:05,281] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2025-03-10 22:46:05,281] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,282] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,282] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,282] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,283] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2025-03-10 22:46:05,284] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)\n",
      "[2025-03-10 22:46:05,296] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)\n",
      "[2025-03-10 22:46:05,296] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)\n",
      "[2025-03-10 22:46:05,296] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)\n",
      "[2025-03-10 22:46:05,296] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)\n",
      "[2025-03-10 22:46:05,297] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)\n",
      "[2025-03-10 22:46:05,298] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2025-03-10 22:46:05,298] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:46:05 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:05 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:05,608] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:05 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:05,712] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:46:05,914] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:46:06,116] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:06 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:06 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:06,619] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2025-03-10 22:46:07,324] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:07 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:07 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:08,331] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:08 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:08 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:09,337] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:09 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:09 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:10 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:10,343] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:10 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:11 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:11,349] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:11 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:12 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:12,355] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:12 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:13 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:13,361] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:13 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:14 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:14,366] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:14 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:15,273] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:15 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:15 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:16,281] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:16 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:16 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:17,287] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:17 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:17 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:18,293] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:18 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:18 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:19,198] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:19 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:19 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:20,103] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:20 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:20 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:21,008] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:21 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:21 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:21,913] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:22 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:22 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:22,818] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:23 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:23 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:23,724] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:24 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:24 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:24,730] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:24 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:25 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:25,735] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:25 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:26 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:26,640] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:26 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:27 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:27,645] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:27 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:28 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:28,549] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:28 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:29 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:29,453] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:29 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:30 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:30,458] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:30 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:31 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:31,463] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:31 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:32 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:32,468] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:32 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:33 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:33,474] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:33 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:34,378] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:34 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:34 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:35,384] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:35 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:35 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:36,399] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:36 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:36 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:37,403] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:37 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:37 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:38,409] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:38 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:38 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:39,413] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:39 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:39 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:40,321] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:40 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:40 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:41,224] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:41 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:41 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:42,228] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:42 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:42 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:43,233] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:43 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:43 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:44,238] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:44 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:44 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:45,242] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:45 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:45 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:46,246] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:46 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:46 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:47,251] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:47 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:47 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:48,255] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:48 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:48 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:49,259] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:49 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:49 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:50,263] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:50 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:50 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:51,268] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:51 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:51 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:52,272] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:52 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:52 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:53,275] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:53 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:53 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:54,279] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:54 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:54 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:55 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:55,283] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:55 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:56 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:56,287] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:56 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:57 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:57,190] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:57 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:58 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:58,194] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:58 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:46:59,098] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:46:59 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:46:59 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:47:00,102] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:47:00 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:00 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:01 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:47:01,105] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:47:01 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:47:02,009] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:47:02 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:02 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:47:02,913] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:47:03 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:03 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:47:03,818] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:47:04 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:04 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:04 WARN KafkaOffsetReaderAdmin: Error in attempt 1 getting Kafka offsets: \n",
      "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\n",
      "\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)\n",
      "\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions(ConsumerStrategy.scala:66)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.retrieveAllPartitions$(ConsumerStrategy.scala:65)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.retrieveAllPartitions(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.assignedTopicPartitions(ConsumerStrategy.scala:113)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:130)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listNodes\n",
      "[2025-03-10 22:47:04,822] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "25/03/10 22:47:05 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:05 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2025-03-10 22:47:05,598] ERROR org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: listTopics\n",
      " (org.apache.kafka.tools.TopicCommand)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while executing topic command : Timed out waiting for a node assignment. Call: listTopics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/10 22:47:05 WARN KafkaOffsetReaderAdmin: Error in attempt 2 getting Kafka offsets: \n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.conf()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.kafka010.KafkaConfigUpdater.setAuthenticationConfigIfNeeded(KafkaConfigUpdater.scala:60)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.setAuthenticationConfigIfNeeded(ConsumerStrategy.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.setAuthenticationConfigIfNeeded$(ConsumerStrategy.scala:60)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.setAuthenticationConfigIfNeeded(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:130)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "25/03/10 22:47:06 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:06 WARN KafkaOffsetReaderAdmin: Error in attempt 3 getting Kafka offsets: \n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.conf()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.kafka010.KafkaConfigUpdater.setAuthenticationConfigIfNeeded(KafkaConfigUpdater.scala:60)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.setAuthenticationConfigIfNeeded(ConsumerStrategy.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.setAuthenticationConfigIfNeeded$(ConsumerStrategy.scala:60)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.setAuthenticationConfigIfNeeded(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:130)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "25/03/10 22:47:07 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:07 ERROR MicroBatchExecution: Query [id = 946a67a1-0b56-42e3-9217-bbd5acd60888, runId = 00a1b1ea-bab9-4029-8119-b27b8c5cc55d] terminated with error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.SparkEnv.conf()\" because the return value of \"org.apache.spark.SparkEnv$.get()\" is null\n",
      "\tat org.apache.spark.kafka010.KafkaConfigUpdater.setAuthenticationConfigIfNeeded(KafkaConfigUpdater.scala:60)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.setAuthenticationConfigIfNeeded(ConsumerStrategy.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.setAuthenticationConfigIfNeeded$(ConsumerStrategy.scala:60)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.setAuthenticationConfigIfNeeded(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin(ConsumerStrategy.scala:48)\n",
      "\tat org.apache.spark.sql.kafka010.ConsumerStrategy.createAdmin$(ConsumerStrategy.scala:47)\n",
      "\tat org.apache.spark.sql.kafka010.SubscribeStrategy.createAdmin(ConsumerStrategy.scala:102)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.admin(KafkaOffsetReaderAdmin.scala:70)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.$anonfun$partitionsAssignedToAdmin$1(KafkaOffsetReaderAdmin.scala:499)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.withRetries(KafkaOffsetReaderAdmin.scala:518)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.partitionsAssignedToAdmin(KafkaOffsetReaderAdmin.scala:498)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaOffsetReaderAdmin.fetchLatestOffsets(KafkaOffsetReaderAdmin.scala:297)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaMicroBatchStream.latestOffset(KafkaMicroBatchStream.scala:130)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$4(MicroBatchExecution.scala:491)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$2(MicroBatchExecution.scala:490)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$constructNextBatch$1(MicroBatchExecution.scala:479)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.withProgressLocked(MicroBatchExecution.scala:810)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.constructNextBatch(MicroBatchExecution.scala:475)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:268)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "25/03/10 22:47:07 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3d41d758[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@2afcbe62[Wrapped task = org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1@7ccaabe]] rejected from java.util.concurrent.ScheduledThreadPoolExecutor@23a5f978[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\n",
      "Exception in thread \"stream execution thread for [id = 946a67a1-0b56-42e3-9217-bbd5acd60888, runId = 00a1b1ea-bab9-4029-8119-b27b8c5cc55d]\" org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef.deactivateInstances(StateStoreCoordinator.scala:119)\n",
      "\tat org.apache.spark.sql.streaming.StreamingQueryManager.notifyQueryTermination(StreamingQueryManager.scala:426)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$3(StreamExecution.scala:360)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:340)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:100)\n",
      "\t... 11 more\n",
      "25/03/10 22:47:08 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:09 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:10 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:11 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:12 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:13 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:14 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:15 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:16 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "25/03/10 22:47:17 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (5a54e50b65a1/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    }
   ],
   "source": [
    "commands = [\n",
    "    # Delete Topics\n",
    "    \"/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch,animals-topic-streaming\",\n",
    "    # Stop Zookeeper\n",
    "    \"/usr/local/kafka/bin/zookeeper-server-stop.sh\",\n",
    "    # Stop Broker\n",
    "    \"/usr/local/kafka/bin/kafka-server-stop.sh\",\n",
    "]\n",
    "execute_commands(commands=commands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - ML - Data Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
